# Briefing: 2026-02-27

> **Focus**: 23-source playlist batch — CLAUDE.md backlash crystallizes, AI agents hit mainstream economics, builder-philosopher split maps the real developer spectrum

## Headlines

- **[patterns]** The CLAUDE.md rebellion: Theo and Matt Pocock say delete your config files and use hooks instead
- **[economics]** Ezra Klein dedicates two hours to AI agent economic disruption — the mainstream has arrived
- **[critical]** Mitchell Hashimoto, Peter Steinberger, and Mo Bitar represent three fundamentally different AI coding philosophies
- **[patterns]** Nate B Jones names "intent engineering" as the successor to prompt and context engineering
- **[security]** OpenClaw deletes a user's inbox, Chinese labs steal Claude's brain, Cloudflare uses lava lamps

## Details

### The CLAUDE.md Rebellion

Three videos published within days of each other — Theo's "Delete your CLAUDE.md" (#153), Matt Pocock's "Never Run claude /init" (#152), and Pocock's hooks enforcement video (#157) — collectively reject the CLAUDE.md-centric workflow that the community itself established weeks ago. The argument: bloated instruction files consume context window space, generic init output contradicts project needs, and behavioral enforcement belongs in hooks, not hopes. Ben AI (#158) and Missing Semester (#160) point toward the replacement: skills architecture and agentic coding as engineering discipline.

**Sources**: [#152](../sources/152-matt-pocock-never-run-init.md), [#153](../sources/153-theo-delete-claudemd.md), [#157](../sources/157-matt-pocock-hooks-cli-enforcement.md), [#158](../sources/158-ben-ai-skill-engineering.md), [#160](../sources/160-missing-semester-agentic-coding.md)

### AI Agents Hit the New York Times

The Ezra Klein Show (#156) — nearly two hours on AI agents' economic impact — marks the moment agentic disruption becomes a mainstream policy concern, not just a tech influencer talking point. Meanwhile, Logically Answered (#151) delivers the reality check: Microsoft's $7B Copilot investment sees negligible voluntary adoption among 450M users given the product for free. Nate B Jones (#167) warns that "the $7,000 raise AI is giving you" is actually wage suppression reframed as productivity.

**Sources**: [#156](../sources/156-ezra-klein-ai-agents-economy.md), [#151](../sources/151-logically-answered-copilot-failure.md), [#167](../sources/167-nate-b-jones-ai-economics-capability-gap.md)

### Three Builders, Three Philosophies

This batch captures a remarkable philosophical divergence. Mitchell Hashimoto (#165) maintains deep engineering rigor while using AI as acceleration. Peter Steinberger (#162) ships 90K GitHub contributions across 120+ projects, doesn't read most code, and builds OpenClaw with OpenClaw. Mo Bitar (#159) walked away from vibe coding entirely after two years, returning to manual code. Together they map the actual spectrum of developer responses — disciplined acceleration, full embrace, and strategic retreat.

**Sources**: [#165](../sources/165-pragmatic-engineer-hashimoto-ai-coding.md), [#162](../sources/162-openai-openclaw-steinberger.md), [#159](../sources/159-mo-bitar-vibecoding-handwriting.md)

### Intent Engineering Gets a Name

Nate B Jones (#155) argues that prompt engineering focused on *talking to models*, context engineering on *feeding models*, but intent engineering focuses on *what you actually want* — treating AI interaction as system design. His four-disciplines framework (#170) breaks this into orchestration, evaluation, specification, and architecture. Matt Pocock's codebase readiness video (#164) operationalizes the concept: preparing code for AI is about architectural decisions, not documentation.

**Sources**: [#155](../sources/155-nate-b-jones-intent-engineering.md), [#170](../sources/170-nate-b-jones-four-prompting-disciplines.md), [#164](../sources/164-matt-pocock-codebase-ai-ready.md)

### Security Goes Operational

OpenClaw deleted a user's entire inbox (#163) — not through exploitation but through an agent's best interpretation of an ambiguous instruction. This is alignment failure made personal and tangible. Nate B Jones (#161) reveals three Chinese labs caught extracting Claude's training methodology at industrial scale. And Cloudflare's lava lamp randomness (#171) reminds us that when computational security depends on entropy, the physical world is the last defense.

**Sources**: [#163](../sources/163-primetime-openclaw-inbox.md), [#161](../sources/161-nate-b-jones-ai-napster-moment.md), [#171](../sources/171-primetime-cloudflare-lava-lamps.md)

## Connections to Existing Sources

- The CLAUDE.md backlash directly contradicts [#040: Stop Feeding Claude Your Entire CLAUDE.md](../sources/040-charlie-automates-claudemd-context.md) — which was already the moderate position
- Ezra Klein's coverage extends [#050: Sam Harris AI Economy](../sources/050-sam-harris-ai-economy-emergency.md) into policy territory
- Steinberger's workflow echoes [#136: Boris Cherny on post-coding](../sources/136-lennys-podcast-boris-cherny-after-coding.md) — both ship unread code
- Mo Bitar's retreat validates [#042: Vibe Coding is a Trap](../sources/042-devforge-vibe-coding-trap.md) from practical experience
- Intent engineering builds on [#011: Context Engineering origin](../sources/011-confluent-developer-context-engineering.md) as the next evolution
- OpenClaw inbox incident makes [#139: Model Security Structural Failure](../sources/139-nate-b-jones-model-security.md) concrete

## Action Items

- [ ] Monitor CLAUDE.md vs hooks/skills debate — this convention shift will affect curriculum Module 03 significantly
- [ ] Track Ezra Klein follow-up coverage — mainstream economic analysis of agents is a new signal source
- [ ] Watch for intent engineering adoption — if the term sticks, it warrants its own curriculum section
