So, I have talked a lot about OpenAI over the last couple days and weeks, and things are not looking any better for this company that is bleeding far too much money than the amount of money that it's actually making. The burn rate of OpenAI is simply unprecedented. And a lot of analysts believe that this is a company that won't survive long if this burn rate continues. And the downfall of OpenAI is something that a lot of enthusiasts would love to see due to the fact that they're basically single-handedly responsible for the current RAM shortage and inflation which has caused the chain reaction that has caused a shortage and inflation of other computing components such as CPU, GPU, SSDs, you name it. In an attempt to stay competitive and try to starve the competition of computing components, OpenAI made a deal with SKH Highix and Samsung where they ended up consuming 40% of the world's RAM during the time of that deal. And that caused the chain reaction of everyone wanting to hoard RAM seeing this happen. And that left consumers in the dust and caused all the computing electronics and computing components for consumers to shoot up in price and for that stuff to become less of a focus for a lot of these companies that once upon a time focused on consumers. And so what's going on with OpenAI right now? Well, as I've mentioned in past videos, OpenAI is a company that's heavily relying on investments from outside thirdparty companies in order to support their endeavors to support the vast amount of money that is required to build the data centers, the AI infrastructure as well as pay for the huge amount of electricity that is involved in powering AI. And one of OpenAI's biggest partners was Microsoft, who have a significant stake in Open AI, who have relied on OpenAI heavily for their own AI endeavors. But it looks like that relationship is starting to show some cracks if recent reports are to be believed. This right here is breaking news from the Financial Times that reads, "icrosoft's AI chief just said they're pursuing true self-sufficiency and cutting their dependence on open AI." Here's a screenshot of the Financial Times article in question. It reads right here, "Microsoft is pursuing true self-sufficiency in AI by building its own powerful models and reducing its reliance on open AI." According to the company's AI chief, Mustafa Souleman is the head of AI at Microsoft and he said, "We have to develop our own foundation models which are at the absolute frontier with gigawatt scale compute and some of the very best AI training teams in the world." And apparently things are shifting when it comes to the business relationship between Microsoft and OpenAI with Sullean telling the Financial Times that the strategic shift follows a restructuring of its relationship with the chat GPT maker in October. Basically, Microsoft is at that point now where

they want to make their AI in-house as much as possible, much like Google does it with their Gemini AI program. And with Google in particular, they're actually even making their own chips called TPUs for their AI. And so I think Microsoft is trying to head in that direction instead of relying on Open AI. And I would surmise that it's a combination of both self-sufficiency being a better business model in the long-term future instead of relying on a third party that might be a wild card. Combined with the fact that OpenAI as a business, when you look at their numbers, it's really just not looking like great prospects. This follows Nvidia recently expressing a lack of confidence in OpenAI when they recently backed away from a publicly announced up to $100 billion mega deal between OpenAI and Nvidia that has been put on ice. Nvidia instead opted to invest about a fifth of that, $20 billion. And with OpenAI needing every billion dollar they can take in order to support their endeavors and their ongoing debt and relationships with other companies and all the money that is circulating there. This was a huge blow for the company. And now to see that Microsoft is starting to like back away from Open AI, trying to become more self-sufficient and potentially leave OpenAI to their own devices in the mid to long-term future, that could spell trouble for Open AI. And the thing is, tensions between Microsoft and OpenAI have been building throughout the last year or so. Back in June of 2025, the following news made headlines. This is a Windows Central article whose headline reads, "Tensions boil as OpenAI executives reportedly accuse Microsoft of anti-competitive behavior as partnership phrase." This is information coming out from an exclusive report by the Wall Street Journal, which Windows Central summarized as tension between the two companies has seemingly continued to brew. The chat GPT maker seeks to evolve into a for-profit venture. However, Microsoft is seemingly holding back from giving its thumb of approval as a transition may weigh heavily on its interests, including its rights to OpenAI's intellectual property. OpenAI is betting on Microsoft's approval to move forward with its for-profit transition, which will allow it to go public and raise money. But Microsoft's delayed blessing has seemingly placed some of OpenAI's executives over the fence, prompting them to accuse the tech giant of anti-competitive business practices. Because of how much Microsoft has invested in OpenAI, they have a lot of power over OpenAI's decisions. And OpenAI wants to go public, but doing so in some areas might not be in the interest of Microsoft. So Microsoft is hesitant to allow OpenAI to do so. And that's caused some friction in their business partnership and relationship. And then a few months back in October of 2025, it was reported that a deal was made behind the scenes, a new definitive agreement where Microsoft and OpenAI will now allow

the former Microsoft to independently pursue AGI or in partnership with third parties. Whereas before Microsoft was tied to OpenAI, they recently made a deal that allows Microsoft to pursue their own ventures while still being able to partner with Open AI in ways that Microsoft is comfortable with, which kind of culminated in Microsoft coming out and saying that they want to pursue self-sufficiency, which raises red flags for OpenAI, which has become so dependent on their partnership with Microsoft. It feels like Microsoft is ready to jump ship and essentially like almost start to compete with OpenAI rather than be like an exclusive partner with them. What all this means is that Microsoft has less incentive to support OpenAI, to invest in OpenAI, and they will likely want to put more of that money into their own self-sufficiency within the AI landscape. While the partnership between Microsoft and OpenAI currently still remains active, who knows if that will stay true for the mid to long-term future. What this plan for self-sufficiency means is that Microsoft is now starting to diversify by backing competitors to OpenAI like Anthropic and Mistral AI and plans to launch its own models this year. And all this comes amidst reports and analysis highlighting that OpenAI is still continuing to bleed way more money than it's actually making with articles like this one from Will Lockett, who's an independent journalist covering global politics, climate change, and technology. The headline of this Medium article reads, "OpenAI is in a far worse position." Talking about a previous article where he thought OpenAI had made $20 billion in revenue last year in 2025. But because he confused annualized recurring revenue with annualized recurring revenue, that $20 billion figure ended up being far more optimistic than the actual reality, which is that OpenAI's total revenue for 2025 was actually 11.9 billion, which sounds like a lot of money to the average Joe, but for a major corporation working at such high level, especially working on AI, those are basically pennies on the dollar. Will Lockett highlights how multiple analysis have found that OpenAI's operational costs will be significantly more than $28 billion in 2025. So even if they had made $20 billion in revenue, they're still likely miles away from breaking even. But again, they didn't actually make $20 billion in revenue last year, they actually made 1.9 billion, which is significantly less. Will locket continues with OpenAI's costs could be even higher than previously imagined, especially as more time passes as more data centers are built and power requirements grow. 1.9 gawatt of computing power is expected by 2025 from OpenAI. And a single gawatt of AI capable data centers costs $80 billion to build. A gigawatt of AI data centers consumes around $1.3 billion in energy costs annually. Data centers have a realistic operational lifespan of 3 years. So logically, the annual cost of a single gawatt of AI compute power is almost $28 billion. So

OpenAI's 1.9 gawatt of compute will cost around $53 billion annually when you take all these factors into consideration. So yeah, when you look at expenses at that level, the current revenue that OpenAI is seeing, it's just not going to cut it. Now, it's worth noting that some of that cost will be soaked up by the owners and operators of the data centers, which is why many AI data center operators are running at a catastrophic loss, but it doesn't change the fact that OpenAI's costs far exceed their revenue potential right now, which means that this is just not a viable business. It's just something where you throw money to burn in the fire. Matters are made worse for AI companies by the fact that they've recently had to commit to paying 100% of grid upgrade costs and electricity. that have been pressured to commit to cover electricity price increases from their data centers. Anthropic was the most recent AI company to make this commitment, but Microsoft did the same back in January 13th and OpenAI followed on January 21st and now Enthropic on February 11th, the same playbook on the same month. Why is that? Well, that's because the Trump administration is preparing a voluntary agreement requiring AI companies to pay 100% of new power generation costs. The companies are announcing these pledges before the White House event forces them to. Basically, AI data centers consume so much power that some of that cost may be passed on to the consumers, which is something that can become a political liability for politicians who are promising their citizens that their electricity bills are going to go down or stay the same. Which is why New York State senators introduced the bill to pause data center permits entirely. Senator Van Holland introduced the legislation requiring AI companies to pay for expansion costs. Virginia's new governor campaigned on making data centers pay their own way when elected officials start running on your electricity bill. You've got maybe 6 months before voluntary becomes mandatory. Referring to this voluntary agreement from the Trump administration requiring companies to pay 100% of the new power generation costs. It's voluntary now, but once you start pissing off the public because of their increase in electricity bills as a result of data centers, that's when politicians start to lose ground. And so in the self-interest of politicians, they're enacting legislations to make sure that AI companies are eating up all the cost. And AI companies are predicting that if they don't make their commitments now, then the current administration will make the voluntary agreement that will require AI companies to pay 100% of new power generation costs mandatory. And when that happens, the government gets to control parameters. Whereas if AI companies kind of get ahead of it now, then they get to control the parameters while adhering to practices that ensure consumers don't have to pay more for electricity, compromising politicians ability to like

win over their citizens. It's AI companies basically going, "Hey, wo government, there's no need to pass legislation and make laws that are mandatory. We'll do it ourselves." And that way AI companies have some freedom within that where they can set some parameters and aren't completely controlled by government legislation. But yeah, what that means is that OpenAI also has to adhere to this commitment in order to not invoke the wrath of the government. That's only going to contribute to their annual expenses. And right now, based on OpenAI's own projection, they're apparently set to lose $14 billion in 2026. As summarized by Yahoo Finance here, a new report from the information claims to have seen internal OpenAI documents. Documents that essentially highlight potential performance projections and their projection is that they'll lose around $14 billion for 2026, which is set to be roughly three times worse than early estimates for 2025. And those kinds of losses are estimated to persist for a few more years. Over the 2023 through end of 2028 period, the report claims OpenAI expects to lose $44 billion. $44 billion lost in just 5 years before turning a profit of $14 billion in 2029. And as if all that wasn't enough, apparently the report claims that OpenAI plans to spend an astonishing $200 billion through the end of the decade up until 2030. 60 to 80% of which will be spent on training and running AI models. Now, something else that this Yahoo Finance article spotlights is how overly optimistic OpenAI is about its future prospects. Apparently, OpenAI's internal forecast predict that the for-profit part of OpenAI will hit $100 billion in annual revenues in 2029, up from an estimated $4 billion in 2025. They claim that their revenue will go from $4 billion to hundred billion in a mere four years. Yahoo Finance thinks that those numbers are getting silly, stating that, let's put that hundred billion in revenue into context. In 2025, Nvidia had revenues of around $130 billion as a consequence of holding a near total monopoly over perhaps the largest tech hardware boom in human history. And OpenAI is expecting to more or less match that in about four years. Uh-huh. says this Yahoo Finance article. Unless OpenAI knows something we don't, those internal forecasts seem to be rather optimistic, to put it lightly. Now, the information did report that OpenAI's cash burn is allegedly not as bad as previously thought, with the company tearing through a mere $340 million in the first half of the most recent financial year, though Yahoo Finance states how that squares with overall losses counted in multiple billions isn't explained. Despite OpenAI's current optimism, most analysts predict that if the spending pace continues without a major new funding round, analysts warn OpenAI could face a serious cash shortage as early as 2027, increasing pressure to raise capital, restructure costs, or accelerate monetization. Furthermore, this post highlights how OpenAI's finances show how expensive scaling

intelligence truly is and why long-term funding, partnerships, and sustainable business models are just as critical as technical breakthroughs. Which is why the fact that Nvidia is kind of backing away a little bit from OpenAI in terms of fully committing with things like up to a $100 billion deal or Microsoft starting to kind of become less reliant on Open AI and starting to fund competitors and also funding their own AI operations to be a competitor to open AAI. Why all of that is extremely bad for OpenAI. Another kind of entity that AI companies rely on are banks. And even banks are starting to show hesitation about investing at the level that they once used to on companies like Open AI or companies like Oracle who are closely tied to OpenAI and provide essentially the computing means for OpenAI to realize their AI infrastructure. A banker familiar with Oracle's fundraising said, "We basically tapped every single project finance bank possible, but there are only so many banks. Banks will have to offload that risk if they want to keep lending." And this individual hedgi had the following take when it comes to this matter. Banks are nervous about their exposure to AI financing and are looking for ways to offload risk they have already committed to. It's this like sunk cost fallacy thing where they've already invested so much that they have to stay on this train but are trying to find ways to mitigate their risk. Open AI burns $9 billion a year and doesn't expect profitability until 2029. Nvidia just backed away from a $100 billion investment. And most recently, Microsoft has kind of backed away from their commitments to Open AI to a pretty significant degree. The banks see the risk accumulating, which is why they're working this hard to get it off their books. When lenders are this eager to find someone else to hold the bag, pay attention to what they're telling you about their own confidence in the trade. And beyond that, companies like OpenAI are losing talent. So, for example, Zoe Hitzik here recently posted the following on February 11th, 2026, talking about how I resigned from OpenAI on Monday, the same day they started testing ads in chat GPT. Basically questioning the moral implications of a company like OpenAI, having the most detailed record of private human thought ever assembled, asking, "Can we trust them to resist the title forces pushing them to abuse it?" What's unique about chat GBT is that it has direct input from the end user and a lot of that input reveals a lot about that person's psychological profile. And so integrating ads with chat GPT while potentially exploiting the information that chat GPT gains from its interactions with the end users, the moral implications of how manipulative that can get because chat GPT can get to know someone very intimately. That's where Zoe Hidzig drew the line and said, "I can't do this.

This is like morally wrong. Stating, I once believed I could help the people building AI get ahead of the problems it would create. This week confirmed my slow realization that OpenAI seems to have stopped asking the questions I joined to help answer. Framing the unique circumstances of running ads on Chat GPT specifically as Chat GPT users have generated an archive of human cander that has no precedent in part because people believed they were talking to something that had no ulterior agenda. And so with that level of cander, what advertising and chat GPT does is create a potential for manipulating users in ways we don't have the tools to understand, let alone prevent. So yeah, basically Zoe realized that when OpenAI doesn't really care about the ways in which this technology can be abused as long as it makes them profit, she was like, I'm out. I can't be a part of this. And it's not just OpenAI that's seeing these kinds of resignations. Anthropic head of safeguards just quit because the world is in peril and wants to write poetry or something. X AI lost 11 people, two of them co-founders, with one saying autonomously self-improving AI go live in 12 months. Oh, and all this comes right as we discovered AI models are now building themselves and are sabotaging their human supervisors without them knowing. And this is something being reported on on mass through major news outlets like Financial Times as well with this article titled OpenAI's chat GPT push triggers senior staff exits. And all the while amidst all of this, amidst the giant mountain of a hurdle that OpenAI faces when it comes to their financial situation and how untenable it currently is, there's also the fact that their dominance in the AI scape is, as M puts it here, crumbling, highlighting a situation where competitors are catching up. Gemini, Google's Gemini, recently surpassed Chat GPT and daily conversations for the first time ever. And Anthropics DAU jumped 11% after their Super Bowl ad. Notably, Anthropic's ad went viral precisely because it mocked OpenAI for introducing ads into AI. And then beyond that, this post right here aptly highlights all of the ways in which OpenAI has created negative PR for itself and all the ways it is [ __ ] up where the public is starting to admonish Open AI because they feel like their feedback isn't being listened to. As for the ads in question, I talked about this in a previous video. these ads from the Super Bowl basically making fun of the fact that ads are being introduced to Chat GPT and the way they have the potential to interrupt people and abuse Chat GPT's knowledge of those people in order for them to be able to like shell out targeted ads to exploit aspects of what Chat GPT has learned about that human psychology. And yeah, Enthropic's campaign is working because Anthropic has become the fastest

growing software business of all time as the numbers here show. Here's another individual highlighting this trend. A single coding tool went from $0 to $2.5 billion in 12 months. Chat GPT, the fastest growing consumer app in history, generated roughly $1 billion in total revenue during its first full year of monetization in 2023. Cloud code did $2.5 times that. Cloud code being from Enthropic selling to a fraction of the audience, developers and engineering teams only at a fraction of the brand awareness. Enthropic just seems to be a lot more well positioned as a business model than Open AI is. Not to mention all the bad press that Open AAI is getting and all of the ways that Anthropic has straight up like taken pot shots at OpenAI and has proven to be incredibly successful in doing so. Going back to user backlash, a big part of that had to do with the way OpenAI killed GPT40. Chat GPT now is up to like 5 something. But the reason people were pissed that 40 was retired was because there were some folks out there who were forming essentially this kind of like parasocial relationship with this AI model, a strong attachment to 4's personality and relied on it for emotional advice. OpenAI felt like they created a model that was far too easy for people to form an attachment with and trying to prevent some of the potential like ethical questions that may come with that. They retired 40. But because they had already put out the 40 model and a lot of people had gotten to like really like this model and become attached to it, its retirement, especially I think like around Valentine's Day, was something that many people absolutely despised and turned on OpenAI as a result. So that's created tons of negative PR with #ke keep440 trending on social media and making the rounds and going viral. And so people who are one supporters of openai are now like celebrating the fact that openai is projected to lose $14 billion in 20126 so on and so forth. And then outside of people who formed parasocial relationships with chat GPT, a campaign called Quit GPT is going viral for other ethical reasons like the way OpenAI's leadership contributed to politicians that a lot of people didn't agree with. the way AI is used in government enforcement as well as ethical unease and corporate accountability. Just a lack of values on the part of these companies that seem to be dead set on making as much money as possible on this technology without asking questions about its potential uses of abuse, especially given how powerful it is. Now, amidst all this, it is hilarious that OpenAI brings up ethics itself because they believe it's unfair and warned US lawmakers that its Chinese rival Deepseek is using unfair and increasingly sophisticated methods to extract results from leading US AI models to train the next generation of

its breakthrough R1 chatbot. So, let me get this straight. OpenAI, whose entire business model revolves around stealing information from other people in order to train their AI without permission, are complaining that their work is being stolen for the benefit of another company. Do you see the irony and hypocrisy in that? Which is why people have been coming out on social media and making fun of all of this, saying things like, "Mommy, someone copied my plagiarizer 9000. The plagiarizer who got plagiarized is complaining that they got plagiarized. You can't make this up." Even companies like Google are saying people are copying its AI without its permission. Much like it scraped everybody's data without asking to create its AI in the first place. So yeah, suffice to say that people are not sympathetic to these companies complaints when they themselves engage in the very same actions that they're complaining about. People are also starting to become a lot more aware of the moral implications behind how powerful a tool AI is and the way it can be exploited. Especially when executives are full-on coming out and saying that they want to replace workers with Sulleon, DeepMind co-founder and Microsoft AI head predicting that most white collar computer-based tasks will be fully automated by AI in 12 to 18 months. So jobs like law and accounting and all of those things, he believes all of that will be run by AI in 12 to 18 months and that those people will essentially be out of work. All the while, government officials like Andrew Yang warn of middle class shrinkage as a result of AI. Bernie Sanders labeled it an economic earthquake and skeptics highlighted AI's limits like hallucinations and past overhyped timelines. And indeed, you look everywhere right now and you'll find plenty of stories of just how flawed and unreliable AI currently is. It is an impressive technology and when it works it works but when it doesn't it fails epically and the over reliance on AI will mean that when a failure happens that will domino effect into like unimaginable consequences. So for example a scenario like this we just found out our AI has been making up analytics data for 3 months and I'm going to throw up. It completely [ __ ] over their financial bookings. It reads right here that we've been using an AI agent since November to answer leadership questions about metrics. It seemed amazing at first with fast answers, detailed explanations. Everyone loved it. I just found out it's been hallucinating numbers this entire time. Our VP of sales made territory decisions based on data that didn't exist. Our CFO showed the board a deck with fake insights. The AI was just inventing plausible sounding percentages. I only caught it by accident when someone asked me to doublech checkck something. I started digging and holy [ __ ] it's bad. This right here highlights the importance of human oversight. Why?

You can't just rely on AI to do everything and leave it to be fully autonomous because it still hallucinates. It's nowhere near reliable enough for it to be able to be deployed at this level. Even if it's right 99% of the time, that 1% can [ __ ] up everything. On a smaller scale, we have situations like these where chat GPT erased two years of a professor's work with one click and there was no way back. A professor lost two years of research after disabling the data consent option in chat GPT settings. Then we have security concerns like this one. A code error temporarily allowed Copilot Chat to expose confidential emails and files in its responses. A bug enabled the AI to include content from protected emails and files, especially in sent items and drafts that were safeguarded by sensitivity labels and DLP policies. Microsoft has confirmed the issue and is deploying a fix. And back in December of 2025, Microsoft full-on said that Windows 11 its AI features do hallucinate like every other chatbot and poses security risks to users. And outside of security risks, people who have tried to use Windows Code Pilot AI exclusively for the computing needs has often led to results where the computer feels incompetent than if you were to use it normally and regularly as we do today with a mouse and keyboard instead of having AI try to do everything for you. with AI often not performing tasks as commanded or with it presenting misinformation when asked questions. Like there are times when it works here and there, but the times that it doesn't makes it enough of a friction point and makes the technology unreliable enough that AI as a technology is, you know, seeing a lot of skepticism and understandably so. On a more severe level, we have situations like this one. An AI powered surgical tool is facing backlash after allegedly harming patients it was designed to treat. Multiple lawsuits have been filed against the Trudy navigation system, alleging that the addition of AI made the device less safe, not more. On a less severe level, we have complaints of using AI in the workplace when it comes to game development with this article from October of 2025, highlighting how EA staff are struggling with management, urging them to use AI for just about everything. Sources claim EA's use of AI tools is creating flawed code and could be leading to layoffs. And then you have game companies like Roblox highlighting this amazing use of AI and the way it can just automatically generate games. And then what it ultimately generates is copyrighted material like this right here. What they generated is just expedition 33. Uh this is not brand new, you know, creative from scratch content. This is just copying and pasting of existing content. Like this is straight up just complete creative bankruptcy. And so yeah, the general sentiment surrounding AI right

now, seeing how the technology has time and again proven to be unreliable or produce quality output that is far inferior to what humans can do right now, is that AI solves zero problems currently that have not been solved yet. All the results it produces are worse and less consistent than what can be achieved by hand. The only selling point is that it can produce the results faster. It's literally a slot machine by definition. And then there are all of the fears surrounding how the government wants to exploit AI. So for example, this Axio's article highlights how the government and Enthropic have been in talks to enable the military to use the AI technology for what they call all lawful purposes. Now Enthropic made a stand on ensuring these two areas are off limits. The mass surveillance of Americans and fully autonomous weaponry. The US government, the Pentagon was not happy with that and threatened Anthropic with a punishment. Defense Secretary Pete Hexth is close to cutting business ties with Enthropic and designating the AI company a supply chain risk, meaning anyone who wants to do business with the US military has to cut ties with the company, a senior Pentagon official told Axios. Basically crippling Anthropic as a business if they don't abide by the Pentagon's demands that Enthropics AI presented to the military doesn't have the restrictions that Enthropic is proposing due to just ethical concerns. The way the Pentagon puts it is that the Department of War's relationship with Enthropic is being reviewed. Our nation requires that our partners be willing to help our war fighters win in any fight. Ultimately, this is about our troops and the safety of the American people. But what they're really saying is, I mean, this quote right here describes it aptly. Enthropic won't let us use our technology for mass surveillance of American citizens. So, we're designating them a national security risk, the US Department of War. I mean, that's pretty much what happened. But amidst all this, of course, AI companies are trying to present themselves under a positive light, which is why we're seeing reports that Google, Microsoft, OpenAI, Anthropic, and Meta are paying influencers between $400,000 and $600,000 each to promote AI products on Instagram and YouTube. when you have to resort to that to try to convince people that AI is good and ethical and that the technology is actually better and outputs great quality when currently all it outputs in the current state of things and in the current exploitative use of things is slop like that's when you know these companies are starting to get desperate and really want to make sure the adoption of AI technology is as vast as they wanted so they can make their money back because they've put too much money into this AI venture for them to not make any money off of this and if that were to happen, then guess what? That's

what we call a bubble bursting. And whether we're actually headed there or not, only time will tell. A lot of people are in the belief that the current state of AI, the current state of things, it feels like indications of some kind of big bubble being on its way to being burst, but only time will tell. But as far as OpenAI specifically is concerned, that is definitely a bubble that feels like it's about to pop. It feels like other companies are better positioned. though even for those companies there's just an insane amount of expense that has to happen that I don't know if it's ultimately sustainable for the next couple of years where they need to continuously expend dozens of billions and not make anywhere near the revenue that uh they need to make to build out the infrastructure to power the technology and those kinds of recurring costs are so incredibly expensive and all the while they're bleeding money and there's a lot of backlash and there's a lot of like uncertainty and ethical questions and all of it getting in the way of this being a technology that is just massaccepted and mass adopted. And with OpenAI specifically, aside from the fact that their financial position is extremely poor, they're starting to lose relationships with companies like Nvidia. And with Microsoft now kind of trying to become more autonomous and less dependent on Open AI. That puts OpenAI in an even more precarious position, especially with competition encroaching and surpassing Open AI in many ways. So, OpenAI is in serious trouble. It was before and it continues to be. And I'll be curious to see if OpenAI is somehow able to find a way around this or if this is a company that, as analysts predict, is doomed to run out of cash in the notsodistant future. But again, only time will tell. In the meantime though, this is kind of an overview of Open AI as a whole and the AI landscape in general. I'd love to hear what your thoughts and opinions are on the current state of AI and what you think prospects look like for OpenAI specifically. Share your thoughts in the comments below. And to be further updated on all things gaming news, reviews, and discussions, stay tuned right here on Yong. Yeah. I'll see you guys next time. Yong.