[00:00] Mental models are powerful. Some of the
[00:02] most successful people in the world
[00:03] swear by mental models. Mental models
[00:06] are basically simplified representations
[00:09] of how the world works. You take
[00:11] something really complicated, you
[00:13] simplify it into a framework that you
[00:15] can then use for decision-m and problem
[00:17] solving. For example, a mental model
[00:19] that I really love around decision-m is
[00:21] the expected value model. This model
[00:24] says that instead of thinking about
[00:25] decisions as being either good or bad
[00:27] decisions, you think about each decision
[00:29] as having a set of positive and negative
[00:33] consequences. That we should make
[00:34] decisions that give us a repeated high
[00:38] probability of winning on average over
[00:40] the long term rather than just oneoff. I
[00:43] think this is a great mental model. I
[00:45] use it all the time. I teach the
[00:46] professionals that I work with. It's
[00:47] such a useful model that it's become
[00:49] standard in a lot of fields revolving
[00:51] around decision-making and probability
[00:53] like trading and finance and
[00:54] professional poker even. So, in this
[00:56] video, I'm going to share with you six
[00:58] of my favorite mental models. But these
[01:00] aren't just regular models. These six
[01:03] are very special mental models. In fact,
[01:05] one of my favorite books of all time is
[01:08] probably this one. It's 50 models for
[01:11] strategic thinking. But here's the thing
[01:13] that I've observed after teaching mental
[01:16] models to so many people. What I've
[01:18] realized is that mental models are not
[01:21] enough. Regardless of the actual model
[01:24] that you use, the way that you apply
[01:27] your context and knowledge and situation
[01:30] to the model can make or break how
[01:34] effective it is. For example, I
[01:35] previously worked with this data
[01:36] scientist for this large e-commerce
[01:39] business and they were trying to make a
[01:40] decision about which email campaign to
[01:42] use. And so by looking at the past data,
[01:44] he estimated the probability of making a
[01:47] certain amount of money for each
[01:48] campaign and decided that campaign A is
[01:51] the one that has the higher probability
[01:53] of delivering higher profit than
[01:55] campaign B. So they went with campaign
[01:57] A. They lost a lot of money. The issue
[01:59] wasn't just luck. The issue was that the
[02:03] past data that he was looking at was in
[02:05] the holiday season and the way that that
[02:07] campaign performs in the holiday season
[02:09] was very different to how it performs in
[02:11] the off season. So even though he was
[02:13] applying this expected value model, he
[02:16] just missed an entire factor, an entire
[02:19] variable that would have changed his
[02:20] equation completely. This is actually
[02:22] the reason why he reached out to me in
[02:23] the first place because it seemed like
[02:24] an impossible problem. How do you know
[02:26] what you don't know? Yes, you've got a
[02:28] model. Yes, you have your knowledge. How
[02:30] do you know you're applying the model in
[02:33] the right way and you don't have gaps
[02:34] and blind spots? And so, this aspect is
[02:38] what I want to focus on in today's
[02:39] video. The six mental models I'm going
[02:42] to give you are not just regular models
[02:44] because they're what I call meta
[02:48] models.
[02:50] They are the mental models that you
[02:52] should apply whenever you use any other
[02:56] form of mental model. And the first meta
[02:58] model is called nonlinearity.
[03:04] In the example I gave before with that
[03:06] data scientist, the mistake he
[03:08] fundamentally made was that he believed
[03:10] that a certain campaign, so let's say
[03:12] this campaign is called A leads to a
[03:16] certain level of profit or a certain
[03:18] level of result whereas campaign B led
[03:20] to a different kind of result. And so
[03:22] this is an example of linear logic or
[03:25] linear thinking where we say A leads to
[03:28] result number one and B leads to result
[03:32] number two. But in real life
[03:33] relationships and logic is rarely
[03:37] linear. In real life it's not like this.
[03:39] It's more like A and B uh influence each
[03:44] other in the presence of C under the
[03:47] condition of D which also relates to E.
[03:50] And all of these things combined when
[03:52] going through F leads to a certain type
[03:54] of result. And so there is this uh
[03:57] incentive for our brain for the human
[04:00] brain to try to find simplicity to find
[04:02] the the easiest way to understand
[04:04] something. And it's very tempting to see
[04:07] relationships and logic as linear. But
[04:09] if this is the true nature of a
[04:12] relationship or a logic or how things
[04:13] actually work, then any attempt to turn
[04:15] this into something that's linear is
[04:17] actually going to be incorrect. And so
[04:18] the meta model of nonlinearity means
[04:21] that by default you should assume that
[04:23] relationships are not onetoone and
[04:25] linear. You should assume that anything
[04:27] that is complex and multiffactorial is
[04:30] nonlinear. And what that means is that
[04:32] when you're thinking about the decision
[04:33] or the problem, you actually want to
[04:35] catch yourself on linear thinking. So
[04:38] this is your your takeaway.
[04:44] First of all, detect and be wary of
[04:48] linear
[04:50] thinking patterns.
[04:54] As you're thinking through a problem or
[04:55] a decision to make, if you notice that
[04:57] you're thinking in a very linear way
[04:59] where there's a onetoone relationship,
[05:00] if I do this, it will lead to this.
[05:03] Whereas, if I do this, it will lead to
[05:05] this. If I want to achieve a certain
[05:07] result, I need to make sure I do this
[05:09] and then I do this and then I do this
[05:12] and then I do this. That kind of pattern
[05:14] of thinking is very fixed, rigid, and
[05:16] most likely inaccurate. So, catch
[05:18] yourself when you're thinking in this
[05:20] way and challenge yourself to think more
[05:23] nonlinearly. A great exercise for this
[05:26] is to actually try to map out the
[05:30] relationships
[05:32] between
[05:34] the different factors or the different
[05:37] variables as part of your problem or
[05:39] your decision. So a complicated decision
[05:41] or complicated problem is not
[05:43] complicated because the universe deems
[05:44] it so. It's because in order to achieve
[05:47] a certain result, there are so many
[05:50] different factors and these factors all
[05:51] relate to each other. It's this
[05:54] complicated web of interactions that
[05:57] makes something complicated or difficult
[05:59] in the first place. And so what some
[06:01] people will try to do is they'll say,
[06:02] well, it's so difficult to think about
[06:04] this. If I still want to achieve this
[06:07] result, the easier way is to just not
[06:10] think about this at all and instead
[06:12] oversimplify it with linear thinking.
[06:15] That is not going to be effective for
[06:16] guaranteeing your result, obviously. And
[06:19] if you fall into this trap, then of all
[06:21] the hundreds of different mental models
[06:23] that you could be using to solve a
[06:25] problem, you're not going to know which
[06:26] one is the most appropriate for this.
[06:29] You're going to think, "Hey, because
[06:30] I've simplified this issue, I can use
[06:32] this mental model and that gives me a
[06:34] nice clean result that I can feel good
[06:36] about." But maybe if you thought deeper
[06:37] about the problem, you'd realize that
[06:38] that mental model doesn't actually make
[06:40] sense in this context or it's it's being
[06:42] applied too forcibly. Maybe there's
[06:44] another model that you can use instead.
[06:46] Again, the mental model is there as a
[06:48] tool to help you to make this decision
[06:50] and to simplify something that's really
[06:52] complicated. But in order for that model
[06:54] to give us a useful output, it depends
[06:56] on the input we think is relevant to
[06:58] give it. So the activity of actually
[07:00] deliberately sitting there and mapping
[07:02] out all the different variables that we
[07:05] think create this complexity is an
[07:08] excellent exercise. So when you try to
[07:09] map out these relationships, the first
[07:12] step is just to list out every variable
[07:15] that you think just literally dump them.
[07:17] Dump them out. list out every factor and
[07:19] variable that you think could be useful
[07:21] and relevant in thinking about this
[07:22] problem. And then you just go through
[07:23] this list and try to see how these
[07:25] things influence each other, how they're
[07:27] connected. So in that marketing campaign
[07:29] example, maybe we've got some words like
[07:32] uh the type of audience,
[07:34] the timing or the seasonality of the
[07:37] campaign, the different channels of
[07:39] distribution, the actual content of the
[07:42] campaign itself, the offer and the
[07:45] perceived value of the campaign, the
[07:48] size of the audience.
[07:51] Okay, whereas this is like audience like
[07:53] demographics, maybe even like data
[07:55] attribution in terms of how good your
[07:57] data tracking is and how reliable your
[07:59] data is. So this might be a bunch of
[08:01] different words to represent the factors
[08:04] that make a decision about which
[08:06] campaign is going to be more profitable.
[08:07] And so as we look at this, there are
[08:09] lots of possible relationships like
[08:11] okay, well we know that the audience
[08:14] demographic resonates with a particular
[08:16] type of offer. But then also we know
[08:19] that the the timing and the seasonality
[08:22] also influences the perceived value of
[08:24] that offer. And also we know that the
[08:26] the the content of the campaign itself
[08:29] is going to frame that offer in a
[08:30] certain way. And the content obviously
[08:32] is depends on the timing and the
[08:34] seasonality. And this audience also
[08:36] exists within a certain type of channel.
[08:38] Like some people might be on emails
[08:40] whereas some people might be on Tik Tok
[08:42] versus some people might be on Facebook
[08:43] in terms of how profitable this entire
[08:45] thing actually is, which is the the
[08:48] point of this campaign. Well, that's
[08:49] also going to depend on the audience
[08:51] total size as well as well as the you
[08:53] know the quality of that audience and
[08:55] how much money that they have to spend.
[08:56] So this is just a very simple example
[08:58] just to show you you know this you can
[09:00] see that there's lots of different other
[09:02] ways that you could have arranged this.
[09:03] This is just one example. But then as
[09:05] you go through this uh just by going
[09:08] through this process of thinking about
[09:09] what's important and how it all relates
[09:11] together and uh what are the factors
[09:13] that influence the profitability you
[09:14] know we might realize hey we've actually
[09:16] completely forgotten about an entire
[09:18] variable which is you know the cost to
[09:21] run the campaign you know
[09:24] and then as soon as we add this
[09:25] additional word of cost in we might
[09:27] think okay well now that that also makes
[09:28] a difference because different channels
[09:30] have different costs and different
[09:31] audience demographics are more costly.
[09:33] to market to. And so we're now seeing
[09:35] the complexity of this decision. And
[09:38] when we get to so many arrows going
[09:40] everywhere, what happens is that we look
[09:41] at all of this and we say, okay, this is
[09:44] the result that we want. And this is all
[09:46] the stuff that makes it complicated.
[09:49] So the solution here is not to say,
[09:51] well, let's just ignore all of this
[09:52] because it's too hard to think about.
[09:54] It's to go through the process of trying
[09:56] to think about it so that we can gain
[09:58] more clarity and organization about this
[10:01] complex thing. Because as we think more
[10:03] about the complicated part, it helps us
[10:06] unwrap this
[10:08] and over time it becomes easier and more
[10:10] intuitive for us to understand and that
[10:12] is what contributes to the problem being
[10:14] actually solved and getting the result
[10:16] that we want. And the reason I recommend
[10:18] doing this mapping activity as a key
[10:20] takeaway to actually try to challenge
[10:23] yourself to do this and to feel that
[10:26] complexity and feel that mental burden
[10:28] is because if you're trying to make a
[10:30] complex decision or solving a complex
[10:32] problem and you don't see how the pieces
[10:36] fit together, you are going to have to
[10:38] pay the consequence of that through the
[10:40] quality of your decision-making. And
[10:42] again, this is basically an expected
[10:44] value thing. You may get lucky. You may
[10:46] be able to ignore that and make a
[10:48] certain decision and you get lucky with
[10:50] that decision one or two times. But if
[10:52] you continuously make decisions and
[10:55] solve problems in that way, ignoring the
[10:57] complexity and oversimplifying things,
[10:59] your luck will eventually run out. And
[11:01] especially if the decisions you're
[11:02] making are important and costly, it only
[11:05] takes two or three times of getting a
[11:08] negative result to undo all the
[11:10] positives that you've stacked up
[11:12] previously. It is much faster and
[11:15] cheaper to get feedback on how good your
[11:19] decision is likely to be by doing this
[11:22] activity and seeing how much you
[11:24] struggle. If you struggle with mapping
[11:27] things out and seeing how it all fits
[11:29] together, it means it's not organized in
[11:32] your brain. It means you don't really
[11:33] understand how it all connects. If you
[11:36] did really understand it, you would find
[11:37] this easy to do. And when someone is
[11:39] feeling overwhelmed with a decision,
[11:42] overwhelmed with a problem, they're not
[11:44] sure where to start. There are all these
[11:45] different moving pieces. They all relate
[11:47] to each other in complicated ways. They
[11:49] don't know what to prioritize. They
[11:51] don't know how to make that decision. I
[11:52] can guarantee in every single one of
[11:55] those instances, that person is going to
[11:58] struggle to map things out. And when you
[12:00] sit down and force yourself to address
[12:02] that weakness head on, that is when you
[12:06] start creating clarity of your
[12:08] decision-making process, that is what
[12:10] allows this complicated problem to be
[12:12] broken down into simpler components. So
[12:15] just remember, linear thinking is an
[12:19] illusion. That's your brain looking for
[12:20] a shortcut, probably not accurate.
[12:23] Nonlinear relationships, that's the
[12:26] truth. That's reality. If you struggle
[12:28] thinking in terms of the reality, the
[12:30] question that's left for you is are you
[12:32] willing to either take the risk of being
[12:34] wrong, which might be okay in some
[12:37] situations, or would you rather do the
[12:40] hard work of trying to organize it and
[12:44] gain clarity. So that's the first meta
[12:46] model, nonlinearity. And so you can see
[12:48] what I mean is that any framework you
[12:51] use, any mental model you use, when you
[12:53] think about how am I going to apply my
[12:55] context and my knowledge and my
[12:57] situation to this mental model, you need
[12:59] to be starting from a position where you
[13:01] recognize the nonlinearity
[13:03] of what's going on. Otherwise, the way
[13:05] you use that mental model is going to be
[13:06] wrong. And the next mental model is very
[13:08] similar to this idea of nonlinearity. It
[13:11] is the idea of gray thinking. When I
[13:15] work with software engineers, especially
[13:17] tech leads, one of the biggest problems
[13:19] that they face is uh whether to move
[13:21] fast or to maintain quality. So when you
[13:24] move fast and you're pushing out new
[13:26] features all the time, it increases the
[13:28] error rate and there's lots of other
[13:30] things and technical debt that builds
[13:31] up. Whereas if you're trying to maintain
[13:32] quality, it reduces your agility and it
[13:35] means that you can't, you know, develop
[13:36] new features as quickly and that could
[13:37] impact the the overall business. And so
[13:39] to resolve this, some mental models that
[13:42] a senior software engineer might use
[13:44] could be around the decision of should
[13:46] we move fast or should we maintain
[13:49] quality? And there are lots of
[13:50] frameworks and mental models that they
[13:52] might use to balance that decision. But
[13:54] in actual fact, those models would be
[13:57] incorrect. It would be wrong to use
[13:59] those models because that's an example
[14:00] of falling into the trap of black and
[14:03] white thinking as opposed to gray
[14:05] thinking. Black and white thinking is
[14:07] saying that it's either A or B. That
[14:11] these two things are polar opposites and
[14:14] mutually exclusive of each other. And
[14:16] just like how it's very rare for things
[14:18] to have a onetoone linear relationship
[14:20] like over here, it's very rare in real
[14:22] life for things to be so black and
[14:24] white. Most things are on a continuous
[14:28] scale. And most of the best solutions
[14:30] are in the gray area in between. By the
[14:33] way, I know someone's going to comment
[14:35] this. It's spelled G R A Y versus G R E
[14:38] Y depending on which country you live
[14:40] in. So going back to that software
[14:42] example, you can move fast with good
[14:45] deployment pipelines and QA processes
[14:47] while maintaining quality. You can
[14:49] strike a balance of both of those
[14:51] things. And so you can see when you
[14:53] start thinking in terms of the gray, it
[14:55] means that other types of mental models
[14:57] may be more suitable. The problem is not
[14:59] should we maintain quality versus should
[15:01] we go fast. It is understanding what
[15:04] parts of going fast lead to the
[15:06] reductions in quality. How can we
[15:08] maintain quality in a lean agile way
[15:11] without sacrificing speed? What are some
[15:13] models of thinking that allow us to
[15:16] increase speed and increase quality? And
[15:19] the reason we are biased towards black
[15:21] and white thinking by default is very
[15:24] similar reason to why we're biased
[15:25] towards linear thinking by default as
[15:27] well is that it's a cognitive shortcut.
[15:29] In fact, not just a cognitive shortcut,
[15:31] a cognitive emotional shortcut. It is
[15:33] much simpler. It's much easier. It's
[15:35] much less overwhelming to assume and
[15:37] say, "Hey, this really complicated thing
[15:39] with all these different factors that
[15:40] come together, it's a onetoone linear
[15:43] relationship." Likewise, it's the same
[15:46] thing to say, "Hey, this really
[15:48] complicated decision, it's easier to say
[15:50] it's either A or it's either B." It
[15:52] simplifies our decision. It creates an
[15:55] illusion of simplicity, but it does so
[15:58] using what's in in in logic and
[16:00] reasoning studying uh is called a false
[16:03] dichotomy.
[16:09] A dichotomy is when we see things as as
[16:12] two different things. And a false
[16:13] dichotomy is saying we've basically
[16:15] split aside uh two different factors as
[16:18] being mutually exclusive from each other
[16:20] when actually they don't have to be. And
[16:21] so the takeaway for this
[16:26] is in a similar way, catch yourself on
[16:31] black and white thinking.
[16:34] And the best part about this is that you
[16:36] don't actually have to understand the
[16:38] gray first. It's enough to recognize the
[16:41] red flag of something being very black
[16:43] and white. And the best example that I
[16:45] can think of off the top of my head is
[16:47] actually uh a conversation pretty
[16:48] recently that I had with our very own
[16:50] YouTube strategist Anv uh who's actually
[16:52] going to be reviewing this video. So,
[16:54] hey, Anv. And I remember a conversation
[16:56] where we're talking about uh different
[16:58] things in terms of uh creating content
[17:00] and and there's lots of different
[17:01] nuances in terms of creating content and
[17:03] educating at scale. And we were talking
[17:05] about this problem of how do you create
[17:06] content that really resonates with
[17:08] people that they can relate to when
[17:10] people are so diverse, they come from so
[17:12] many different backgrounds. Do we create
[17:13] content that is broadly resonant with
[17:16] many people but is pretty superficial or
[17:19] do we create content that is deep and
[17:21] nuanced but it only resonates with a a
[17:23] small percentage of the population and
[17:24] what he said at the time was I don't
[17:27] know the right way to think about this
[17:28] but I recognize that the way that I'm
[17:32] seeing this is very black and white
[17:34] which is usually not true for anything I
[17:37] really understand properly. So it
[17:39] probably means that I need to think
[17:41] about this more. And I think that is a
[17:43] perfect example of catching yourself on
[17:45] black and white thinking and going
[17:47] towards the gray. And you can probably
[17:49] feel this yourself is that when you
[17:51] think about stuff that you really know a
[17:53] lot about, there are not that many black
[17:56] and white statements that you would be
[17:58] able to make about it. And so if there
[17:59] are things that you're tackling,
[18:01] problems and decisions that you have to
[18:02] make at work that the way you're
[18:04] thinking about it, you may feel very
[18:06] confident. But if the way you're
[18:09] thinking about it is also quite black
[18:10] and white, then for me that is always uh
[18:13] a warning sign. That's always a red
[18:15] flag. It doesn't mean you're wrong, but
[18:17] you should explore it. And when you're
[18:18] in that situation and when you realize,
[18:20] hey, I might be doing some black and
[18:22] white thinking. The second takeaway is
[18:24] actually just to do more of this.
[18:25] Engaging in nonlinearity
[18:28] helps you to identify different factors
[18:30] and variables that you might have been
[18:31] missing before and show you where a gray
[18:34] solution might exist. Now, at this
[18:36] point, if you've been listening
[18:36] attentively, the question that's
[18:39] probably in your head right now is this
[18:41] is all really useful so far, and I'm
[18:43] finding this really insightful. I wish
[18:45] I'd known this sooner.
[18:47] Why didn't I know this sooner? And in my
[18:50] experience, nine out of 10 times, the
[18:51] reason that you didn't know this is
[18:53] because you're not signed up to my
[18:54] newsletter. For those of you that don't
[18:56] know, I have a free weekly newsletter
[18:58] that I send out. I write them myself
[19:00] where I think about all the different
[19:02] models, the meta models, the insights,
[19:04] the principles that I think would really
[19:05] help you learn more efficiently and also
[19:08] manage yourself more efficiently. All
[19:09] the things that you need to be a
[19:12] well-rounded, effective professional.
[19:14] These are things that I've distilled
[19:15] from my years of working with so many
[19:17] people. And each of these newsletters
[19:19] could probably be its own YouTube video.
[19:22] So, if you found this video useful so
[19:23] far, then I'm sure you're also going to
[19:25] love my newsletter. Again, it's totally
[19:27] free. It takes a few minutes to read. If
[19:28] you're interested in signing up, I'll
[19:29] leave a link to that in the description
[19:30] below. Now, the third meta model is
[19:34] what I call AAM's bias. Now, there's
[19:39] this thing which you may have heard of
[19:40] called AAM's razor. I first learned
[19:43] about this in medicine. Okam's razor
[19:46] says that the simplest explanation is
[19:49] probably the right one. So, if someone
[19:51] comes in and they've got all these
[19:52] different types of symptoms, like
[19:54] they've got a headache and they've got a
[19:55] fever and they've got a cough and they
[19:57] were sick before and they've got this
[19:58] rash all over their body and they're
[20:00] finding it hard to breathe. It's more
[20:02] likely that there's one disease with all
[20:06] of these symptoms rather than like five
[20:08] different diseases occurring
[20:09] simultaneously. It's named after William
[20:11] of Okam who was this 14th century
[20:14] philosopher and it's called Okam's razor
[20:17] uh because the term razor apart from
[20:19] meaning like a blade in logic refers to
[20:23] a tool which cuts away unnecessary
[20:28] possibilities to make decisions easier.
[20:30] So another razor is called Alder's razor
[20:33] uh which is also called Newton's flaming
[20:36] laser sword which states that if
[20:38] something cannot be settled through
[20:41] experimentation and observation then
[20:43] it's not worth debating. It basically
[20:44] means that this is going to be a a
[20:46] futile endless debate that no one can
[20:48] really prove. And so AAM's razor is
[20:50] really good because it forces you to be
[20:54] consilient in the way that you look at
[20:56] evidence. It means that if there's lots
[20:57] of different factors that are popping
[20:59] up, don't just say, "Hey, there's lots
[21:01] of individual things." It kind of forces
[21:03] a level of nonlinearity,
[21:05] which is a good thing. And it says,
[21:06] "Find the underlying cause that ties all
[21:09] of it together." You're sort of like a
[21:11] detective doing like a murder mystery
[21:12] with all the like the crazy photos and
[21:14] the string corkboard thing going on the
[21:16] wall. But I'm not talking about AAM's
[21:18] razor. I'm talking about AAM's bias. I
[21:21] call it Okam's bias because this is what
[21:24] I see happening when people use Okam's
[21:26] razor too aggressively. And the issue I
[21:29] see is people doing over attribution
[21:36] where they see all these different
[21:38] symptoms and then they force it to fit a
[21:42] single cause because that's the simplest
[21:44] explanation. And so this can actually be
[21:46] really dangerous because it may not be
[21:49] all caused by the same thing. For
[21:51] example, when I was working in the
[21:52] emergency department, people come in for
[21:54] heartburn, stomach pain all the time,
[21:56] like every single day, dozens of people.
[21:58] And when you're assessing someone that's
[21:59] coming in for like heartburn or stomach
[22:01] pain or something like that, you always
[22:03] have to be careful of diagnosing all of
[22:06] that as gastritis or reflux because what
[22:09] it could also be is a heart attack. Pain
[22:13] occurring here is not so far from pain
[22:15] occurring here. And every doctor has
[22:18] heard horror stories of having a patient
[22:21] assessing them as having just like a
[22:23] pretty benign, you know, acid reflux or
[22:26] heartburn issue, but then it turned out
[22:27] to be an underlying, you know, heart
[22:29] problem. But the thing is that there is
[22:32] a temptation to just say, "Yes, this is
[22:35] just heartburn. It's just acid in your
[22:38] stomach. Nothing to worry about."
[22:40] Because working someone up and and
[22:42] investigating them and treating them for
[22:45] a heart problem is much more
[22:47] complicated. It requires a lot more
[22:49] work. And when you're a busy doctor
[22:50] working in emergency, you've already got
[22:52] endless amounts of work. You want to
[22:54] make life easier for yourself. And it's
[22:56] the same thing outside of the emergency
[22:58] department. In any profession, you don't
[23:00] want to give yourself more work by
[23:02] turning something that could be simple
[23:04] into something that is unnecessarily
[23:06] complicated. But we have to understand
[23:08] the risk that oversimplifying could lead
[23:11] to error in medicine. Actually, this is
[23:14] such a big problem that not only is this
[23:16] issue like drilled into us constantly
[23:19] during medical school and in our
[23:20] training to make sure we don't make this
[23:22] mistake and we still make this mistake,
[23:24] it's actually got its own term which is
[23:26] called Hickham's dictim which basically
[23:29] came around in medicine to counter AAM's
[23:32] razor. While Okam's razor says that the
[23:35] simplest explanation for all these
[23:37] symptoms is probably the most accurate,
[23:39] Hickham's dictim says verbatim, patients
[23:43] can have as many diseases as they damn
[23:46] well please. It states that reality
[23:49] doesn't owe it to you to be simple. How
[23:52] easy or difficult it is for you to
[23:55] understand doesn't matter. And so here's
[23:57] the takeaway for you to avoid
[24:01] AAM's bias is first of all be aware of
[24:05] the cost of simplification.
[24:11] Whenever you're simplifying an issue and
[24:13] there's lots of different components and
[24:14] you're trying to find, you know, one way
[24:16] to attribute all of those things to
[24:18] progress on your problem or your
[24:19] decision, remember that any step of
[24:22] simplification increases the risk of
[24:24] some kind of error. you're losing some
[24:27] level of detail every time you simplify.
[24:30] Sometimes those details don't matter.
[24:31] It's just noise that's preventing you
[24:33] from making a good decision. But
[24:34] sometimes those details are crucial.
[24:37] What's important is not to just say
[24:39] don't simplify ever because that's going
[24:42] to slow down your your pace of execution
[24:44] too much. Simplification is a cognitive
[24:47] shortcut and cognitive shortcuts are not
[24:48] always a bad thing. What's important is
[24:50] to recognize the cost of that shortcut.
[24:53] What risk are you now exposing yourself
[24:56] to by having simplified it in a certain
[24:59] way? Which factors are you choosing to
[25:01] remove? And again, if you haven't done
[25:03] this nonlinearity piece, it becomes
[25:06] really hard to do this because you're
[25:07] not even aware of what you're losing.
[25:10] All you're doing is you're taking what
[25:11] is a vague sense of overwhelm and you're
[25:15] turning that into something that feels
[25:16] simple. You have no concept of the risk
[25:18] you're exposing yourself to. And this
[25:20] ties into the the second part, which is
[25:22] when you are simplifying something,
[25:26] be mindful. Are you simplifying it
[25:28] because you just you're lazy or you just
[25:31] can't be bothered? Or are you
[25:33] simplifying things to reduce the amount
[25:35] of noise? Simplifying things to reduce
[25:38] the amount of noise and make a better
[25:39] decision is a good thing. Simplifying
[25:41] because you just can't be bothered or it
[25:43] takes too long or it's just too hard to
[25:45] think about how it all connects together
[25:47] is not useful. You can get to a point
[25:49] where you see how everything comes
[25:51] together and you know what's important
[25:53] and how these different factors
[25:55] influence each other and make the
[25:57] educated decision to remove some of
[26:01] those variables because you don't think
[26:02] it's going to be important and now you
[26:04] create a simplified representation of
[26:05] the problem that you can now put into
[26:07] the appropriate mental model so that you
[26:10] can work through that framework and come
[26:11] to a decision or solve that problem. Now
[26:13] that's very different to again that
[26:15] feeling of overwhelm. This is very vague
[26:18] concept that there are lots of things
[26:20] going on and because I want to make it
[26:22] simpler, I'm just going to only focus on
[26:24] the parts that I immediately am aware of
[26:26] and find intuitive which again reality
[26:29] does not owe it to you to fit what you
[26:32] think is intuitive. Now, when you do it
[26:33] the first way and you see generally how
[26:36] it connects together, you've done like
[26:38] sort of this nonlinear map, you may
[26:40] still be wrong. You may decide to cut
[26:42] away factors that you don't think are
[26:43] important and then you run your
[26:44] experiment. you you get your data and
[26:46] you find hey actually that was important
[26:49] you it doesn't mean that you are
[26:51] guaranteed to be in the the most optimal
[26:54] place every single time but again it's
[26:56] about the expected value there is a
[26:58] higher probability that you're going to
[27:01] mitigate huge risks there is a higher
[27:05] probability that you're going to get the
[27:06] result that you want when you make
[27:08] decisions in this way and you approach
[27:09] problems in this way consistently over
[27:12] time you're more likely to win whereas
[27:14] If every time you're faced with
[27:15] something that feels overwhelming, your
[27:17] response is to oversimplify it by just
[27:20] cutting away everything else and not
[27:22] thinking about it over time, you're
[27:24] likely to lose. And I'll give you a
[27:25] little pro tip for this one. And this
[27:27] this can be your third takeaway is learn
[27:30] to be okay with black boxes. Black boxes
[27:35] are basically areas of uncertainty,
[27:37] things that you don't really know how it
[27:39] all works, how it all fits together. you
[27:40] know that there's this sort of clump of
[27:43] of concepts that relate to each other
[27:44] and it's pretty complicated and you
[27:46] don't really want to dive into it. Even
[27:47] if you can't explore that, you might not
[27:49] have enough time. It might be too
[27:51] complicated. There is a big difference
[27:52] between seeing the black box,
[27:55] appreciating and recognizing that it's
[27:57] there and then making a decision versus
[28:00] ignoring the black box, not even knowing
[28:02] which variables or factors you might be
[28:04] missing. The difference is that when you
[28:06] make your decision, when you solve the
[28:08] problem and you get real world data and
[28:10] feedback on how effective it was,
[28:13] whether you got the actual result at the
[28:16] end of the day, when you get this
[28:18] feedback coming back to you, if you knew
[28:20] that there is this black box part of the
[28:23] process that you didn't quite figure
[28:24] out, you can turn to that black box and
[28:26] say, "Okay, maybe I need to dive into
[28:28] that a little bit more. Maybe this part
[28:30] that I thought wasn't important actually
[28:32] is more important than I thought. So now
[28:33] it's worth my time to explore that
[28:36] because I need the result. Whereas if
[28:38] you didn't even do that level of
[28:39] thinking, you're not even aware of that
[28:41] black box. You get this result that you
[28:43] didn't expect that is not desirable and
[28:45] then you don't know what to do with
[28:46] that. You're not learning from that
[28:47] experience. It prevents you from being
[28:49] able to think and process failures and
[28:52] data points in a productive way, which
[28:55] significantly slows down how fast you're
[28:57] able to iterate and learn from that
[28:58] experience. So that's AAM's bias. See
[29:01] reality for what it is. Don't simplify
[29:03] things just to make it easier for
[29:05] yourself and then expose yourself to to
[29:08] tons of risk. Now, one of the most
[29:09] common reasons that I see people
[29:11] oversimplifying things in a way that is
[29:14] inaccurate and not catching themselves
[29:16] on the fact that this is an
[29:17] oversimplification is this fourth meta
[29:20] model, which is framing bias. I'm just
[29:25] noticing that my S's just look like
[29:27] backwards C's. But if you zoom in
[29:29] enough, you can see that there's a
[29:32] little squiggle there. So that's an S.
[29:36] Anyway, I want you to remember this
[29:38] statement. Just because it's logical
[29:42] doesn't mean it's right. Information can
[29:45] be organized. Problems and situations
[29:48] can be categorized in any number of
[29:51] different ways. And sometimes that way
[29:53] that you categorize it is not only
[29:55] logical, it's also practical and
[29:57] effective. The issue, and this is what
[30:00] framing bias is about, is that the way
[30:03] you think about a problem or a situation
[30:06] or a decision you need to make shouldn't
[30:08] be restricted to the way that it was
[30:12] presented to you, the way someone else
[30:15] organizes something, the way someone
[30:18] else categorizes something. If someone
[30:20] presents something to you in a way
[30:21] that's like here's A, then B, then C.
[30:24] When you first consume that, it may feel
[30:26] very logical to think about it in that
[30:28] way, but you have to have the cognitive
[30:30] flexibility to recognize that that may
[30:33] not be the best way to think about it.
[30:35] And in many situations when there is an
[30:37] existing problem and lots of people are
[30:39] thinking about it in a certain way and
[30:40] finding it difficult, the way to break
[30:42] through that problem is to frame that
[30:45] problem differently. the ability to
[30:47] break free of existing structures and
[30:50] ways that people tend to think about
[30:52] something and having that flexibility to
[30:55] see things laid out and organized
[30:57] differently creates immense value in the
[31:00] professional world. This is what I was
[31:01] saying at the very beginning is that the
[31:03] difference between a great worker uh and
[31:05] a great thinker versus someone who's
[31:08] just average is not really about what
[31:10] they know. At a certain point, everyone
[31:12] knows enough. The difference is the
[31:14] person that knows how to think about a
[31:17] problem in a different way. So simply
[31:19] put, framing bias is when
[31:23] the way information is presented
[31:28] to us
[31:30] changes the way
[31:32] so changes how we think about that
[31:37] information. So if I say here's a
[31:40] problem, here's a situation. It's
[31:41] basically A and B and we need to get to
[31:44] C. And so you say, okay, there's A,
[31:46] there's B and we need to get to C. Cool.
[31:48] And if that's the only way you think
[31:50] about this problem, you are likely to
[31:52] run into framing bias because perhaps
[31:54] actually the true solution is to say,
[31:56] well, hold on. You've said that it's A
[31:58] and B. But to me, A and B actually sound
[32:00] like the same thing. And it feels like
[32:02] there's something else that leads to C,
[32:04] which is this other thing, D. So, isn't
[32:06] it perhaps A plus B being one thing with
[32:10] D leading to C? Isn't this the right way
[32:13] to think about it? And the situation I
[32:14] see this all the time, the most common
[32:16] by far are technical disciplines where
[32:20] there's usually lots of different
[32:21] information and there are existing
[32:23] frameworks and models on how to think
[32:25] about things. And these frameworks and
[32:26] models tend to be very utilitarian.
[32:29] They're very practical. They allow you
[32:30] to have these cognitive shortcuts that
[32:32] you need to use every single day. So
[32:34] these existing frameworks exist exist to
[32:36] speed things up. So in medicine a really
[32:38] common framework that people think about
[32:41] all diseases through is what's the
[32:43] history? What do people say when they
[32:45] come in as a patient? What are the signs
[32:47] and the symptoms? What are the
[32:48] investigations like the blood tests and
[32:50] the the x-rays and the CTS that you can
[32:52] do? What would you find there? And then
[32:54] what is your treatment? Sometimes you
[32:55] divide that treatment into what do you
[32:57] do acutely right now versus what do you
[32:59] do chronically. 90% of every single
[33:01] disease can be categorized through that
[33:04] framework and 90% of the time when
[33:06] you're learning these diseases you're
[33:07] learning it through that flow. The same
[33:09] thing is is common with uh software
[33:11] engineering where there's an existing
[33:13] software development life cycle. There
[33:15] are existing frameworks. So when people
[33:16] think about problems with software, they
[33:19] think about it through this framework of
[33:20] the software development life cycle. But
[33:23] the thing we have to recognize is that
[33:24] if there's a specific problem you're
[33:25] solving or decision that you need to
[33:27] make that's particularly complicated,
[33:29] it's not likely that that framework that
[33:32] exists and you're familiar with is
[33:35] created with this type of problem
[33:37] solving or decision-m in mind. This was
[33:40] created for an entirely different
[33:42] purpose. And so if the way you're
[33:43] thinking about this problem is using
[33:46] this method of thinking, there's going
[33:48] to be misalignment and it's going to be
[33:50] really hard for you to do the
[33:51] nonlinearity and seeing the reality for
[33:54] what it is when you're locked into
[33:56] seeing it through a different pattern.
[33:58] It's going to feel very forced like it
[34:00] doesn't quite all connect together. And
[34:02] again, reality is your benchmark.
[34:04] Reality tells you the truth. If you're
[34:06] thinking about a problem in a certain
[34:07] way and it doesn't fit, the issue is the
[34:09] way that you're thinking about it.
[34:11] That's the part that needs to change.
[34:12] You can't manipulate reality in order to
[34:16] make it fit the way that you need it to.
[34:17] And so this is crucial because the way
[34:20] that you think about a problem or a
[34:22] situation is 90% of the battle. A lot of
[34:24] time is wasted and lost on just trying
[34:26] to figure out the right way to break
[34:29] down a complicated situation. And a lot
[34:31] of mistakes come from not having thought
[34:33] about it in the right way to begin with.
[34:36] applying the wrong mental model or
[34:38] applying a mental model and missing some
[34:40] of those factors. Again, it's not the
[34:41] lack of a mental model. It's the lack of
[34:44] the meta model that teaches you how to
[34:46] use the right model in the right way.
[34:49] And a really famous example of uh people
[34:53] overcoming the framing bias, allowing
[34:55] them to switch mental models and create
[34:58] enormous value is actually in Toyota. So
[35:01] if you weren't aware in the ' 50s and60s
[35:04] Toyota started really making a name for
[35:06] themselves in really highquality
[35:09] efficient production line like
[35:11] manufacturing. There are a lot of
[35:12] quality control and efficiency practices
[35:15] used in all sorts of industries around
[35:16] the world today that originated from
[35:19] Toyota in the ' 50s60s and 70s. And one
[35:21] famous example is the Toyota Anden cord
[35:24] system. Back in the 50s, the prevailing
[35:27] assumption, the frame that people were
[35:29] taught about manufacturing is that
[35:31] efficiency is keeping that production
[35:33] line moving as much as possible.
[35:35] Anything that stops the production line
[35:37] creates inefficiency. And so a lot of
[35:39] the models around increasing efficiency
[35:41] were how do you log and document
[35:43] failures and inconsistencies in your
[35:45] production line so you can go back and
[35:46] fix it? How do you make the logging
[35:48] faster for the workers? How do you make
[35:50] it more accurate? How do you uh you know
[35:52] bring people in to diagnose what the
[35:53] issues are and then when do you take
[35:55] time to improve those processes and
[35:56] repair them? And so what Toyota did
[35:58] differently is that they broke out of
[36:00] that framing bias and they said well
[36:02] what if efficiency doesn't come from
[36:05] never stopping the production line. What
[36:07] if efficiency comes from constantly
[36:09] learning? And they did the exact
[36:10] opposite. They gave workers the ability
[36:14] at any point for any worker to pull the
[36:17] and cord which stops the entire
[36:20] production line. As soon as a worker on
[36:22] the ground level saw an issue, they
[36:24] would pull the cord. The supervisors
[36:25] would come in, the technicians would
[36:26] come in, they diagnose the issue. They
[36:29] they had improved the process
[36:30] immediately. And as a result, their
[36:32] production process was able to increase
[36:34] in efficiency much more quickly and
[36:36] iteratively than than the traditional
[36:38] manufacturing model. In fact, this
[36:40] principle ended up becoming one of the
[36:42] core pillars of the lean manufacturing
[36:45] revolution of the 80s that a lot of
[36:47] manufacturers in the western worlds
[36:49] would start studying to improve their
[36:50] own processes. And so that all comes
[36:52] from being able to escape this framing
[36:54] bias. So here's a takeaway for you for
[36:57] this, which is to actively
[37:01] reframe.
[37:03] There's always more than one way to see
[37:05] a situation. If you can only think of
[37:08] one way where it makes sense and it
[37:10] intuitively fits in, you're definitely
[37:12] missing a perspective. There's always a
[37:14] different way to see it. So your job is
[37:16] to find that way. Now it doesn't mean
[37:18] that the other way of looking at it is
[37:19] better. But it is faster and cheaper to
[37:23] go through the thought process, figure
[37:25] out those other ways of thinking about
[37:27] it and evaluate which perspective, which
[37:31] frame of thinking about this problem is
[37:32] the most productive for me, rather than
[37:34] taking the easy way out and saying,
[37:36] "Well, it makes sense the way that it
[37:38] was presented to me. It feels logical,
[37:40] so I'm just going to stick with this."
[37:42] And then potentially missing the real
[37:44] game-changing perspective. And I'm
[37:46] saying actively reframe because it is an
[37:49] active process. You when when someone
[37:53] unless it already is like really
[37:55] disorganized and you have no idea where
[37:57] to start. If it's presented to you in a
[37:59] way that's like here's how you should
[38:00] think about this problem A, B, and C and
[38:02] it feels logical and it feels intuitive.
[38:04] You're not going to feel the need to
[38:07] reframe that problem. You're not going
[38:09] to feel the need to challenge yourself.
[38:10] It feels like unnecessary extra work
[38:13] that you're giving. But when you get
[38:14] into the habit of constantly trying to
[38:16] reframe the information and seeing
[38:18] different ways that it comes together,
[38:20] this process not only is valuable and
[38:22] deepening your thought and helping you
[38:24] arrive at innovative really highquality
[38:27] solutions and decisions, but also that
[38:29] process starts getting easier for you.
[38:30] So it's not all this extra work. It
[38:33] might be at the beginning, but once you
[38:34] get used to it, it's as easy as just
[38:36] thinking about anything else. And in
[38:38] short, what that means is that by
[38:39] getting used to these meta models of
[38:42] thinking, you are getting used to being
[38:45] excellent, which is kind of the point of
[38:48] the next meta model, which is the
[38:51] anti-comfort
[38:54] model. There's this other great book
[38:57] called anti-fragile
[38:59] by the legendary Nim Nicholas Taleb. And
[39:03] what he talks about is this idea of
[39:05] systems and processes that are fragile.
[39:07] So that means that when things change,
[39:10] they get worse. And then he talks about
[39:12] systems that are resilient. Supposedly
[39:14] the opposite of fragile. So when
[39:16] something is resilient, when things
[39:18] change, it doesn't get worse. It's able
[39:20] to withstand that change. But then he
[39:22] talks about the idea of something that's
[39:24] anti-fragile,
[39:26] which is something that when things
[39:28] change, it gets better. The thing that
[39:30] creates instability and concern for
[39:33] fragile systems and the thing that puts
[39:35] pressure on resilient systems, an
[39:38] anti-fragile system thrives from it. And
[39:41] this is the same idea with anti-comfort.
[39:43] When something is comfortable, it means
[39:45] that we're used to it. We're familiar
[39:47] with it. It's easy for us to think in a
[39:50] way that's comfortable. If there's a
[39:52] problem that we have at work, if there's
[39:54] a complex situation or a decision that
[39:55] we need to make and we're thinking about
[39:57] it in a way that feels comfortable for
[39:59] us, what it means at a cognitive level
[40:01] is that we're using patterns of thinking
[40:04] that we're used to. We're relying on
[40:07] existing habits and patterns of problem
[40:09] solving and organizing information that
[40:11] we have experience with. Now, if someone
[40:13] is uncomfortable with a problem or a
[40:16] situation, they're feeling overwhelmed.
[40:18] They're seeing all of these different
[40:20] factors and then they're feeling there's
[40:22] too much. I I don't know what to do with
[40:24] all of this information. They want to
[40:25] retreat away. An anti-comfort
[40:29] mindset. This meta model is talking
[40:31] about actively looking for ways to make
[40:35] yourself feel less comfortable. It's
[40:38] going from feeling familiar with the
[40:41] patterns of thinking, having a way of
[40:43] approaching a problem or a decision that
[40:45] you feel pretty comfortable with, and
[40:47] then actively looking for reasons why
[40:50] you're wrong. The idea is that you are
[40:53] wary, you're cautious of that feeling of
[40:56] comfort because it means that there
[40:58] could be a blind spot that you're
[40:59] unaware of. I guess that's what a blind
[41:03] spot is. And so in short, we can say
[41:05] that an anti-comfort approach means that
[41:07] you are looking for
[41:10] your gaps.
[41:13] You're asking yourself, "What have I
[41:16] missed?
[41:17] What could make me
[41:22] wrong?"
[41:24] You want to feel a little uncomfortable
[41:26] when you're too comfortable. And this is
[41:28] hard to do because it there's there's
[41:30] emotion tied into it. You don't want to
[41:31] give yourself more work like we talked
[41:32] about. But an anti-comfort mentality
[41:34] means that you are more committed to
[41:36] getting the result that you want than
[41:38] how you feel about the process of
[41:40] getting to this result. You're willing
[41:42] to accept discomfort in exchange for a
[41:44] better result. And so the takeaway to
[41:46] this is is is really simple
[41:49] because the takeaway to this one is just
[41:52] do all this stuff. Do all of this. Use
[41:55] these other models. Trying to use these
[41:58] meta models whenever you're working
[42:00] through a framework and thinking about a
[42:02] problem is uncomfortable and it's going
[42:04] to make you look at that feeling of
[42:06] overwhelm and say, "Hey, what are you
[42:09] why am I overwhelmed? What is it that I
[42:11] do not know that is making me feel like
[42:14] the pieces don't fit together?" And so
[42:16] merely the commitment to apply these
[42:18] meta models means that you are taking an
[42:20] anti-comfort approach. And to anchor
[42:22] this in in terms of why it's so worth it
[42:24] to do this is actually the final meta
[42:27] model which is the model of delayed
[42:32] discomfort.
[42:35] There's this concept I talk about a lot
[42:36] called desirable discomfort. It's saying
[42:39] that just because something is
[42:40] uncomfortable doesn't mean that that is
[42:42] a bad thing. Whether something is bad or
[42:44] not is your interpretation of that
[42:46] feeling. But discomfort is just a
[42:48] sensation like the the breeze against
[42:50] your skin or you know smelling some kind
[42:52] of food. It's just a sensation that
[42:53] you're noticing. When we tell ourselves
[42:56] this is a bad thing, that can sometimes
[42:58] be a barrier to growth and improvement.
[43:00] When we're engaging in a hobby or a fun
[43:02] activity that is that's mentally or
[43:04] physically challenging that is creating
[43:07] discomfort, but we we interpret that as
[43:10] being fun and worthwhile. And sometimes
[43:12] there are things that are worthwhile
[43:14] that create discomfort that we interpret
[43:16] as being bad. Learning is a great one
[43:18] where there's lots of studies that have
[43:20] been done around how people
[43:21] self-regulate their learning strategies
[43:23] which has found that when learning and
[43:25] using a certain strategy feels difficult
[43:28] and feels like it involves more mental
[43:32] work and thinking, people think that
[43:34] that means that this strategy is not
[43:36] effective and so they stop using it. But
[43:39] actually what's clear is that the most
[43:41] effective learning strategies force you
[43:44] to think more deeply. And so in that
[43:46] case that is desirable difficulty. You
[43:49] actually want your brain to be thinking
[43:51] more deeply because that produces a
[43:54] better result. Now an issue with the way
[43:56] that I've seen a lot of people interpret
[43:58] this idea of desirable difficulty is
[44:00] that they will have a certain task that
[44:01] they need to do and this this task uh
[44:05] may have a way of doing this. Like for
[44:06] example, if it is learning about
[44:08] something, there is a a strategy that
[44:09] you can use and a method and a way to go
[44:11] about learning uh which I teach in all
[44:14] my other videos that could be difficult.
[44:17] It could induce a level of difficulty or
[44:20] I could do it in the way that I'm used
[44:21] to doing which is potentially
[44:23] comfortable. It's much easier. I know
[44:25] how to do that. And so this is not
[44:27] difficult.
[44:29] And so the the the issue here is that
[44:33] they're making this decision about
[44:34] saying, "Okay, this one is actually the
[44:36] one that I feel like doing because it's
[44:39] easier and this one is the one that is
[44:41] harder for me to do." But I'm telling
[44:43] myself, this is the one that is actually
[44:46] desirable. This is the one that I should
[44:48] do. And so now you're torn between what
[44:50] you know you should do versus what you
[44:54] kind of feel more drawn towards, which
[44:56] is the easier option. And if on a bad
[44:58] day when you just don't have enough
[45:00] time, when you don't have the willpower,
[45:02] you just resort to the easier option.
[45:05] But this is not the full picture. And
[45:07] this is the part that I want to
[45:08] communicate really clearly here is that
[45:10] this is only the first part of that
[45:12] decision. Because often if it's
[45:15] desirable difficulty, when you pick the
[45:17] path that involves lower levels of
[45:20] difficulty, it's also going to lead to a
[45:23] lower level of result as opposed to if
[45:26] you pick the path with the desirable
[45:28] difficulty, which leads more closely to
[45:30] the result that you actually wanted in
[45:32] the first place. And when you have the
[45:34] lower level of result,
[45:37] this result also has consequences.
[45:42] And now you need to manage these
[45:45] consequences. So that's extra work you
[45:48] need to do. That's extra effort. That is
[45:50] extra time that you need to spend. And
[45:52] all of this this is also difficult. And
[45:56] sometimes the consequences of not
[45:59] getting the result that you want adds an
[46:01] extra layer which is that it is
[46:03] emotionally
[46:06] And so the decision that you're making
[46:08] at this point when you're deciding how
[46:10] should I go about this task is not
[46:12] desirable difficulty versus ease. The
[46:16] true decision we're making is do I pick
[46:18] the path of desirable discomfort which
[46:22] is this one or do I pick the path of
[46:25] delayed discomfort
[46:27] which is this one. So the discomfort is
[46:30] there regardless. It's just do you pay
[46:33] that upfront or do you pay that later?
[46:36] And most of the time it's better to pay
[46:38] that upfront because the level of
[46:41] discomfort is easier to plan for
[46:44] upfront. Whereas if you have delayed
[46:46] discomfort, you don't know what the
[46:48] consequences of that is going to be. You
[46:50] don't know how much discomfort there's
[46:52] going to be. It's harder to assess what
[46:53] the cost you're paying in those
[46:55] consequences and getting the bad result
[46:57] actually means. And the future version
[46:58] of you has other things to do than pay
[47:01] off this discomfort, debt, and the
[47:03] consequences of getting the poor result.
[47:05] In learning, I see this all the time
[47:07] where people pick the easiest, most
[47:09] passive way to learn something. They're
[47:10] covering 100 pages of content in half an
[47:12] hour. They write up a beautiful set of
[47:14] notes that 90% AI generated. And then
[47:17] the future version of them is now stuck
[47:19] with 3 4 hours a day where they need to
[47:21] go through the stuff to keep on top of
[47:23] it or they'll come back to it 2 weeks
[47:24] later and they've forgotten everything.
[47:26] you've now created a problem for the
[47:28] future version of yourself. And that's
[47:29] where people get stuck on this
[47:31] overwhelming just hamster wheel of
[47:33] constantly working and constantly trying
[47:35] to catch up. The thing you're trying to
[47:37] catch up to is not your present
[47:39] challenges. The things that you're
[47:40] trying to catch up to is the challenges
[47:42] that the past version of you made for
[47:44] you today. And so the takeaway for you
[47:46] is this.
[47:49] Sometimes delayed discomfort is okay.
[47:51] Sometimes delayed discomfort is actually
[47:53] just strategic. You can make that
[47:54] decision. Just make that decision
[47:57] intentionally.
[47:59] Intentionally decide whether you want
[48:02] the discomfort
[48:05] now or
[48:09] later. If you need to make a decision
[48:10] about something, if you need to solve a
[48:12] problem and you need to do it by the end
[48:13] of today, you maybe don't have time to
[48:15] go through all of this stuff. And so you
[48:18] may be willing to accept the risk that
[48:20] you're going to pay for that discomfort
[48:22] later if the result you get isn't good
[48:24] enough. And you can hope that it is good
[48:26] enough. You can use the mental model
[48:27] that you think is the best one for you
[48:29] based on your limited understanding of
[48:31] the issue and just hope you get the
[48:33] result right now while understanding
[48:36] that that's probably not the best way to
[48:39] go about solving problems and making
[48:40] decisions long term. But just make that
[48:42] decision consciously. And when you
[48:44] decide that you are going to take this
[48:46] difficulty up front, hold yourself
[48:51] to a high standard.
[48:56] If you're going to take on a level of
[49:00] discomfort, do it right. At least don't
[49:04] shortcut yourself. When I'm doing a
[49:06] coaching consultation with someone and
[49:07] I'm sitting there watching how they
[49:09] apply a certain learning strategy or a
[49:10] learning technique and they've been
[49:11] struggling with it for for weeks or even
[49:13] months, one of the most effective things
[49:17] that I do that allows a transformation
[49:19] to occur in that person in one hour that
[49:22] they previously weren't able to do in 6
[49:24] months before that is simply being clear
[49:27] about the standard they need to hold
[49:29] themselves to and not letting them get
[49:32] away with it. when they see a problem
[49:33] and they say, "Okay, well, I'm seeing
[49:35] this problem in this kind of way." And I
[49:38] say, "Well, what's another way that you
[49:40] could think about this? What's another
[49:42] way you could perceive the situation?
[49:44] What's another way you could group and
[49:46] categorize and connect it into a big
[49:49] picture?" And they say, "I'm not really
[49:51] sure. I don't let them get away with I
[49:53] don't know." I encourage them to just
[49:54] try their best. Just try to find another
[49:57] way. when they're looking at all these
[49:59] different parts that connect together
[50:00] and they're getting overwhelmed and they
[50:01] say, "I don't know how it connects
[50:03] together." All I say is, "Well, just try
[50:05] to connect it. Just see where you get
[50:07] to. Yes, it's overwhelming. Yes, it's
[50:09] complicated. That's the reason it's a
[50:11] problem in the first place. That's the
[50:12] reason it is your job to solve this. So,
[50:16] just try." And honestly, 70% of the time
[50:19] when someone has an issue, that is the
[50:22] difference that allows them to make the
[50:24] light bulb click. That's the point where
[50:26] they realize, oh, this is what it feels
[50:28] like to think at this level. That's when
[50:31] they realize, oh, it's actually not as
[50:33] scary as I thought, not as bad as I
[50:35] thought to hold myself to this standard.
[50:37] And then from that point, it gets easier
[50:39] and easier. And I know that when
[50:40] someone's able to experience what it's
[50:42] like to think at that level, just even
[50:45] once, then we're winning. From that
[50:47] point, everything is easier because they
[50:49] know that they can do it, they can hold
[50:51] themselves to a certain standard, and
[50:52] they can hit that standard. And as they
[50:54] repeatedly hit that standard again and
[50:56] again, it gets easier and easier and
[50:57] easier to do it. So these are the six
[50:59] meta models that you should apply
[51:01] anytime that you're using any other type
[51:03] of framework or mental model. If you
[51:04] found this video useful, please share it
[51:06] with a colleague or a friend. And if
[51:08] you're interested in leveling up the way
[51:09] that you think and improving your
[51:11] skills, you're going to need to make
[51:13] sure that you're spending your time
[51:14] effectively. And one of the biggest time
[51:17] waste that I see is how people spend
[51:20] their evenings coming home after work.
[51:22] So, if you're interested in some
[51:23] strategies on how you can reclaim your
[51:25] evenings, then check out this video here
[51:27] where I talk about that very topic.
[51:29] Thank you so much for watching and I'll
[51:31] see you in the next one.
