# Raw Transcript: You are Not Ready: Agentic coding in 2026

- **URL**: https://www.youtube.com/watch?v=6W_-YWHKwZ4
- **Creator**: Jo Van Eyck
- **Date**: 2026-02-11
- **Duration**: 31:04
- **Captured**: 2026-02-12
- **Method**: Playwright automated extraction
- **Segments**: 293 segments extracted (deduplicated from 586)

---

[0:00] Hey folks, it's time we had another talk because things have been happening and not enough people are paying the right amount of attention here. So, in today's video, I want to go a bit into a rant and a broad helicopter view of what's been happening in the last couple of months and why I think it matters for the future of software development. Now to get started, I still see a lot of software engineers, especially older seasoned engineers, being very skeptical about how far AI coding agents will actually get. And I think there's a structural under appreciation of where we are right now. I think 2026 will be a sobering year for a whole lot of people.

[0:58] Before we start, I want to point out that I am quite the AI skeptic myself, but I experiment heavily and I am continually impressed by what a software engineer with an AI coding agent can do once they start building on top of it and once you start incorporating these new things that we will be discussing today. Second point I want to highlight before we dive in is I am a somewhat experienced software engineer. I have 15 years of experience writing software, leading teams, coaching teams on test-driven development, continuous delivery, software architecture and design.

[2:01] First thing I want to highlight is the large language models themselves. If you look at the new models coming out in the last couple of months, starting from the Claude 4 family of models and the GPT-5 range or in the open community, the Qwen Coder 3 kind of models, they are all focusing on one thing right now — agentic work. They're fine-tuning their models to do long horizon work, not minutes but hours of work autonomously without human intervention and lots of tool calling. These new models are able to run for hours. They are able to do a lot of tool calling and it is going to be a huge unlock for software development.

[3:10] Second innovation I wanted to highlight is the Ralph Wiggum loop. And while it's a fun little experiment, and it's only like four lines of code, it is a crucial insight that will move things forward. Ralph is a while loop put around a coding agent. The halting condition or the break statement to jump out of the while loop is a deterministic way to verify whether or not work is done. Because if you've been working with an AI coding agent you recognize the "okay I'm all done, all things green, all tests pass" and then you try to compile the code and it doesn't even compile. So this coding agent is lying in your face. That's what the Ralph Wiggum loop is trying to prevent.

[4:29] If the code is not compiling and the test is not running, it just starts a new session and has it continue to work. The other principle is it shows us that we do not need AGI, we do not need super smart models, we just need persistence. You can make them really persistent and have them iterate a bit more to an ideal state and you can get really far with it.

[5:09] A third aspect for why I think the Ralph Wiggum loop is super important has to do with the autonomy slider. If you look back at my first video where I talked about AI augmented coding, I was really babysitting my agents. I was looking at every line of code as it got written. That's not how I work today at all. Ralph Wiggum is one of those approaches that allows me to prepare a package of work, give it off to an agent, and I only have to come back when it's in a stage of high quality and guaranteed completion.

[6:13] The next innovation I want to talk about is Beats — persistent memory upgrades for your coding agents. I like to think of Beats as a Trello board for your coding agents. It's a way to put your plans, break it down into subtasks, identify dependencies between subtasks or blocking dependencies so you can reason about what work can happen in parallel, what work needs to happen in sequence. And it's all persisted outside of the context window. For Beats, it's a git repository with some JSON, but there's a real Trello board somewhere where your agents can look at the next task to be done and update tasks when they're done.

[7:35] Next innovation is Gas Town. It's from the same author as Beats, Steve Yaggi, and it's a bit of a fever dream. But the ideas behind Gas Town are worth paying attention to. The idea is multi-agent orchestrations. Say you have a Trello board like Beats and you have a way to manage a fleet of these agents and have them pick up tasks and update states. That's what Gas Town is. It's like the logical conclusion of where all this is going.

[8:30] The final thing I wanted to discuss is the whole OpenClaw situation. OpenClaw is the AI personal assistant everyone is dreaming of. If you've seen the movie Her, it's literally the operating system in that movie. Except that it's wildly insecure. Don't install OpenClaw on your machine. It's a security nightmare. But if you put it in a bunker with nuclear grade defenses and you do not give it access to the worldwide web or personal information, you can do amazing things. It shows that you don't need AGI. If you just need a large language model as they are today, you give it some tools and put it in a nuclear bunker, it can do amazing things.

[10:00] Now I want to direct your attention to Claude Code. I don't want to point you to Claude Code because I think it's the best tool and you should be using it in favor of anything else. I want to point you towards it because Anthropic are really good at implementing all these things we've discussed today in some kind of experimental form. Claude Code has hooks (Ralph Wiggum-like deterministic verification). Cloud Code has sub agents which have their own context window. Last week Cloud Code introduced teams which is basically Gas Town again — you have a team lead agent and it can spawn team member agents. Also the Beats thing — Cloud Code has improved their plan mode. It is a series of JSON files on disk. Very Beats-like. And looking at OpenClaw — Cloud Code is like poor man's OpenClaw, but it is pretty good at tool calling.

[12:31] One caveat: this stuff is not cheap. If you are running the latest Sonnet or Opus models and you are starting to play around with multi-agent stuff, you will need multiple hundreds of dollars. If you are a solo dev, start taking this into your pricing. If you are an enterprise developer, wait until you get keys. Do not pay for this yourself because it's expensive as heck.

[13:19] Six months in my AI coding journey, things have shifted dramatically. I am not babysitting these things because of all the innovations we just discussed and the quality of code that meets my eyes for the first time is almost indistinguishable from the quality of code that I hand-rolled before. So what does this mean for software engineers? Quite a lot actually. More than I thought it would impact our job six months ago. Things are going a bit quicker than expected.

[14:18] I want to show you my AI augmented coding maturity ladder that I use when I teach this stuff to software engineers. I do think there are several stages you need to master, and you need to start at the bottom or wherever you are today, master that level and move up because a whole lot of this is compounding and you need the base level skills to actually leverage the higher level skills.

[15:34] First level, lowest rung of the ladder is Chat. This means having ChatGPT open, having Claude open, and chatting with the model to ask it questions, to solve problems for you. Skills required: basics of prompt engineering, basics of what goes in the context window, why you should feed certain things into the context window and what you should not put into a context window. You know you've mastered this level if you are confident you can write a good prompt and the output is of a decent and consistent quality.

[16:56] Second rung of the ladder is Mid-Loop Generation. This is where you meet your LLM in your IDE. Autocomplete on steroids. You type a code comment and it suggests alternative implementations. I think you have mastered this level if you use types in a strongly typed programming language, embrace suggestions and can critically evaluate the best alternative.

[18:20] The next rung is the In-the-Loop Agentic Coding. That's a level where a lot of people will be spending a lot of time. Every engineer, junior or senior, needs to be spending two to three months in this stage and get very comfortable before moving on. Why? Because you need to see how these things work. You need to see them struggle and you need to get frustrated with these struggles. When you see a coding agent doom loop, your mind should go, "How can I help? Install guard rails, improve my prompt, improve the design of my codebase?" You should be building your prompt library, your skill library. You should be extracting reusable skills out of interactive sessions with a model.

[20:26] Level four is On-the-Loop Agentic Coding. You are not involved in the building phase. You spec the work, you hand it off to an agent, you go to sleep or have a coffee and when you come back it's high quality artifacts and you just have to verify some things and move on. You've mastered this if you can run multiple Claude Code sessions in parallel, each in their own work tree, and the output is of high quality.

[21:36] The final phase is Multi-Agent Coding. This is the Claude Code teams, the Gas Town level. This is a very fresh level, but this is where things are going. What does mastery at this level look like? I don't know. Everyone's figuring it out as they go.

[22:07] It is important to do your reps. Start where you are, master that level and move up when you are ready. If you start with a multi-agent coding setup and you have not implemented reusable skills, played around with MCP servers, put in guard rails like test automation, security vulnerability scanners — you will shoot yourself, your organization, and your friends in the foot.

[22:41] What does this mean for the skill set of tomorrow's software engineers? Fading skills: Syntax. I can write React today. I have never learned React. Learning languages on a syntax level doesn't make a lot of sense. Writing code by hand in a well-established codebase with well-established architecture and good examples — I do not think that has a place in tomorrow's world of software engineering. If you're a junior engineer please write some code. You need to build up a mental model of programming.

[24:30] Evergreen skills: System design and architecture. You need to be the one designing the good example that an LLM can copy paste from. You need to set up walking skeletons — a codebase with a minimal functional vertical slice and good design and architecture with test automation. Another big skill: taking a fuzzy problem and making it more concrete — product requirement documents, user story maps, requirements. And breaking work down into small vertical chunks. This is a senior engineering skill everyone needs to master in the age of multi-agent orchestration. Learn to do some elephant carpaccio.

[26:17] Next core skill: curating and perfecting your sense of judgment. You need to know what good code looks like. The only way is by seeing a lot of good code and writing a lot of good code by hand. It's not only a validation concern — it's also an ownership and responsibility thing. AI coding agents cannot become accountability sinks. You need to have ownership over the code you're pushing into production. Playing around with the code once in a while allows me to understand the code and create a sense of ownership.

[28:21] New skills you should be learning: basics of prompt engineering, context engineering, harness engineering. And you need to be able to set up agentic harnesses, workflows, and custom pipelines — and more than just setting them up, you need to be able to debug them and improve them. Thinking about Andrej Karpathy's quote that it's not the year of agents, it's the decade of agents. I think we will have job security as software engineers. But the job will change. A small-to-big part of the job will be setting up and debugging these agentic workflows.
