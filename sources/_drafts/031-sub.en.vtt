WEBVTT
Kind: captions
Language: en

00:00:00.320 --> 00:00:02.790 align:start position:0%
 
Most<00:00:00.640><c> modern</c><00:00:01.040><c> AI</c><00:00:01.439><c> products</c><00:00:02.000><c> are</c><00:00:02.320><c> built</c><00:00:02.560><c> from</c>

00:00:02.790 --> 00:00:02.800 align:start position:0%
Most modern AI products are built from
 

00:00:02.800 --> 00:00:05.670 align:start position:0%
Most modern AI products are built from
the<00:00:03.040><c> same</c><00:00:03.200><c> set</c><00:00:03.360><c> of</c><00:00:03.600><c> core</c><00:00:03.840><c> ideas.</c><00:00:04.880><c> In</c><00:00:05.120><c> the</c><00:00:05.279><c> next</c>

00:00:05.670 --> 00:00:05.680 align:start position:0%
the same set of core ideas. In the next
 

00:00:05.680 --> 00:00:07.990 align:start position:0%
the same set of core ideas. In the next
seven<00:00:06.000><c> minutes,</c><00:00:06.799><c> I'll</c><00:00:07.120><c> walk</c><00:00:07.359><c> through</c><00:00:07.680><c> nine</c>

00:00:07.990 --> 00:00:08.000 align:start position:0%
seven minutes, I'll walk through nine
 

00:00:08.000 --> 00:00:10.230 align:start position:0%
seven minutes, I'll walk through nine
concepts<00:00:08.400><c> you</c><00:00:08.559><c> will</c><00:00:08.800><c> see</c><00:00:09.040><c> repeatedly</c><00:00:09.760><c> across</c>

00:00:10.230 --> 00:00:10.240 align:start position:0%
concepts you will see repeatedly across
 

00:00:10.240 --> 00:00:12.950 align:start position:0%
concepts you will see repeatedly across
real<00:00:10.559><c> world</c><00:00:10.800><c> AI</c><00:00:11.200><c> systems.</c><00:00:12.480><c> One,</c>

00:00:12.950 --> 00:00:12.960 align:start position:0%
real world AI systems. One,
 

00:00:12.960 --> 00:00:15.829 align:start position:0%
real world AI systems. One,
tokenization.<00:00:14.240><c> Neural</c><00:00:14.639><c> networks</c><00:00:15.040><c> like</c><00:00:15.280><c> LMS</c>

00:00:15.829 --> 00:00:15.839 align:start position:0%
tokenization. Neural networks like LMS
 

00:00:15.839 --> 00:00:18.230 align:start position:0%
tokenization. Neural networks like LMS
cannot<00:00:16.160><c> work</c><00:00:16.320><c> with</c><00:00:16.560><c> raw</c><00:00:16.880><c> text</c><00:00:17.199><c> directly.</c><00:00:18.080><c> A</c>

00:00:18.230 --> 00:00:18.240 align:start position:0%
cannot work with raw text directly. A
 

00:00:18.240 --> 00:00:20.870 align:start position:0%
cannot work with raw text directly. A
tokenizer<00:00:18.960><c> breaks</c><00:00:19.279><c> text</c><00:00:19.680><c> into</c><00:00:20.080><c> smaller</c><00:00:20.480><c> units</c>

00:00:20.870 --> 00:00:20.880 align:start position:0%
tokenizer breaks text into smaller units
 

00:00:20.880 --> 00:00:23.509 align:start position:0%
tokenizer breaks text into smaller units
called<00:00:21.279><c> tokens</c><00:00:22.080><c> and</c><00:00:22.320><c> maps</c><00:00:22.640><c> each</c><00:00:22.880><c> token</c><00:00:23.199><c> to</c><00:00:23.359><c> an</c>

00:00:23.509 --> 00:00:23.519 align:start position:0%
called tokens and maps each token to an
 

00:00:23.519 --> 00:00:25.910 align:start position:0%
called tokens and maps each token to an
integer<00:00:24.000><c> ID.</c><00:00:24.640><c> So,</c><00:00:24.800><c> the</c><00:00:25.039><c> model</c><00:00:25.359><c> can</c><00:00:25.519><c> take</c><00:00:25.680><c> the</c>

00:00:25.910 --> 00:00:25.920 align:start position:0%
integer ID. So, the model can take the
 

00:00:25.920 --> 00:00:28.230 align:start position:0%
integer ID. So, the model can take the
sequence<00:00:26.240><c> as</c><00:00:26.400><c> input</c><00:00:26.800><c> instead</c><00:00:27.119><c> of</c><00:00:27.279><c> raw</c><00:00:27.599><c> text.</c>

00:00:28.230 --> 00:00:28.240 align:start position:0%
sequence as input instead of raw text.
 

00:00:28.240 --> 00:00:30.390 align:start position:0%
sequence as input instead of raw text.
The<00:00:28.480><c> most</c><00:00:28.720><c> common</c><00:00:29.039><c> algorithm</c><00:00:29.599><c> is</c><00:00:29.840><c> bite</c><00:00:30.160><c> pair</c>

00:00:30.390 --> 00:00:30.400 align:start position:0%
The most common algorithm is bite pair
 

00:00:30.400 --> 00:00:33.910 align:start position:0%
The most common algorithm is bite pair
encoding<00:00:30.960><c> or</c><00:00:31.199><c> BPE.</c><00:00:32.320><c> BPE</c><00:00:32.960><c> starts</c><00:00:33.280><c> from</c><00:00:33.600><c> small</c>

00:00:33.910 --> 00:00:33.920 align:start position:0%
encoding or BPE. BPE starts from small
 

00:00:33.920 --> 00:00:36.470 align:start position:0%
encoding or BPE. BPE starts from small
units<00:00:34.480><c> often</c><00:00:34.800><c> bytes</c><00:00:35.120><c> or</c><00:00:35.360><c> characters</c><00:00:36.160><c> and</c>

00:00:36.470 --> 00:00:36.480 align:start position:0%
units often bytes or characters and
 

00:00:36.480 --> 00:00:38.869 align:start position:0%
units often bytes or characters and
repeatedly<00:00:37.120><c> merges</c><00:00:37.520><c> the</c><00:00:37.760><c> most</c><00:00:38.000><c> frequent</c>

00:00:38.869 --> 00:00:38.879 align:start position:0%
repeatedly merges the most frequent
 

00:00:38.879 --> 00:00:41.830 align:start position:0%
repeatedly merges the most frequent
adjacent<00:00:39.440><c> pairs</c><00:00:39.840><c> to</c><00:00:40.000><c> form</c><00:00:40.320><c> new</c><00:00:40.480><c> tokens.</c><00:00:41.440><c> Over</c>

00:00:41.830 --> 00:00:41.840 align:start position:0%
adjacent pairs to form new tokens. Over
 

00:00:41.840 --> 00:00:45.350 align:start position:0%
adjacent pairs to form new tokens. Over
time,<00:00:42.239><c> common</c><00:00:42.559><c> fragments</c><00:00:43.120><c> like</c><00:00:43.760><c> ing</c><00:00:44.160><c> or</c><00:00:44.559><c> ti</c>

00:00:45.350 --> 00:00:45.360 align:start position:0%
time, common fragments like ing or ti
 

00:00:45.360 --> 00:00:47.430 align:start position:0%
time, common fragments like ing or ti
become<00:00:45.680><c> single</c><00:00:46.000><c> tokens.</c><00:00:46.640><c> So</c><00:00:46.879><c> words</c><00:00:47.200><c> like</c>

00:00:47.430 --> 00:00:47.440 align:start position:0%
become single tokens. So words like
 

00:00:47.440 --> 00:00:51.350 align:start position:0%
become single tokens. So words like
walking<00:00:48.000><c> might</c><00:00:48.239><c> be</c><00:00:48.480><c> split</c><00:00:48.800><c> as</c><00:00:49.120><c> walk</c><00:00:49.520><c> plus</c><00:00:50.000><c> ing.</c>

00:00:51.350 --> 00:00:51.360 align:start position:0%
walking might be split as walk plus ing.
 

00:00:51.360 --> 00:00:54.229 align:start position:0%
walking might be split as walk plus ing.
Two,<00:00:51.840><c> text</c><00:00:52.079><c> decoding.</c><00:00:53.199><c> An</c><00:00:53.440><c> LLM</c><00:00:53.920><c> simply</c>

00:00:54.229 --> 00:00:54.239 align:start position:0%
Two, text decoding. An LLM simply
 

00:00:54.239 --> 00:00:56.389 align:start position:0%
Two, text decoding. An LLM simply
outputs<00:00:54.719><c> a</c><00:00:54.879><c> probability</c><00:00:55.520><c> distribution</c><00:00:56.079><c> over</c>

00:00:56.389 --> 00:00:56.399 align:start position:0%
outputs a probability distribution over
 

00:00:56.399 --> 00:00:58.950 align:start position:0%
outputs a probability distribution over
the<00:00:56.559><c> vocabulary</c><00:00:57.199><c> for</c><00:00:57.440><c> the</c><00:00:57.680><c> next</c><00:00:57.920><c> token.</c><00:00:58.719><c> A</c>

00:00:58.950 --> 00:00:58.960 align:start position:0%
the vocabulary for the next token. A
 

00:00:58.960 --> 00:01:00.950 align:start position:0%
the vocabulary for the next token. A
decoding<00:00:59.440><c> algorithm</c><00:01:00.000><c> chooses</c><00:01:00.399><c> one</c><00:01:00.559><c> token</c>

00:01:00.950 --> 00:01:00.960 align:start position:0%
decoding algorithm chooses one token
 

00:01:00.960 --> 00:01:03.270 align:start position:0%
decoding algorithm chooses one token
from<00:01:01.199><c> that</c><00:01:01.440><c> distribution,</c><00:01:02.559><c> appends</c><00:01:02.960><c> it</c><00:01:03.120><c> to</c>

00:01:03.270 --> 00:01:03.280 align:start position:0%
from that distribution, appends it to
 

00:01:03.280 --> 00:01:05.830 align:start position:0%
from that distribution, appends it to
the<00:01:03.600><c> sequence,</c><00:01:04.320><c> and</c><00:01:04.559><c> repeats</c><00:01:04.960><c> the</c><00:01:05.280><c> process</c><00:01:05.600><c> to</c>

00:01:05.830 --> 00:01:05.840 align:start position:0%
the sequence, and repeats the process to
 

00:01:05.840 --> 00:01:08.710 align:start position:0%
the sequence, and repeats the process to
produce<00:01:06.240><c> a</c><00:01:06.560><c> full</c><00:01:06.880><c> response.</c><00:01:08.000><c> The</c><00:01:08.240><c> simplest</c>

00:01:08.710 --> 00:01:08.720 align:start position:0%
produce a full response. The simplest
 

00:01:08.720 --> 00:01:10.469 align:start position:0%
produce a full response. The simplest
text<00:01:08.960><c> decoding</c><00:01:09.520><c> approach</c><00:01:09.760><c> is</c><00:01:10.080><c> greedy</c>

00:01:10.469 --> 00:01:10.479 align:start position:0%
text decoding approach is greedy
 

00:01:10.479 --> 00:01:12.870 align:start position:0%
text decoding approach is greedy
decoding,<00:01:11.200><c> which</c><00:01:11.520><c> always</c><00:01:11.920><c> picks</c><00:01:12.240><c> the</c><00:01:12.479><c> most</c>

00:01:12.870 --> 00:01:12.880 align:start position:0%
decoding, which always picks the most
 

00:01:12.880 --> 00:01:15.830 align:start position:0%
decoding, which always picks the most
likely<00:01:13.360><c> next</c><00:01:13.600><c> token.</c><00:01:14.400><c> It</c><00:01:14.640><c> can</c><00:01:14.799><c> work</c><00:01:15.119><c> well</c><00:01:15.439><c> for</c>

00:01:15.830 --> 00:01:15.840 align:start position:0%
likely next token. It can work well for
 

00:01:15.840 --> 00:01:18.789 align:start position:0%
likely next token. It can work well for
deterministic<00:01:16.640><c> tasks,</c><00:01:17.520><c> but</c><00:01:17.759><c> not</c><00:01:18.000><c> for</c><00:01:18.240><c> tasks</c>

00:01:18.789 --> 00:01:18.799 align:start position:0%
deterministic tasks, but not for tasks
 

00:01:18.799 --> 00:01:21.749 align:start position:0%
deterministic tasks, but not for tasks
requiring<00:01:19.600><c> creativity.</c><00:01:20.880><c> Sampling</c><00:01:21.439><c> based</c>

00:01:21.749 --> 00:01:21.759 align:start position:0%
requiring creativity. Sampling based
 

00:01:21.759 --> 00:01:24.149 align:start position:0%
requiring creativity. Sampling based
methods<00:01:22.240><c> add</c><00:01:22.880><c> controlled</c><00:01:23.360><c> randomness</c><00:01:23.920><c> to</c>

00:01:24.149 --> 00:01:24.159 align:start position:0%
methods add controlled randomness to
 

00:01:24.159 --> 00:01:26.710 align:start position:0%
methods add controlled randomness to
improve<00:01:24.560><c> diversity.</c><00:01:25.600><c> For</c><00:01:25.759><c> example,</c><00:01:26.240><c> top</c><00:01:26.560><c> P</c>

00:01:26.710 --> 00:01:26.720 align:start position:0%
improve diversity. For example, top P
 

00:01:26.720 --> 00:01:28.870 align:start position:0%
improve diversity. For example, top P
sampling<00:01:27.360><c> draws</c><00:01:27.680><c> the</c><00:01:27.840><c> next</c><00:01:28.080><c> token</c><00:01:28.479><c> from</c><00:01:28.720><c> the</c>

00:01:28.870 --> 00:01:28.880 align:start position:0%
sampling draws the next token from the
 

00:01:28.880 --> 00:01:30.630 align:start position:0%
sampling draws the next token from the
smallest<00:01:29.360><c> set</c><00:01:29.520><c> of</c><00:01:29.680><c> tokens</c><00:01:30.080><c> whose</c>

00:01:30.630 --> 00:01:30.640 align:start position:0%
smallest set of tokens whose
 

00:01:30.640 --> 00:01:33.510 align:start position:0%
smallest set of tokens whose
probabilities<00:01:31.439><c> sum</c><00:01:31.759><c> to</c><00:01:32.079><c> P,</c><00:01:32.720><c> then</c><00:01:33.119><c> samples</c>

00:01:33.510 --> 00:01:33.520 align:start position:0%
probabilities sum to P, then samples
 

00:01:33.520 --> 00:01:36.069 align:start position:0%
probabilities sum to P, then samples
from<00:01:33.759><c> that</c><00:01:34.000><c> set.</c><00:01:35.280><c> Three,</c><00:01:35.759><c> prompt</c>

00:01:36.069 --> 00:01:36.079 align:start position:0%
from that set. Three, prompt
 

00:01:36.079 --> 00:01:38.630 align:start position:0%
from that set. Three, prompt
engineering.<00:01:37.040><c> Vake</c><00:01:37.439><c> prompts</c><00:01:37.920><c> usually</c><00:01:38.400><c> lead</c>

00:01:38.630 --> 00:01:38.640 align:start position:0%
engineering. Vake prompts usually lead
 

00:01:38.640 --> 00:01:41.350 align:start position:0%
engineering. Vake prompts usually lead
to<00:01:38.799><c> vague</c><00:01:39.200><c> answers.</c><00:01:40.240><c> Prompt</c><00:01:40.640><c> engineering</c><00:01:41.119><c> is</c>

00:01:41.350 --> 00:01:41.360 align:start position:0%
to vague answers. Prompt engineering is
 

00:01:41.360 --> 00:01:43.830 align:start position:0%
to vague answers. Prompt engineering is
the<00:01:41.600><c> practice</c><00:01:42.000><c> of</c><00:01:42.400><c> shaping</c><00:01:42.960><c> instructions</c><00:01:43.600><c> and</c>

00:01:43.830 --> 00:01:43.840 align:start position:0%
the practice of shaping instructions and
 

00:01:43.840 --> 00:01:46.389 align:start position:0%
the practice of shaping instructions and
context<00:01:44.479><c> to</c><00:01:44.880><c> steer</c><00:01:45.280><c> a</c><00:01:45.520><c> model's</c><00:01:45.920><c> behavior</c>

00:01:46.389 --> 00:01:46.399 align:start position:0%
context to steer a model's behavior
 

00:01:46.399 --> 00:01:48.950 align:start position:0%
context to steer a model's behavior
without<00:01:46.799><c> changing</c><00:01:47.200><c> its</c><00:01:47.439><c> weights.</c><00:01:48.320><c> A</c><00:01:48.640><c> strong</c>

00:01:48.950 --> 00:01:48.960 align:start position:0%
without changing its weights. A strong
 

00:01:48.960 --> 00:01:51.429 align:start position:0%
without changing its weights. A strong
prompt<00:01:49.439><c> clearly</c><00:01:50.000><c> states</c><00:01:50.320><c> the</c><00:01:50.479><c> task</c><00:01:51.200><c> key</c>

00:01:51.429 --> 00:01:51.439 align:start position:0%
prompt clearly states the task key
 

00:01:51.439 --> 00:01:54.389 align:start position:0%
prompt clearly states the task key
constraints<00:01:52.240><c> and</c><00:01:52.560><c> expected</c><00:01:53.040><c> output</c><00:01:53.520><c> format.</c>

00:01:54.389 --> 00:01:54.399 align:start position:0%
constraints and expected output format.
 

00:01:54.399 --> 00:01:56.789 align:start position:0%
constraints and expected output format.
One<00:01:54.640><c> common</c><00:01:54.960><c> technique</c><00:01:55.360><c> is</c><00:01:55.680><c> fshot</c><00:01:56.159><c> prompting</c>

00:01:56.789 --> 00:01:56.799 align:start position:0%
One common technique is fshot prompting
 

00:01:56.799 --> 00:01:59.270 align:start position:0%
One common technique is fshot prompting
where<00:01:57.040><c> you</c><00:01:57.280><c> include</c><00:01:57.680><c> a</c><00:01:57.920><c> handful</c><00:01:58.240><c> of</c><00:01:58.479><c> examples</c>

00:01:59.270 --> 00:01:59.280 align:start position:0%
where you include a handful of examples
 

00:01:59.280 --> 00:02:01.830 align:start position:0%
where you include a handful of examples
so<00:01:59.520><c> the</c><00:01:59.759><c> model</c><00:02:00.159><c> imitates</c><00:02:00.719><c> the</c><00:02:00.960><c> desired</c><00:02:01.520><c> style</c>

00:02:01.830 --> 00:02:01.840 align:start position:0%
so the model imitates the desired style
 

00:02:01.840 --> 00:02:04.310 align:start position:0%
so the model imitates the desired style
and<00:02:02.159><c> structure.</c><00:02:03.119><c> Another</c><00:02:03.600><c> is</c><00:02:03.920><c> chain</c><00:02:04.159><c> of</c>

00:02:04.310 --> 00:02:04.320 align:start position:0%
and structure. Another is chain of
 

00:02:04.320 --> 00:02:06.550 align:start position:0%
and structure. Another is chain of
thought<00:02:04.640><c> prompting</c><00:02:05.439><c> which</c><00:02:05.600><c> you</c><00:02:05.840><c> ask</c><00:02:06.079><c> for</c>

00:02:06.550 --> 00:02:06.560 align:start position:0%
thought prompting which you ask for
 

00:02:06.560 --> 00:02:09.589 align:start position:0%
thought prompting which you ask for
step-by-step<00:02:07.280><c> reasoning.</c><00:02:08.239><c> Coot</c><00:02:08.720><c> prompting</c>

00:02:09.589 --> 00:02:09.599 align:start position:0%
step-by-step reasoning. Coot prompting
 

00:02:09.599 --> 00:02:11.830 align:start position:0%
step-by-step reasoning. Coot prompting
can<00:02:09.840><c> improve</c><00:02:10.239><c> performance</c><00:02:10.800><c> on</c><00:02:11.039><c> problems</c><00:02:11.520><c> that</c>

00:02:11.830 --> 00:02:11.840 align:start position:0%
can improve performance on problems that
 

00:02:11.840 --> 00:02:14.550 align:start position:0%
can improve performance on problems that
require<00:02:12.640><c> multi-step</c><00:02:13.360><c> logic</c><00:02:13.760><c> like</c><00:02:14.080><c> math</c><00:02:14.319><c> and</c>

00:02:14.550 --> 00:02:14.560 align:start position:0%
require multi-step logic like math and
 

00:02:14.560 --> 00:02:16.949 align:start position:0%
require multi-step logic like math and
coding.<00:02:15.440><c> Prompt</c><00:02:15.840><c> engineering</c><00:02:16.319><c> is</c><00:02:16.560><c> widely</c>

00:02:16.949 --> 00:02:16.959 align:start position:0%
coding. Prompt engineering is widely
 

00:02:16.959 --> 00:02:19.190 align:start position:0%
coding. Prompt engineering is widely
used<00:02:17.280><c> because</c><00:02:17.520><c> it</c><00:02:17.760><c> is</c><00:02:17.920><c> fast</c><00:02:18.239><c> to</c><00:02:18.400><c> iterate</c><00:02:18.800><c> on</c>

00:02:19.190 --> 00:02:19.200 align:start position:0%
used because it is fast to iterate on
 

00:02:19.200 --> 00:02:21.589 align:start position:0%
used because it is fast to iterate on
and<00:02:19.520><c> inexpensive</c><00:02:20.400><c> compared</c><00:02:20.720><c> to</c><00:02:21.040><c> training</c><00:02:21.360><c> or</c>

00:02:21.589 --> 00:02:21.599 align:start position:0%
and inexpensive compared to training or
 

00:02:21.599 --> 00:02:25.589 align:start position:0%
and inexpensive compared to training or
fine-tuning<00:02:22.160><c> a</c><00:02:22.400><c> model.</c><00:02:23.599><c> Four,</c><00:02:24.400><c> multi-step</c><00:02:25.200><c> AI</c>

00:02:25.589 --> 00:02:25.599 align:start position:0%
fine-tuning a model. Four, multi-step AI
 

00:02:25.599 --> 00:02:28.790 align:start position:0%
fine-tuning a model. Four, multi-step AI
agents.<00:02:26.480><c> An</c><00:02:26.720><c> LLM</c><00:02:27.280><c> on</c><00:02:27.440><c> its</c><00:02:27.599><c> own</c><00:02:27.920><c> only</c><00:02:28.239><c> generates</c>

00:02:28.790 --> 00:02:28.800 align:start position:0%
agents. An LLM on its own only generates
 

00:02:28.800 --> 00:02:31.030 align:start position:0%
agents. An LLM on its own only generates
text.<00:02:29.360><c> It</c><00:02:29.599><c> cannot</c><00:02:29.920><c> take</c><00:02:30.239><c> actions</c><00:02:30.720><c> like</c>

00:02:31.030 --> 00:02:31.040 align:start position:0%
text. It cannot take actions like
 

00:02:31.040 --> 00:02:32.790 align:start position:0%
text. It cannot take actions like
browsing<00:02:31.440><c> the</c><00:02:31.599><c> web,</c><00:02:31.920><c> checking</c><00:02:32.160><c> the</c><00:02:32.400><c> weather,</c>

00:02:32.790 --> 00:02:32.800 align:start position:0%
browsing the web, checking the weather,
 

00:02:32.800 --> 00:02:35.670 align:start position:0%
browsing the web, checking the weather,
or<00:02:33.040><c> running</c><00:02:33.360><c> code.</c><00:02:34.239><c> Multi-step</c><00:02:34.959><c> agents</c><00:02:35.440><c> wrap</c>

00:02:35.670 --> 00:02:35.680 align:start position:0%
or running code. Multi-step agents wrap
 

00:02:35.680 --> 00:02:38.150 align:start position:0%
or running code. Multi-step agents wrap
an<00:02:35.840><c> LLM</c><00:02:36.400><c> in</c><00:02:36.480><c> a</c><00:02:36.720><c> loop</c><00:02:37.040><c> with</c><00:02:37.280><c> access</c><00:02:37.599><c> to</c><00:02:37.760><c> tools</c>

00:02:38.150 --> 00:02:38.160 align:start position:0%
an LLM in a loop with access to tools
 

00:02:38.160 --> 00:02:40.710 align:start position:0%
an LLM in a loop with access to tools
and<00:02:38.400><c> memory.</c><00:02:39.360><c> So</c><00:02:39.519><c> it</c><00:02:39.680><c> can</c><00:02:39.920><c> plan</c><00:02:40.160><c> what</c><00:02:40.400><c> to</c><00:02:40.560><c> do</c>

00:02:40.710 --> 00:02:40.720 align:start position:0%
and memory. So it can plan what to do
 

00:02:40.720 --> 00:02:43.589 align:start position:0%
and memory. So it can plan what to do
next,<00:02:41.360><c> call</c><00:02:41.680><c> external</c><00:02:42.160><c> tools,</c><00:02:42.959><c> and</c><00:02:43.200><c> use</c><00:02:43.360><c> the</c>

00:02:43.589 --> 00:02:43.599 align:start position:0%
next, call external tools, and use the
 

00:02:43.599 --> 00:02:45.990 align:start position:0%
next, call external tools, and use the
results<00:02:43.920><c> to</c><00:02:44.239><c> decide</c><00:02:44.480><c> the</c><00:02:44.720><c> next</c><00:02:45.040><c> step.</c><00:02:45.760><c> The</c>

00:02:45.990 --> 00:02:46.000 align:start position:0%
results to decide the next step. The
 

00:02:46.000 --> 00:02:48.470 align:start position:0%
results to decide the next step. The
agent<00:02:46.560><c> repeats</c><00:02:47.040><c> this</c><00:02:47.280><c> cycle</c><00:02:47.920><c> until</c><00:02:48.239><c> it</c>

00:02:48.470 --> 00:02:48.480 align:start position:0%
agent repeats this cycle until it
 

00:02:48.480 --> 00:02:51.270 align:start position:0%
agent repeats this cycle until it
reaches<00:02:48.800><c> the</c><00:02:49.040><c> goal,</c><00:02:49.760><c> runs</c><00:02:50.080><c> out</c><00:02:50.239><c> of</c><00:02:50.400><c> a</c><00:02:50.640><c> budget,</c>

00:02:51.270 --> 00:02:51.280 align:start position:0%
reaches the goal, runs out of a budget,
 

00:02:51.280 --> 00:02:53.350 align:start position:0%
reaches the goal, runs out of a budget,
or<00:02:51.519><c> determines</c><00:02:52.080><c> it</c><00:02:52.319><c> cannot</c><00:02:52.720><c> make</c><00:02:52.879><c> further</c>

00:02:53.350 --> 00:02:53.360 align:start position:0%
or determines it cannot make further
 

00:02:53.360 --> 00:02:54.949 align:start position:0%
or determines it cannot make further
progress.

00:02:54.949 --> 00:02:54.959 align:start position:0%
progress.
 

00:02:54.959 --> 00:02:57.910 align:start position:0%
progress.
Five,<00:02:55.519><c> retrieval</c><00:02:56.000><c> augmented</c><00:02:56.640><c> generation.</c><00:02:57.680><c> A</c>

00:02:57.910 --> 00:02:57.920 align:start position:0%
Five, retrieval augmented generation. A
 

00:02:57.920 --> 00:03:00.630 align:start position:0%
Five, retrieval augmented generation. A
plain<00:02:58.239><c> LLM</c><00:02:58.800><c> answers</c><00:02:59.440><c> using</c><00:02:59.840><c> only</c><00:03:00.080><c> what</c><00:03:00.319><c> is</c>

00:03:00.630 --> 00:03:00.640 align:start position:0%
plain LLM answers using only what is
 

00:03:00.640 --> 00:03:02.949 align:start position:0%
plain LLM answers using only what is
stored<00:03:00.959><c> in</c><00:03:01.120><c> its</c><00:03:01.360><c> weights.</c><00:03:02.080><c> So</c><00:03:02.239><c> it</c><00:03:02.480><c> can</c><00:03:02.640><c> be</c>

00:03:02.949 --> 00:03:02.959 align:start position:0%
stored in its weights. So it can be
 

00:03:02.959 --> 00:03:05.350 align:start position:0%
stored in its weights. So it can be
wrong<00:03:03.200><c> or</c><00:03:03.440><c> outdated</c><00:03:04.080><c> on</c><00:03:04.319><c> recent</c><00:03:04.720><c> events</c><00:03:05.040><c> or</c>

00:03:05.350 --> 00:03:05.360 align:start position:0%
wrong or outdated on recent events or
 

00:03:05.360 --> 00:03:08.550 align:start position:0%
wrong or outdated on recent events or
changing<00:03:05.840><c> company</c><00:03:06.239><c> policies.</c><00:03:07.440><c> Rag</c><00:03:08.000><c> pairs</c><00:03:08.319><c> an</c>

00:03:08.550 --> 00:03:08.560 align:start position:0%
changing company policies. Rag pairs an
 

00:03:08.560 --> 00:03:10.869 align:start position:0%
changing company policies. Rag pairs an
LLM<00:03:09.040><c> with</c><00:03:09.200><c> a</c><00:03:09.440><c> retrieval</c><00:03:09.920><c> system</c><00:03:10.319><c> connected</c><00:03:10.720><c> to</c>

00:03:10.869 --> 00:03:10.879 align:start position:0%
LLM with a retrieval system connected to
 

00:03:10.879 --> 00:03:13.430 align:start position:0%
LLM with a retrieval system connected to
a<00:03:11.120><c> knowledge</c><00:03:11.680><c> store.</c><00:03:12.560><c> When</c><00:03:12.800><c> you</c><00:03:12.959><c> ask</c><00:03:13.200><c> a</c>

00:03:13.430 --> 00:03:13.440 align:start position:0%
a knowledge store. When you ask a
 

00:03:13.440 --> 00:03:16.229 align:start position:0%
a knowledge store. When you ask a
question,<00:03:14.239><c> the</c><00:03:14.480><c> retriever</c><00:03:15.040><c> first</c><00:03:15.840><c> pulls</c>

00:03:16.229 --> 00:03:16.239 align:start position:0%
question, the retriever first pulls
 

00:03:16.239 --> 00:03:18.229 align:start position:0%
question, the retriever first pulls
relevant<00:03:16.640><c> passages</c><00:03:17.200><c> from</c><00:03:17.519><c> sources</c><00:03:17.920><c> like</c>

00:03:18.229 --> 00:03:18.239 align:start position:0%
relevant passages from sources like
 

00:03:18.239 --> 00:03:21.430 align:start position:0%
relevant passages from sources like
PDFs,<00:03:18.800><c> docs,</c><00:03:19.200><c> or</c><00:03:19.440><c> a</c><00:03:19.599><c> database.</c><00:03:20.400><c> Then</c><00:03:20.640><c> the</c><00:03:20.800><c> LLM</c>

00:03:21.430 --> 00:03:21.440 align:start position:0%
PDFs, docs, or a database. Then the LLM
 

00:03:21.440 --> 00:03:24.149 align:start position:0%
PDFs, docs, or a database. Then the LLM
uses<00:03:21.840><c> those</c><00:03:22.159><c> passages</c><00:03:22.640><c> to</c><00:03:22.879><c> write</c><00:03:23.120><c> the</c><00:03:23.280><c> answer.</c>

00:03:24.149 --> 00:03:24.159 align:start position:0%
uses those passages to write the answer.
 

00:03:24.159 --> 00:03:26.309 align:start position:0%
uses those passages to write the answer.
This<00:03:24.640><c> grounds</c><00:03:24.959><c> the</c><00:03:25.200><c> response</c><00:03:25.599><c> in</c><00:03:25.840><c> external</c>

00:03:26.309 --> 00:03:26.319 align:start position:0%
This grounds the response in external
 

00:03:26.319 --> 00:03:28.710 align:start position:0%
This grounds the response in external
evidence<00:03:26.959><c> instead</c><00:03:27.360><c> of</c><00:03:27.599><c> relying</c><00:03:28.080><c> only</c><00:03:28.319><c> on</c><00:03:28.480><c> the</c>

00:03:28.710 --> 00:03:28.720 align:start position:0%
evidence instead of relying only on the
 

00:03:28.720 --> 00:03:30.710 align:start position:0%
evidence instead of relying only on the
model's<00:03:29.120><c> memory.</c>

00:03:30.710 --> 00:03:30.720 align:start position:0%
model's memory.
 

00:03:30.720 --> 00:03:33.110 align:start position:0%
model's memory.
Six,<00:03:31.440><c> reinforcement</c><00:03:32.080><c> learning</c><00:03:32.400><c> from</c><00:03:32.799><c> human</c>

00:03:33.110 --> 00:03:33.120 align:start position:0%
Six, reinforcement learning from human
 

00:03:33.120 --> 00:03:36.470 align:start position:0%
Six, reinforcement learning from human
feedback.<00:03:34.080><c> The</c><00:03:34.319><c> initial</c><00:03:34.799><c> launch</c><00:03:35.040><c> of</c><00:03:35.200><c> Chad</c><00:03:35.519><c> GPT</c>

00:03:36.470 --> 00:03:36.480 align:start position:0%
feedback. The initial launch of Chad GPT
 

00:03:36.480 --> 00:03:39.350 align:start position:0%
feedback. The initial launch of Chad GPT
succeeded<00:03:37.040><c> in</c><00:03:37.360><c> large</c><00:03:37.680><c> because</c><00:03:38.080><c> of</c><00:03:38.319><c> the</c><00:03:38.560><c> RLHF</c>

00:03:39.350 --> 00:03:39.360 align:start position:0%
succeeded in large because of the RLHF
 

00:03:39.360 --> 00:03:42.470 align:start position:0%
succeeded in large because of the RLHF
stage.<00:03:40.319><c> RLHF</c><00:03:41.120><c> is</c><00:03:41.360><c> a</c><00:03:41.519><c> reinforcement</c><00:03:42.159><c> learning</c>

00:03:42.470 --> 00:03:42.480 align:start position:0%
stage. RLHF is a reinforcement learning
 

00:03:42.480 --> 00:03:45.110 align:start position:0%
stage. RLHF is a reinforcement learning
approach<00:03:42.879><c> where</c><00:03:43.200><c> the</c><00:03:43.360><c> model</c><00:03:43.760><c> practices</c><00:03:44.799><c> by</c>

00:03:45.110 --> 00:03:45.120 align:start position:0%
approach where the model practices by
 

00:03:45.120 --> 00:03:47.750 align:start position:0%
approach where the model practices by
generating<00:03:45.680><c> multiple</c><00:03:46.159><c> candidate</c><00:03:46.720><c> responses.</c>

00:03:47.750 --> 00:03:47.760 align:start position:0%
generating multiple candidate responses.
 

00:03:47.760 --> 00:03:50.390 align:start position:0%
generating multiple candidate responses.
A<00:03:48.000><c> separate</c><00:03:48.319><c> reward</c><00:03:48.720><c> model</c><00:03:49.200><c> scores</c><00:03:49.519><c> them</c><00:03:50.159><c> and</c>

00:03:50.390 --> 00:03:50.400 align:start position:0%
A separate reward model scores them and
 

00:03:50.400 --> 00:03:52.149 align:start position:0%
A separate reward model scores them and
the<00:03:50.560><c> training</c><00:03:50.959><c> algorithm</c><00:03:51.519><c> updates</c><00:03:51.920><c> the</c>

00:03:52.149 --> 00:03:52.159 align:start position:0%
the training algorithm updates the
 

00:03:52.159 --> 00:03:54.470 align:start position:0%
the training algorithm updates the
model's<00:03:52.560><c> weights.</c><00:03:53.440><c> So</c><00:03:53.680><c> higher</c><00:03:54.080><c> scoring</c>

00:03:54.470 --> 00:03:54.480 align:start position:0%
model's weights. So higher scoring
 

00:03:54.480 --> 00:03:57.589 align:start position:0%
model's weights. So higher scoring
responses<00:03:55.040><c> become</c><00:03:55.440><c> more</c><00:03:55.680><c> likely</c><00:03:56.799><c> over</c><00:03:57.120><c> time.</c>

00:03:57.589 --> 00:03:57.599 align:start position:0%
responses become more likely over time.
 

00:03:57.599 --> 00:03:59.750 align:start position:0%
responses become more likely over time.
This<00:03:57.840><c> pushes</c><00:03:58.159><c> the</c><00:03:58.400><c> model</c><00:03:58.640><c> toward</c><00:03:59.040><c> outputs</c>

00:03:59.750 --> 00:03:59.760 align:start position:0%
This pushes the model toward outputs
 

00:03:59.760 --> 00:04:02.070 align:start position:0%
This pushes the model toward outputs
that<00:04:00.080><c> people</c><00:04:00.480><c> consistently</c><00:04:01.200><c> rate</c><00:04:01.519><c> as</c><00:04:01.760><c> more</c>

00:04:02.070 --> 00:04:02.080 align:start position:0%
that people consistently rate as more
 

00:04:02.080 --> 00:04:04.309 align:start position:0%
that people consistently rate as more
helpful,<00:04:02.640><c> clear,</c><00:04:02.959><c> and</c><00:04:03.280><c> safe,</c><00:04:04.000><c> not</c><00:04:04.159><c> just</c>

00:04:04.309 --> 00:04:04.319 align:start position:0%
helpful, clear, and safe, not just
 

00:04:04.319 --> 00:04:07.270 align:start position:0%
helpful, clear, and safe, not just
outputs<00:04:04.799><c> that</c><00:04:05.040><c> are</c><00:04:05.360><c> statistically</c><00:04:06.239><c> likely.</c>

00:04:07.270 --> 00:04:07.280 align:start position:0%
outputs that are statistically likely.
 

00:04:07.280 --> 00:04:09.830 align:start position:0%
outputs that are statistically likely.
RLHFs<00:04:08.239><c> align</c><00:04:08.640><c> an</c><00:04:08.799><c> LLM</c><00:04:09.360><c> with</c><00:04:09.519><c> human</c>

00:04:09.830 --> 00:04:09.840 align:start position:0%
RLHFs align an LLM with human
 

00:04:09.840 --> 00:04:12.309 align:start position:0%
RLHFs align an LLM with human
preferences,<00:04:10.879><c> mainly</c><00:04:11.360><c> because</c><00:04:11.680><c> of</c><00:04:11.920><c> how</c><00:04:12.159><c> the</c>

00:04:12.309 --> 00:04:12.319 align:start position:0%
preferences, mainly because of how the
 

00:04:12.319 --> 00:04:14.550 align:start position:0%
preferences, mainly because of how the
reward<00:04:12.720><c> model</c><00:04:13.040><c> is</c><00:04:13.280><c> trained.</c><00:04:13.920><c> The</c><00:04:14.159><c> reward</c>

00:04:14.550 --> 00:04:14.560 align:start position:0%
reward model is trained. The reward
 

00:04:14.560 --> 00:04:16.789 align:start position:0%
reward model is trained. The reward
model<00:04:15.200><c> learns</c><00:04:15.599><c> directly</c><00:04:16.079><c> from</c><00:04:16.400><c> human</c>

00:04:16.789 --> 00:04:16.799 align:start position:0%
model learns directly from human
 

00:04:16.799 --> 00:04:19.110 align:start position:0%
model learns directly from human
feedback,<00:04:17.600><c> usually</c><00:04:17.919><c> from</c><00:04:18.160><c> pairs</c><00:04:18.560><c> of</c><00:04:18.799><c> model</c>

00:04:19.110 --> 00:04:19.120 align:start position:0%
feedback, usually from pairs of model
 

00:04:19.120 --> 00:04:21.349 align:start position:0%
feedback, usually from pairs of model
responses<00:04:20.000><c> to</c><00:04:20.320><c> the</c><00:04:20.479><c> same</c><00:04:20.720><c> prompt</c><00:04:21.120><c> where</c>

00:04:21.349 --> 00:04:21.359 align:start position:0%
responses to the same prompt where
 

00:04:21.359 --> 00:04:24.150 align:start position:0%
responses to the same prompt where
annotators<00:04:22.079><c> pick</c><00:04:22.400><c> the</c><00:04:22.639><c> one</c><00:04:22.880><c> they</c><00:04:23.199><c> prefer.</c><00:04:23.840><c> By</c>

00:04:24.150 --> 00:04:24.160 align:start position:0%
annotators pick the one they prefer. By
 

00:04:24.160 --> 00:04:26.230 align:start position:0%
annotators pick the one they prefer. By
learning<00:04:24.479><c> these</c><00:04:24.880><c> preference</c><00:04:25.360><c> patterns,</c><00:04:26.000><c> the</c>

00:04:26.230 --> 00:04:26.240 align:start position:0%
learning these preference patterns, the
 

00:04:26.240 --> 00:04:28.710 align:start position:0%
learning these preference patterns, the
reward<00:04:26.560><c> model</c><00:04:26.960><c> becomes</c><00:04:27.280><c> a</c><00:04:27.520><c> proxy</c><00:04:28.240><c> for</c><00:04:28.479><c> what</c>

00:04:28.710 --> 00:04:28.720 align:start position:0%
reward model becomes a proxy for what
 

00:04:28.720 --> 00:04:31.590 align:start position:0%
reward model becomes a proxy for what
humans<00:04:29.199><c> tend</c><00:04:29.440><c> to</c><00:04:29.759><c> want</c><00:04:30.639><c> and</c><00:04:30.880><c> reinforcement</c>

00:04:31.590 --> 00:04:31.600 align:start position:0%
humans tend to want and reinforcement
 

00:04:31.600 --> 00:04:33.830 align:start position:0%
humans tend to want and reinforcement
learning<00:04:31.919><c> uses</c><00:04:32.320><c> that</c><00:04:32.560><c> signal</c><00:04:33.040><c> to</c><00:04:33.360><c> steer</c><00:04:33.680><c> the</c>

00:04:33.830 --> 00:04:33.840 align:start position:0%
learning uses that signal to steer the
 

00:04:33.840 --> 00:04:36.390 align:start position:0%
learning uses that signal to steer the
LLM<00:04:34.400><c> toward</c><00:04:34.800><c> responses</c><00:04:35.360><c> that</c><00:04:35.840><c> score</c><00:04:36.080><c> higher</c>

00:04:36.390 --> 00:04:36.400 align:start position:0%
LLM toward responses that score higher
 

00:04:36.400 --> 00:04:38.310 align:start position:0%
LLM toward responses that score higher
on<00:04:36.560><c> that</c><00:04:36.800><c> proxy.</c>

00:04:38.310 --> 00:04:38.320 align:start position:0%
on that proxy.
 

00:04:38.320 --> 00:04:41.990 align:start position:0%
on that proxy.
Seven,<00:04:39.199><c> variational</c><00:04:39.919><c> autoenccoder.</c><00:04:41.120><c> A</c><00:04:41.280><c> VAE</c>

00:04:41.990 --> 00:04:42.000 align:start position:0%
Seven, variational autoenccoder. A VAE
 

00:04:42.000 --> 00:04:44.230 align:start position:0%
Seven, variational autoenccoder. A VAE
is<00:04:42.240><c> a</c><00:04:42.400><c> generative</c><00:04:43.040><c> modeling</c><00:04:43.520><c> approach</c><00:04:44.000><c> that</c>

00:04:44.230 --> 00:04:44.240 align:start position:0%
is a generative modeling approach that
 

00:04:44.240 --> 00:04:46.230 align:start position:0%
is a generative modeling approach that
learns<00:04:44.639><c> a</c><00:04:44.800><c> probability</c><00:04:45.360><c> distribution</c><00:04:46.000><c> of</c>

00:04:46.230 --> 00:04:46.240 align:start position:0%
learns a probability distribution of
 

00:04:46.240 --> 00:04:49.110 align:start position:0%
learns a probability distribution of
data.<00:04:47.040><c> A</c><00:04:47.199><c> VAE</c><00:04:47.759><c> consists</c><00:04:48.160><c> of</c><00:04:48.479><c> two</c><00:04:48.720><c> neural</c>

00:04:49.110 --> 00:04:49.120 align:start position:0%
data. A VAE consists of two neural
 

00:04:49.120 --> 00:04:51.830 align:start position:0%
data. A VAE consists of two neural
networks,<00:04:49.840><c> an</c><00:04:50.080><c> encoder</c><00:04:50.560><c> and</c><00:04:50.720><c> a</c><00:04:50.880><c> decoder.</c><00:04:51.600><c> The</c>

00:04:51.830 --> 00:04:51.840 align:start position:0%
networks, an encoder and a decoder. The
 

00:04:51.840 --> 00:04:53.990 align:start position:0%
networks, an encoder and a decoder. The
encoder<00:04:52.320><c> maps</c><00:04:52.639><c> the</c><00:04:52.880><c> input</c><00:04:53.600><c> into</c><00:04:53.840><c> a</c>

00:04:53.990 --> 00:04:54.000 align:start position:0%
encoder maps the input into a
 

00:04:54.000 --> 00:04:56.550 align:start position:0%
encoder maps the input into a
lowdimensional<00:04:54.960><c> latent</c><00:04:55.440><c> representation</c>

00:04:56.550 --> 00:04:56.560 align:start position:0%
lowdimensional latent representation
 

00:04:56.560 --> 00:04:58.950 align:start position:0%
lowdimensional latent representation
while<00:04:56.880><c> the</c><00:04:57.040><c> decoder</c><00:04:57.680><c> maps</c><00:04:57.919><c> the</c><00:04:58.160><c> latent</c><00:04:58.560><c> vector</c>

00:04:58.950 --> 00:04:58.960 align:start position:0%
while the decoder maps the latent vector
 

00:04:58.960 --> 00:05:01.350 align:start position:0%
while the decoder maps the latent vector
back<00:04:59.199><c> to</c><00:04:59.360><c> the</c><00:04:59.600><c> original</c><00:05:00.000><c> input</c><00:05:00.479><c> space.</c>

00:05:01.350 --> 00:05:01.360 align:start position:0%
back to the original input space.
 

00:05:01.360 --> 00:05:03.990 align:start position:0%
back to the original input space.
Training<00:05:02.000><c> optimizes</c><00:05:02.720><c> a</c><00:05:03.040><c> reconstruction</c>

00:05:03.990 --> 00:05:04.000 align:start position:0%
Training optimizes a reconstruction
 

00:05:04.000 --> 00:05:07.029 align:start position:0%
Training optimizes a reconstruction
objective<00:05:04.880><c> so</c><00:05:05.040><c> the</c><00:05:05.280><c> decoded</c><00:05:05.759><c> output</c><00:05:06.320><c> stays</c>

00:05:07.029 --> 00:05:07.039 align:start position:0%
objective so the decoded output stays
 

00:05:07.039 --> 00:05:09.749 align:start position:0%
objective so the decoded output stays
close<00:05:07.280><c> to</c><00:05:07.520><c> the</c><00:05:07.759><c> original</c><00:05:08.160><c> input.</c><00:05:09.360><c> After</c>

00:05:09.749 --> 00:05:09.759 align:start position:0%
close to the original input. After
 

00:05:09.759 --> 00:05:12.150 align:start position:0%
close to the original input. After
training,<00:05:10.400><c> new</c><00:05:10.639><c> data</c><00:05:11.039><c> can</c><00:05:11.280><c> be</c><00:05:11.440><c> generated</c><00:05:11.919><c> by</c>

00:05:12.150 --> 00:05:12.160 align:start position:0%
training, new data can be generated by
 

00:05:12.160 --> 00:05:14.629 align:start position:0%
training, new data can be generated by
sampling<00:05:12.639><c> a</c><00:05:12.880><c> point</c><00:05:13.120><c> from</c><00:05:13.360><c> the</c><00:05:13.520><c> latent</c><00:05:14.080><c> space</c>

00:05:14.629 --> 00:05:14.639 align:start position:0%
sampling a point from the latent space
 

00:05:14.639 --> 00:05:17.350 align:start position:0%
sampling a point from the latent space
and<00:05:14.960><c> decoding</c><00:05:15.440><c> it.</c><00:05:16.080><c> In</c><00:05:16.320><c> modern</c><00:05:16.639><c> text</c><00:05:16.880><c> to</c><00:05:17.039><c> image</c>

00:05:17.350 --> 00:05:17.360 align:start position:0%
and decoding it. In modern text to image
 

00:05:17.360 --> 00:05:19.749 align:start position:0%
and decoding it. In modern text to image
and<00:05:17.520><c> texttovideo</c><00:05:18.240><c> systems</c><00:05:18.639><c> like</c><00:05:18.960><c> OpenAI's</c>

00:05:19.749 --> 00:05:19.759 align:start position:0%
and texttovideo systems like OpenAI's
 

00:05:19.759 --> 00:05:22.790 align:start position:0%
and texttovideo systems like OpenAI's
Sora,<00:05:20.639><c> a</c><00:05:20.880><c> VA</c><00:05:21.280><c> is</c><00:05:21.440><c> often</c><00:05:21.759><c> used</c><00:05:22.000><c> as</c><00:05:22.240><c> a</c><00:05:22.400><c> latent</c>

00:05:22.790 --> 00:05:22.800 align:start position:0%
Sora, a VA is often used as a latent
 

00:05:22.800 --> 00:05:24.710 align:start position:0%
Sora, a VA is often used as a latent
compressor,<00:05:23.520><c> allowing</c><00:05:23.919><c> the</c><00:05:24.160><c> downstream</c>

00:05:24.710 --> 00:05:24.720 align:start position:0%
compressor, allowing the downstream
 

00:05:24.720 --> 00:05:26.790 align:start position:0%
compressor, allowing the downstream
model<00:05:24.960><c> to</c><00:05:25.199><c> operate</c><00:05:25.600><c> more</c><00:05:25.919><c> efficiently</c><00:05:26.400><c> in</c><00:05:26.639><c> a</c>

00:05:26.790 --> 00:05:26.800 align:start position:0%
model to operate more efficiently in a
 

00:05:26.800 --> 00:05:28.790 align:start position:0%
model to operate more efficiently in a
smaller<00:05:27.280><c> space.</c>

00:05:28.790 --> 00:05:28.800 align:start position:0%
smaller space.
 

00:05:28.800 --> 00:05:31.430 align:start position:0%
smaller space.
Eight,<00:05:29.440><c> diffusion</c><00:05:30.000><c> models.</c><00:05:30.880><c> Diffusion</c>

00:05:31.430 --> 00:05:31.440 align:start position:0%
Eight, diffusion models. Diffusion
 

00:05:31.440 --> 00:05:33.590 align:start position:0%
Eight, diffusion models. Diffusion
models<00:05:31.840><c> generate</c><00:05:32.240><c> data</c><00:05:32.639><c> by</c><00:05:32.960><c> learning</c><00:05:33.280><c> to</c>

00:05:33.590 --> 00:05:33.600 align:start position:0%
models generate data by learning to
 

00:05:33.600 --> 00:05:36.150 align:start position:0%
models generate data by learning to
reverse<00:05:34.000><c> a</c><00:05:34.320><c> gradual</c><00:05:34.800><c> noising</c><00:05:35.360><c> process.</c>

00:05:36.150 --> 00:05:36.160 align:start position:0%
reverse a gradual noising process.
 

00:05:36.160 --> 00:05:38.390 align:start position:0%
reverse a gradual noising process.
During<00:05:36.479><c> training,</c><00:05:37.120><c> you</c><00:05:37.360><c> take</c><00:05:37.600><c> real</c><00:05:37.919><c> samples</c>

00:05:38.390 --> 00:05:38.400 align:start position:0%
During training, you take real samples
 

00:05:38.400 --> 00:05:41.110 align:start position:0%
During training, you take real samples
like<00:05:38.720><c> images,</c><00:05:39.360><c> add</c><00:05:39.680><c> noise</c><00:05:40.080><c> over</c><00:05:40.400><c> many</c><00:05:40.800><c> time</c>

00:05:41.110 --> 00:05:41.120 align:start position:0%
like images, add noise over many time
 

00:05:41.120 --> 00:05:43.430 align:start position:0%
like images, add noise over many time
steps,<00:05:41.759><c> and</c><00:05:42.000><c> train</c><00:05:42.240><c> a</c><00:05:42.479><c> model</c><00:05:42.720><c> to</c><00:05:42.960><c> predict</c><00:05:43.280><c> the</c>

00:05:43.430 --> 00:05:43.440 align:start position:0%
steps, and train a model to predict the
 

00:05:43.440 --> 00:05:45.830 align:start position:0%
steps, and train a model to predict the
noise<00:05:43.840><c> given</c><00:05:44.080><c> the</c><00:05:44.320><c> noisy</c><00:05:44.720><c> input.</c><00:05:45.280><c> the</c><00:05:45.600><c> time</c>

00:05:45.830 --> 00:05:45.840 align:start position:0%
noise given the noisy input. the time
 

00:05:45.840 --> 00:05:48.070 align:start position:0%
noise given the noisy input. the time
step<00:05:46.240><c> and</c><00:05:46.479><c> optional</c><00:05:47.039><c> conditioning</c><00:05:47.680><c> such</c><00:05:47.919><c> as</c>

00:05:48.070 --> 00:05:48.080 align:start position:0%
step and optional conditioning such as
 

00:05:48.080 --> 00:05:51.029 align:start position:0%
step and optional conditioning such as
text.<00:05:48.880><c> At</c><00:05:49.120><c> inference</c><00:05:49.600><c> time,</c><00:05:50.160><c> you</c><00:05:50.479><c> start</c><00:05:50.720><c> from</c>

00:05:51.029 --> 00:05:51.039 align:start position:0%
text. At inference time, you start from
 

00:05:51.039 --> 00:05:53.270 align:start position:0%
text. At inference time, you start from
pure<00:05:51.440><c> noise</c><00:05:51.840><c> and</c><00:05:52.160><c> repeatedly</c><00:05:52.800><c> apply</c><00:05:53.120><c> the</c>

00:05:53.270 --> 00:05:53.280 align:start position:0%
pure noise and repeatedly apply the
 

00:05:53.280 --> 00:05:55.510 align:start position:0%
pure noise and repeatedly apply the
learn<00:05:53.600><c> the</c><00:05:53.680><c> noising</c><00:05:54.160><c> step</c><00:05:54.400><c> to</c><00:05:54.639><c> move</c><00:05:54.800><c> toward</c><00:05:55.199><c> a</c>

00:05:55.510 --> 00:05:55.520 align:start position:0%
learn the noising step to move toward a
 

00:05:55.520 --> 00:05:57.430 align:start position:0%
learn the noising step to move toward a
clean<00:05:55.840><c> sample.</c>

00:05:57.430 --> 00:05:57.440 align:start position:0%
clean sample.
 

00:05:57.440 --> 00:06:00.870 align:start position:0%
clean sample.
Nine,<00:05:58.240><c> low</c><00:05:58.560><c> rank</c><00:05:58.880><c> adaptation.</c><00:06:00.160><c> Large</c><00:06:00.560><c> models</c>

00:06:00.870 --> 00:06:00.880 align:start position:0%
Nine, low rank adaptation. Large models
 

00:06:00.880 --> 00:06:03.749 align:start position:0%
Nine, low rank adaptation. Large models
like<00:06:01.199><c> LLMs</c><00:06:01.840><c> and</c><00:06:02.160><c> textto</c><00:06:02.639><c> image</c><00:06:02.960><c> systems</c><00:06:03.360><c> are</c>

00:06:03.749 --> 00:06:03.759 align:start position:0%
like LLMs and textto image systems are
 

00:06:03.759 --> 00:06:06.070 align:start position:0%
like LLMs and textto image systems are
general<00:06:04.160><c> purpose.</c><00:06:04.960><c> They</c><00:06:05.280><c> handle</c><00:06:05.680><c> broad</c>

00:06:06.070 --> 00:06:06.080 align:start position:0%
general purpose. They handle broad
 

00:06:06.080 --> 00:06:08.790 align:start position:0%
general purpose. They handle broad
everyday<00:06:06.560><c> tasks</c><00:06:07.039><c> well,</c><00:06:07.680><c> but</c><00:06:07.919><c> often</c><00:06:08.400><c> struggle</c>

00:06:08.790 --> 00:06:08.800 align:start position:0%
everyday tasks well, but often struggle
 

00:06:08.800 --> 00:06:11.670 align:start position:0%
everyday tasks well, but often struggle
in<00:06:09.199><c> specialized</c><00:06:09.919><c> domains.</c><00:06:10.880><c> Laura</c><00:06:11.360><c> is</c><00:06:11.520><c> an</c>

00:06:11.670 --> 00:06:11.680 align:start position:0%
in specialized domains. Laura is an
 

00:06:11.680 --> 00:06:13.990 align:start position:0%
in specialized domains. Laura is an
efficient<00:06:12.080><c> fine-tuning</c><00:06:12.800><c> method</c><00:06:13.280><c> that</c><00:06:13.600><c> adapts</c>

00:06:13.990 --> 00:06:14.000 align:start position:0%
efficient fine-tuning method that adapts
 

00:06:14.000 --> 00:06:16.150 align:start position:0%
efficient fine-tuning method that adapts
a<00:06:14.160><c> pre-trained</c><00:06:14.720><c> model</c><00:06:15.039><c> without</c><00:06:15.440><c> updating</c><00:06:15.919><c> all</c>

00:06:16.150 --> 00:06:16.160 align:start position:0%
a pre-trained model without updating all
 

00:06:16.160 --> 00:06:19.110 align:start position:0%
a pre-trained model without updating all
of<00:06:16.319><c> its</c><00:06:16.639><c> parameters.</c><00:06:17.680><c> It</c><00:06:17.919><c> keeps</c><00:06:18.160><c> the</c><00:06:18.479><c> original</c>

00:06:19.110 --> 00:06:19.120 align:start position:0%
of its parameters. It keeps the original
 

00:06:19.120 --> 00:06:22.150 align:start position:0%
of its parameters. It keeps the original
linear<00:06:19.680><c> layer</c><00:06:19.840><c> weights</c><00:06:20.240><c> frozen</c><00:06:20.880><c> and</c><00:06:21.199><c> adds</c><00:06:21.759><c> two</c>

00:06:22.150 --> 00:06:22.160 align:start position:0%
linear layer weights frozen and adds two
 

00:06:22.160 --> 00:06:24.710 align:start position:0%
linear layer weights frozen and adds two
small<00:06:22.639><c> low</c><00:06:22.960><c> rank</c><00:06:23.199><c> trainable</c><00:06:23.680><c> matrices.</c><00:06:24.560><c> So</c>

00:06:24.710 --> 00:06:24.720 align:start position:0%
small low rank trainable matrices. So
 

00:06:24.720 --> 00:06:26.870 align:start position:0%
small low rank trainable matrices. So
the<00:06:24.880><c> model</c><00:06:25.280><c> can</c><00:06:25.440><c> learn</c><00:06:25.759><c> a</c><00:06:26.000><c> domain</c><00:06:26.400><c> specific</c>

00:06:26.870 --> 00:06:26.880 align:start position:0%
the model can learn a domain specific
 

00:06:26.880 --> 00:06:29.270 align:start position:0%
the model can learn a domain specific
adjustments<00:06:27.520><c> with</c><00:06:27.840><c> far</c><00:06:28.160><c> fewer</c><00:06:28.960><c> new</c>

00:06:29.270 --> 00:06:29.280 align:start position:0%
adjustments with far fewer new
 

00:06:29.280 --> 00:06:31.909 align:start position:0%
adjustments with far fewer new
parameters.<00:06:30.400><c> With</c><00:06:30.639><c> this</c><00:06:30.880><c> foundation,</c><00:06:31.680><c> you</c>

00:06:31.909 --> 00:06:31.919 align:start position:0%
parameters. With this foundation, you
 

00:06:31.919 --> 00:06:33.909 align:start position:0%
parameters. With this foundation, you
should<00:06:32.080><c> find</c><00:06:32.400><c> reading</c><00:06:32.800><c> future</c><00:06:33.199><c> AI</c><00:06:33.520><c> designs</c>

00:06:33.909 --> 00:06:33.919 align:start position:0%
should find reading future AI designs
 

00:06:33.919 --> 00:06:37.120 align:start position:0%
should find reading future AI designs
and<00:06:34.160><c> articles</c><00:06:34.639><c> much</c><00:06:34.880><c> easier.</c>

