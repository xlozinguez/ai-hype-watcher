[00:07] Ever since the release of Chad GBT, AI
[00:09] executives in the news media have been
[00:11] hyperventilating about how AI will take
[00:13] everybody's jobs and thus cause mass
[00:15] unemployment. We are now in the fourth
[00:17] year of the AI bubble and there is very
[00:19] little evidence that AI is displacing a
[00:20] significant number of jobs. According to
[00:23] the consulting firm Challenger, AI was
[00:25] responsible for 55,000 layoffs in the US
[00:27] in 2025. While that sounds like a lot,
[00:30] we need to put that number into context.
[00:32] In 2025, there were over 1 million
[00:35] layoffs. So, AI was only responsible for
[00:37] 5% of total job losses. For those 55,000
[00:41] layoffs, that just means the company
[00:43] said the layoffs were due to AI. There's
[00:45] no way to confirm that the jobs were
[00:46] actually replaced by AI. In many cases,
[00:49] a company needs to conduct layoffs for
[00:51] other reasons. For example, if they
[00:53] overhired in the past, instead of
[00:55] admitting the real reason, they will
[00:57] often credit the layoffs to AI because
[00:59] this sounds better to stock market
[01:00] analysts. In the few cases where
[01:02] companies have actually tried to replace
[01:04] employees with AI, the results have
[01:06] often been poor. A recent study in the
[01:08] UK found that 55% of companies who
[01:10] replaced workers with AI now regret the
[01:13] decision and in many cases are hiring
[01:15] them back. Of course, different jobs
[01:17] will have different impacts from AI. One
[01:19] of the jobs believed to be most at risk
[01:21] is software engineering. On paper,
[01:23] software engineering should be one of
[01:25] the easiest jobs for AI to replace. LLMs
[01:28] are trained by scraping huge amounts of
[01:29] data from websites like Stack Overflow.
[01:31] Anthropics Claude Code and OpenAI's
[01:34] Codeex can output huge amounts of code
[01:36] very quickly. In January of 2026,
[01:39] Anthropic CEO Dario Amade made the
[01:42] following prediction. I have engineers
[01:44] within Enthropic who say, "I don't write
[01:46] any code anymore. I just I just let the
[01:48] model write the code. I edit it. I do
[01:51] the things around it. I think I don't
[01:54] know. We might be six to 12 months away
[01:56] from when the model is doing most maybe
[01:59] all of what SWES do end to end. And then
[02:02] it's a question of how fast does that
[02:04] loop close. According to Amadeday,
[02:07] within 6 to 12 months, AI will be able
[02:09] to do everything that software engineers
[02:10] do end to end. That might sound scary to
[02:13] aspiring software engineers. In fact,
[02:16] many universities have reported a
[02:17] decrease in computer science majors as
[02:19] students are scared that software
[02:20] engineering jobs will all be replaced by
[02:22] AI. The only problem is Daario Amade
[02:25] made the exact same prediction almost 12
[02:27] months ago. In March of 2025, Amade made
[02:30] the following prediction. But now
[02:33] getting to kind of the job side of this.
[02:35] Um I I I do have a fair amount of
[02:38] concern about this. Um on one hand, I
[02:41] think comparative advantage is a very
[02:43] powerful tool. If I look at coding
[02:46] programming which is one area where AI
[02:48] is making the most progress um what we
[02:51] are finding is we are not far from a
[02:52] world I think we'll be there in three to
[02:54] six months where AI is writing 90% of
[02:57] the code and then in 12 months we may be
[03:00] in a world where AI is writing
[03:02] essentially all of the code that was in
[03:05] March of 2025 in 3 to 6 months AI will
[03:08] write 90% of all code in 12 months which
[03:12] is basically now AI will write essent
[03:14] essentially all of the code. Of course,
[03:16] this hasn't happened. Basically, since
[03:18] the release of Chat GPT, tech CEOs have
[03:21] been saying that AI is going to take
[03:22] everybody's jobs within 12 months. 12
[03:24] months later, AI hasn't taken any jobs.
[03:27] But then they make the exact same
[03:28] prediction delayed by another 12 months.
[03:31] In this video, we'll explain why AI is
[03:33] not replacing a significant number of
[03:35] jobs and is not likely to do so in the
[03:37] foreseeable future. And more
[03:39] importantly, we'll look at why AI CEOs
[03:41] want you to believe that AI will take
[03:42] your job even when it won't.
[03:45] Let's start off by looking at software
[03:47] engineering in particular. It is true
[03:49] that many software engineers use AI
[03:51] tools. According to Google, 90% of
[03:53] technology workers now use some form of
[03:55] LLM during their work. This may very
[03:58] well be true, but just because software
[04:00] engineers use AI doesn't mean they can
[04:02] be replaced by AI. So, how do coders
[04:04] actually use AI? Let's say you're a
[04:07] software engineer. Even if you're very
[04:09] experienced and capable, you will forget
[04:11] certain functions from time to time.
[04:13] Back in the day, you would go on Stack
[04:14] Overflow. You'd find examples of the
[04:16] function you're looking for and copy
[04:18] paste that into your own code. AI models
[04:20] are trained by scraping the internet.
[04:22] They can pretty easily recreate
[04:24] everything you would read on Stack
[04:25] Overflow because they are trained on
[04:26] this data. Now, instead of going to
[04:28] Stack Overflow, you can go to ChatgBT to
[04:31] look up functions. This is much easier.
[04:33] You can even use an AI native IDE like
[04:35] cursor or codeex to have the AI write
[04:38] whatever function directly in your code
[04:39] so you don't need to copy paste. Using
[04:41] AI can save you a little bit of time
[04:43] compared to using Stack Overflow. Most
[04:45] AI coding tools are pretty cheap
[04:47] compared to the salary of a software
[04:48] engineer. So it makes sense that these
[04:50] tools have been widely adopted. If you
[04:52] see a statistic that 90% of software
[04:54] engineers use AI, this can give a highly
[04:57] misleading impression of how useful the
[04:58] AI actually is.
[05:00] A software engineer does much more than
[05:02] just memorize a bunch of functions from
[05:04] Stack Overflow. In real world
[05:06] environments, engineers must collaborate
[05:08] closely with product managers,
[05:10] designers, security teams, and other
[05:12] developers to define requirements, and
[05:13] make thoughtful trade-offs. They spend
[05:15] significant time debugging issues,
[05:17] maintaining and refactoring existing
[05:19] systems, reviewing code, writing tests,
[05:21] and ensuring reliability and performance
[05:23] at scale. You can try to use AI to
[05:26] create an entire piece of software or
[05:27] even an app. This is called vibe coding.
[05:30] The idea is that someone with limited or
[05:32] no coding experience can create a new
[05:34] app just by giving the AI natural
[05:36] language prompts. But there are huge
[05:38] problems with this approach.
[05:41] There are very few examples of software
[05:42] or apps that were created with AI alone.
[05:45] The highest profile example I could find
[05:47] was Moltbook. Moltbook is a recently
[05:49] released social media platform. It has a
[05:52] very basic interface similar in some
[05:53] ways to 4chan. is supposed to be a
[05:56] social media platform for AI agents. The
[05:58] idea is you create an AI agent with chat
[06:00] GPT or Claude and give it access to
[06:02] Moltbook. People's AIs will talk to each
[06:05] other on Moltbook and have completely
[06:06] fake AI conversations. There is zero
[06:09] practical use case for Moltbook. It's
[06:11] basically just an AI gimmick. The
[06:13] creator of Moltbook is a guy called Matt
[06:15] Schlick. He claims to have used AI to
[06:18] create the Moltbook website. He didn't
[06:20] write a single line of code by hand.
[06:22] Within days, hackers found
[06:24] vulnerabilities in Mlebook's code, which
[06:25] they were able to exploit. Hackers were
[06:28] able to steal 35,000 email addresses and
[06:30] 1.5 million Open AI and anthropic API
[06:33] keys. These were the API keys people
[06:36] used to power their AI agents. If your
[06:38] API keys are stolen, the hacker can use
[06:40] it to rack up huge bills that will be
[06:42] charged to your account. So yes, you can
[06:44] vibe code an entire app or website, but
[06:46] it will have so many security holes and
[06:48] other problems that no real company will
[06:50] be willing to put their name behind it.
[06:52] Security is a huge problem with vibe
[06:54] coding. The cyber security firm Apiro
[06:56] has witnessed a massive increase in
[06:58] security breaches over the past year.
[07:00] They attribute this to software
[07:01] engineers increasingly relying on AI
[07:03] tools to write code.
[07:06] AI coding tools cannot fully replace
[07:08] software engineers, but maybe they can
[07:10] increase the productivity of each
[07:11] software engineer, so you need fewer of
[07:13] them in total. While this sounds like a
[07:15] reasonable hypothesis, it is not borne
[07:17] out by the data. Many software engineers
[07:19] think that AI increases their
[07:21] productivity. The AI spits out a lot of
[07:23] code very fast, so it feels like you're
[07:25] working faster. But in reality, the code
[07:28] has so many problems in it that you
[07:29] spend more time fixing the problems than
[07:31] it would take to just write the code by
[07:33] hand.
[07:35] In early 2025, a nonprofit organization
[07:37] called Model Evaluation and Threat
[07:39] Research, or METR, ran an experiment to
[07:42] see how effective AI coding tools are.
[07:44] They hired 16 software engineers to
[07:46] complete various coding tasks. The
[07:48] software engineers had about 5 years of
[07:50] experience. Half of them were allowed to
[07:52] use AI coding tools while the other half
[07:54] were not. The coding tool was Cursor Pro
[07:56] using Claw 3.7, which was considered to
[07:59] be the best coding LLM at the time. The
[08:02] results were shocking. Before completing
[08:04] the task, they asked the software
[08:05] engineers to estimate how long it would
[08:07] take. The ones who were not allowed to
[08:09] use AI thought it would take two hours
[08:10] to complete the task. The ones who were
[08:13] allowed to use AI thought it would only
[08:14] take them an hour and a half. In
[08:16] reality, the software engineers who were
[08:18] not allowed to use AI were able to
[08:20] complete the tasks in about 1 hour and
[08:21] 40 minutes, less than they forecasted.
[08:24] The ones who used AI took well over 2
[08:26] hours. While software engineers think AI
[08:29] speeds them up, it actually slows them
[08:31] down.
[08:32] Over the past few years, the media hype
[08:35] around AI job losses has reached a point
[08:37] of near absurdity. Let's watch a clip of
[08:39] Anthropic CEO Dario Amade speaking to
[08:41] CNN in May of 2025.
[08:44] Dario, you've said that AI could wipe
[08:46] out half of all entry-level white collar
[08:49] jobs and spike unemployment to 10 to
[08:52] 20%. How soon might that happen?
[08:57] Well, let's uh uh uh well, first of all,
[08:59] thanks for having me on the show, but uh
[09:01] uh just to back up a little bit, you
[09:02] know, I've been building AI for over a
[09:05] decade, and I think maybe the most
[09:07] salient feature of the technology, and
[09:09] what is driving all of this is how fast
[09:12] the technology is getting better. Um, a
[09:14] couple years ago, you could say that AI
[09:16] models were maybe as good as a smart
[09:18] high school student. I would say that
[09:19] now they're as good as a smart college
[09:21] student and and and sort of reaching
[09:23] past that. I really worry particularly
[09:25] at the entry level that the AI models
[09:28] are are are you know ve very much at the
[09:30] center of what what an entry level human
[09:33] worker would do. Um and so it's hard to
[09:36] estimate you know exactly what the
[09:37] impact would be and and you know there
[09:39] that there's always this question of
[09:41] adaptation and and you know these these
[09:43] technology changes have happened before
[09:45] but I think what is striking to me about
[09:47] the that this this AI boom is that it's
[09:50] bigger and it's broader and it's moving
[09:52] faster than anything has before and so
[09:54] compared to previous technology changes
[09:57] I'm a little bit more worried about the
[09:58] labor impact simply because it's
[10:00] happening so fast that yes people will
[10:02] adapt but they they they may not adapt
[10:05] fast enough and so there there you know
[10:07] there there may be an adjustment period.
[10:09] you are running an incredibly important
[10:12] company uh in AI uh and you know this
[10:16] better better than anybody or as well as
[10:18] as you know all the names we know people
[10:21] Sam Alman and others who are working
[10:22] Elon Musk and AI
[10:25] why are you raising the alarm because
[10:27] it's not necessarily I would think in
[10:30] your best interest because a lot of the
[10:31] messages we hear from at least publicly
[10:34] from you know some AI CEOs and stuff is
[10:36] is a little bit more calming saying
[10:39] like, you know, these agents are going
[10:40] to be great in your life and and yes,
[10:42] there may be problems. Uh but, you know,
[10:45] writ large, this is a fantastic thing.
[10:48] &gt;&gt; Yeah. I mean, you know, I think I think
[10:50] the reason I'm raising the alarm is that
[10:51] I think others others haven't as much
[10:53] and you know, I think I think someone
[10:54] needs to say it. You know,
[10:56] &gt;&gt; Dario Amade did something very clever
[10:58] here and he completely fooled the CNN
[11:00] anchor. Anthropic is developing AI.
[11:03] Amday is sounding the alarm about the
[11:05] negative impacts AI will have on the job
[11:06] market. Supposedly, it will cause the
[11:09] unemployment rate to increase to 20%
[11:11] within the next 5 years. Emay seems
[11:13] credible because he is sounding the
[11:15] alarm about AI. Despite being the CEO of
[11:17] an AI company, his alarmist statements
[11:20] seem to be motivated by a genuine
[11:21] concern about the people who will lose
[11:23] their jobs. While I can't get inside
[11:25] Amadeay's head, I believe his
[11:26] motivations to be very different.
[11:28] Anthropic mostly sells his cla chatbot
[11:31] and claude code product to enterprise
[11:32] customers. For a company to spend large
[11:35] amounts of money on clawed code, they
[11:36] need to believe that this technology
[11:38] will allow them to lay off software
[11:40] engineers. That's the only way to
[11:41] justify the spending. For Anthropic to
[11:44] sell its products, it needs people to
[11:45] believe that AI can replace human
[11:47] workers. But as we will see shortly,
[11:49] there is very little evidence that AI
[11:51] can replace human workers. In fact,
[11:53] there's a lot of evidence to the
[11:54] contrary.
[11:56] One of the problems with reporting about
[11:58] AI is that public company CEOs often
[12:00] exaggerate how much their companies are
[12:02] using AI because they think this sounds
[12:04] good to Wall Street analysts. For
[12:06] example, in June of 2025, Salesforce CEO
[12:09] Mark Beni off claimed that AI is doing
[12:11] 30 to 50% of all internal work within
[12:13] Salesforce. If this were really the
[12:15] case, they should lay off 30 to 50% of
[12:17] their employees and recognize huge cost
[12:19] savings. Of course, this hasn't
[12:21] happened. In September, it was reported
[12:23] that Salesforce laid off 4,000 customer
[12:25] support workers. Salesforce has over
[12:28] 70,000 employees, so this is only about
[12:30] 3%. It was later revealed that
[12:32] Salesforce didn't even lay off 4,000
[12:35] people. They reassigned 4,000 customer
[12:37] support workers to other roles, but
[12:39] there were no net layoffs. They tried to
[12:41] get AI to do customer service, but this
[12:44] has caused huge problems with faulty
[12:45] responses. A Salesforce executive told
[12:48] the information that the company has
[12:49] lost confidence in LMS over the past
[12:51] year due to poor performance at customer
[12:53] service tasks. Mark Beni off made huge
[12:56] claims about AI which generated a lot of
[12:58] media headlines, but there's really no
[13:00] evidence that Salesforce is getting any
[13:02] efficiency gains from AI.
[13:05] Another example is Microsoft. If any
[13:07] company can replace workers with AI, it
[13:09] should be Microsoft. Microsoft owns 27%
[13:12] of Open AAI and uses OpenAI's technology
[13:15] to create its own AI coding tools such
[13:17] as GitHub Copilot. Microsoft requires
[13:19] its employees to use AI. AI usage is
[13:22] tied to performance reviews. If you
[13:24] don't use AI enough, you'll have your
[13:26] bonus cut or you might even be fired. In
[13:29] May of 2025, Microsoft CEO Saja Nadella
[13:32] boasted that 20 to 30% of code at
[13:34] Microsoft is now written by AI. The
[13:36] shift to AI coding has coincided with
[13:38] huge problems with Windows 11, which is
[13:41] plagued by bugs and security issues.
[13:43] Despite bold claims about AI replacing
[13:45] humans, Microsoft's number of full-time
[13:47] employees has continued to increase.
[13:50] Perhaps the most egregious case of AI
[13:52] hype comes from Black Rockck, which is
[13:54] the world's largest asset management
[13:56] company. Black Rockck is a major
[13:57] investor in AI infrastructure. In 2024,
[14:00] they created a new subsidiary called the
[14:02] Black Rockck AI Partnership, which
[14:04] invests tens of billions of dollars into
[14:06] AI data centers. Black Rockck CEO Larry
[14:09] Frink is a huge proponent of AI and
[14:11] claims that his company is deploying AI
[14:12] internally to improve efficiency. In
[14:15] January of 2026, Think spoke at the
[14:17] World Economic Forum where he boasted
[14:19] about the revolutionary impact of AI
[14:22] &gt;&gt; with your data. I could just tell you
[14:24] from at our firm things that would take
[14:26] 12 hours to compute now takes minutes
[14:30] for us processing 14 trillion dollars of
[14:33] other people's money with hundreds of
[14:34] thousands of different um mandates um we
[14:38] could do that instantaneous and we you
[14:40] know that to me if it wasn't for the
[14:42] technology and AI today we would not be
[14:44] able to function to the scale that we're
[14:46] operating.
[14:47] &gt;&gt; Black Rockck manages $14 trillion of
[14:49] client assets. Black Rockck's operations
[14:51] are so complicated that it's not
[14:53] possible to manage without AI. Without
[14:56] AI, Black Rockck could not function at
[14:57] its current scale. There are a few
[14:59] problems within narrative. Generative AI
[15:02] only became widely available after Chat
[15:04] GBT was released in 2022. Before then,
[15:07] Black Rockck was not using Generative AI
[15:09] to any significant degree. Back in 2021,
[15:12] Black Rockck already had $10 trillion of
[15:14] assets under management. That's within
[15:16] the same order of magnitude of what they
[15:18] manage now. They were able to function
[15:20] just fine in 2021 without AI. Even after
[15:23] Black Rockck started implementing AI,
[15:25] they continued to hire more employees.
[15:27] Again, no sign of any AIdriven job
[15:30] losses.
[15:31] When you use LLMs, they can feel like
[15:33] they are very capable. They feel like
[15:35] maybe they should be able to replace at
[15:36] least some human workers. But when left
[15:39] on its own, AI is surprisingly
[15:41] incompetent. In October of 2025, an
[15:44] organization called the Center for AI
[15:46] Safety published a study called Remote
[15:48] Labor Index, measuring AI automation of
[15:50] remote work. The study was funded by
[15:52] Scale AI. One of the co-authors is
[15:55] Alexander Wang, who is a co-founder of
[15:57] Scale AI and is currently the chief AI
[15:59] officer of Meta. They went on to
[16:01] freelancing platforms such as Upwork and
[16:03] Fiverr. They found freelancing jobs that
[16:06] in theory an AI should be able to
[16:07] complete. For example, build a web page
[16:09] for data visualization, create a 3D
[16:12] rendering of a product, or animate a
[16:14] short video. The average cost for these
[16:16] freelancing jobs was $632.
[16:19] They tested many different AI models to
[16:21] complete these freelancing tasks. The
[16:23] results were atrocious. The best
[16:25] performing AI agent was Manis. Manis
[16:28] creates AI agents powered by multiple
[16:30] frontier LLM. Even it only had a 2.5%
[16:33] success rate. They gave Manis hundreds
[16:36] of freelancing tasks. Only 2.5% of the
[16:39] time did it complete the job acceptably.
[16:41] Success is defined as creating an output
[16:43] that a reasonable buyer on Upwork or
[16:45] Fiverr would accept. All the other LLM
[16:47] did even worse. In 18% of cases, the AI
[16:51] agent delivered corrupted files, meaning
[16:53] you couldn't even open the file. In 36%
[16:56] of cases, the project was incomplete. In
[16:58] 46% of cases, the project was completed,
[17:01] but the quality was so bad that a
[17:03] reasonable buyer would not accept
[17:04] delivery of it. In 15% of cases, there
[17:07] were inconsistencies.
[17:09] That means the AI did create a usable
[17:11] output, but it's different from what you
[17:12] asked for. In less than 2% of the cases
[17:15] did the AI complete the job
[17:16] successfully.
[17:18] The Center for AI Safety maintains a
[17:20] website called remote labor.ai. Every
[17:23] time a new AI model is released, they
[17:25] conduct the test with the new model.
[17:27] Subsequent to them releasing their
[17:28] original report, OpenAI and Anthropic
[17:31] have both released new models. As of the
[17:33] time of recording this video, the best
[17:35] performing model is Claude Opus 4.5. It
[17:38] has a success rate of 3.75%.
[17:41] This study was funded by Scale AI. Scale
[17:44] AI is a company that sells training data
[17:45] to LLM developers. They have every
[17:48] incentive to exaggerate the capabilities
[17:50] of AI. I give a lot of credit to Scale
[17:52] AI and Alexander Wang for having the
[17:54] integrity to publish this research which
[17:56] exposes the limitations of current AI
[17:58] technology.
[18:00] Daario Amade goes on TV and tries to
[18:03] scaremonger, saying that 50% of
[18:05] entry-level jobs will be replaced by AI
[18:07] within 1 to 5 years. In reality, his
[18:10] best model can't even complete 4% of
[18:12] freelancing gigs. If you can't even do a
[18:14] Fiverr gig, you definitely can't do a
[18:16] full-time job.
[18:18] To finish off this video, we need to
[18:20] debunk one of the most outrageous recent
[18:22] cases of AI scaremongering. On February
[18:25] 10th, 2026, a guy called Matt Schumer
[18:27] made a lengthy post on Twitter titled,
[18:29] "Something big is happening." In the
[18:31] essay, he claims that AI has reached an
[18:33] inflection point and will imminently
[18:35] take everybody's jobs. Schumer's post
[18:37] went viral, getting over 80 million
[18:39] views on Twitter. It was quickly picked
[18:41] up by the mainstream media. The entire
[18:44] essay was republished in Fortune
[18:45] magazine. Schumer was invited to give
[18:48] interviews on mainstream news outlets,
[18:49] including CNN and The Information. Once
[18:52] we look at Schumer's resume, you'll see
[18:54] why it's outrageous that this man is
[18:55] given any airtime at all. Matt Schumer
[18:58] is the founder and CEO of an AI startup
[19:00] called Hyperite. It is an AI based text
[19:03] editor. It is powered by a version of
[19:05] Meta's Llama open-source model. In
[19:07] September of 2024, Schumer claimed to
[19:09] have created his own open- source LLM
[19:11] called Reflection 70B. He started with
[19:14] Meta's open source Llama 3.1 model. He
[19:17] used an advanced technique called
[19:18] reflection tuning which enables LMS to
[19:21] fix themselves. This drastically
[19:23] improved his capabilities. Schumer
[19:25] claimed to have tested his new LLM on
[19:27] various benchmarks. On all the
[19:29] benchmarks, it performed better than
[19:30] Chat GPT. On most of the benchmarks, it
[19:33] performed better than Claude. If true,
[19:35] this would be a great achievement. Open
[19:37] AAI and Anthropic spent billions of
[19:39] dollars to develop their Frontier AI
[19:41] models. Matt Schumer, with a tiny
[19:43] fraction of that budget, created a new
[19:45] open- source LLM that performs even
[19:47] better. There's only one problem. It was
[19:50] all fake. Schumer made Reflection 70B
[19:52] open- source so anybody could test it.
[19:55] People soon found out that it was
[19:56] actually just a rapper that used
[19:58] Claude's API on the back end. People
[20:00] would give it prompts and would give the
[20:02] exact same output as Claude Sonet 3.5.
[20:05] Schumer set up Reflection 70B so that it
[20:07] wasn't allowed to say the word Claude.
[20:09] He didn't want the LM to call itself
[20:11] Claude. If you asked it to say the word
[20:13] Claude, it is programmed to only return
[20:15] blank text. Matt Schumer lied to the
[20:18] public. He said he created a
[20:20] groundbreaking LLM when in reality he
[20:22] created nothing. He just used the Claw
[20:24] API. He went through great lengths to
[20:27] hide this, but he was exposed
[20:29] nonetheless. The fact that the
[20:30] mainstream media takes this guy
[20:32] seriously is a testament to how gullible
[20:34] they are. You can read Matt Schumer's
[20:37] viral essay if you want. It's on his
[20:39] Twitter account, but it's extremely long
[20:41] and mostly not worth reading. 90% of it
[20:44] is hyperbolic assertions with zero
[20:45] citations or evidence. There's only one
[20:48] part where he makes specific claims. He
[20:50] says he started using Chad GBT 5.3
[20:52] Codeex. That's OpenAI's latest coding
[20:55] LLM. He says he made an app with Codeex.
[20:58] The app can even open itself and click
[21:00] buttons. Schumer does not explain what
[21:02] this app does. He does not provide any
[21:05] evidence that this app even exists.
[21:07] We're just supposed to take his word for
[21:08] it.
[21:10] All right, guys. That wraps it up for
[21:12] this video. What do you think about AI
[21:14] taking jobs? Let us know in the comments
[21:16] section below. As always, thank you so
[21:19] much for watching and we'll see you in
[21:20] the next one. Wall Street Millennial
[21:22] signing
