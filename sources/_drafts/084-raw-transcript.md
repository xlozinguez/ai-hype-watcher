[00:00] ChatBT starts out smart and then
[00:02] somewhere around message 15 or 20, it
[00:05] gets dumb. It forgets your instructions.
[00:07] It contradicts itself and it even makes
[00:10] stuff up. But here's what nobody tells
[00:12] you. There's a pattern. The same thing
[00:14] happens every time, right before your AI
[00:17] falls apart. I'm going to show you the
[00:19] warning signs to look for as well as the
[00:21] four tactics that can stop this from
[00:23] happening. Let's get into it. So, what
[00:25] do I mean when I talk about the AI
[00:26] getting dumber? Well, we can think about
[00:28] it as a whiteboard. Imagine the AI's
[00:30] memory, its brain, is the size of a
[00:32] whiteboard. And every piece of
[00:34] information we add to that whiteboard,
[00:35] as it fills up, the AI gets dumber. So,
[00:38] here we have maybe five messages going
[00:40] back back and forth between you and the
[00:42] AI. And 25% of that whiteboard is
[00:44] filled. Now, when I say messages, it
[00:46] includes what you give the AI, what the
[00:48] AI gives back to you, any files you
[00:50] attach to it, and also the AI's thinking
[00:52] process. All of that is information
[00:54] that's being added to this whiteboard.
[00:56] And as the whiteboard gets fuller, so
[00:58] say we get above the 25% mark, around
[01:00] the 60% mark, the AI's intelligence is
[01:03] still effective and it will still follow
[01:05] your instructions, but it's slowly
[01:07] starting to degrade. And once you get
[01:09] past the 60% mark, and we're getting
[01:10] around the 95% mark, the AI's ability to
[01:13] be effective and follow your
[01:14] instructions degrades rapidly. Now, the
[01:17] size of this whiteboard and the AI's
[01:19] ability to use information on it varies
[01:21] by the model you're using. And most of
[01:23] you are using likely one of three
[01:26] options. Either you're using chatbt,
[01:28] you're using claude, or you're using
[01:30] Gemini. I'm also assuming that you're
[01:32] using most of these tools in the UI
[01:34] itself. And each of them have different
[01:36] size memories, brains, andor in our
[01:38] analogy, whiteboards. So either it's
[01:40] going to have 60,000 tokens, 200,000
[01:42] tokens, or a million tokens. So what is
[01:44] a token? A token, simply put, is part of
[01:47] a word. And a good equivalent to
[01:49] understand how big these actually are is
[01:52] 60,000 tokens equates to around half of
[01:54] a novel. Say 120 pages. 200,000 tokens
[01:57] equates to around a novel and a half.
[02:00] And then a million tokens equates to 7
[02:02] to eight novels. And with chatbt, they
[02:05] do say that they actually have a 400,000
[02:07] token limit, which would be around 3ish
[02:10] novels. But what you get access to
[02:12] inside of the UI itself, that's going to
[02:14] be around 60k. At least that's what
[02:15] users say they're getting right now. So,
[02:17] this is the size of the whiteboard.
[02:18] Quick pause in your regular programming.
[02:20] This video is brought to you by me as
[02:22] always. So, two quick things. First off,
[02:25] below is a 30-day AI insight series,
[02:27] completely free. You'll get 30 insights
[02:29] in your inbox so I can apply AI to your
[02:31] business and your work. The second thing
[02:32] is if you'd like to work with me, Blow a
[02:34] series of offerings to see if there's a
[02:35] good fit between the two of us, such as
[02:37] a private AI community of business
[02:39] owners and leaders or one-on-one
[02:40] coaching. With that being said, let's
[02:42] get back into the video. And again, the
[02:44] goal of this entire thing is to utilize
[02:48] as much intelligence as possible before
[02:50] it starts to to degrade. And that's what
[02:52] this chart represents. So here on the
[02:54] vertical axis, we have the performance
[02:55] of the AI. On the horizontal axis, we
[02:58] have the context usage. So that's
[02:59] basically the the brain space that's
[03:01] getting filled up with the AI. And then
[03:03] these lines here shows the intelligence
[03:06] degrading over time. So if you do
[03:08] nothing and you just use the AI as is,
[03:10] the cut off point is going to be
[03:12] probably around 50% of the AI's memory
[03:14] space and the intelligence will start to
[03:16] degrade after that point. So the AI gets
[03:18] dumber. And if you use the tactics that
[03:19] I'm going to walk you through today,
[03:21] there's a chance that we can extend the
[03:23] ability of that AI to follow your
[03:25] instructions and keep the intelligence
[03:27] over a longer period of time. And before
[03:28] we actually start using those tactics,
[03:30] we need to first understand the warning
[03:32] signs of when we're approaching the
[03:34] degradation of the AI's intelligence and
[03:36] its ability to follow your instructions.
[03:38] So there are a few different warning
[03:39] signs you can see here that I'll walk
[03:41] you through. We first have the
[03:42] instructions getting ignored. The AI
[03:44] contradicts itself. It starts to forget
[03:46] facts you initially gave it. And then
[03:47] also there's an automatic compaction
[03:49] that occurs for different types of
[03:51] models which I'll show you later. We'll
[03:52] walk through each one of these. Now, the
[03:54] first one here is when the instructions
[03:56] start to fade in the AI's memory. And in
[03:58] this case, you'll eventually have to
[03:59] start repeating yourself over and over
[04:01] to get it to follow those instructions.
[04:02] As an example, say in this first message
[04:05] you give to the AI, you say, "I'm going
[04:07] to ask you a series of questions, and I
[04:09] want you to respond in under 200 words,
[04:11] so I don't have to read really long
[04:12] responses." And this will work for one
[04:14] back and forth, maybe five or 10 or 15
[04:17] back and forth with the AI. Well, you
[04:18] start to notice maybe around 16 or 20
[04:21] messages, the AI is giving you back
[04:23] 600word essays instead of the maximum
[04:26] count of 200 words. This is happening
[04:28] because we've filled up the AI's memory
[04:30] and it's forgotten the initial
[04:31] instructions we gave it. That's the
[04:33] first signal. The next signal is when
[04:35] the AI contradicts itself. So maybe at
[04:37] the beginning of a conversation, we've
[04:39] asked the AI how to specifically
[04:41] structure a presentation for a potential
[04:43] client when we're presenting our
[04:44] offering to them. and it initially
[04:46] stated that we should lead with the ROI.
[04:48] So, what's the return on investment for
[04:49] the offering we're giving to this
[04:50] potential client? But then we do a bunch
[04:52] of back and forth with this AI having a
[04:53] longunning conversation and we ask a
[04:56] similar question or we have it summarize
[04:59] the presentation and create the slides
[05:00] for us and it comes back to us and says
[05:02] it's actually important that we put the
[05:04] ROI at the end of the presentation and
[05:06] instead we build context first. Now, we
[05:09] know because we just had the
[05:10] conversation with the AI that this
[05:12] actually contradicts what it initially
[05:14] stated. And this again is a sign that
[05:16] we've filled the AI's memory and it's
[05:18] starting to get dumber in this case.
[05:20] That's our second warning. Our third
[05:22] warning is when facts start to
[05:24] disappear. So, this is when you're
[05:25] having a longunning conversation with an
[05:26] AI and you give it a series of
[05:28] statistics or facts to remember in the
[05:29] beginning, but over time it starts to
[05:32] either hallucinate those facts or
[05:33] completely ignore them in in their
[05:35] entirety. As an example, say we're
[05:37] having a conversation with an AI about a
[05:39] project and at the very beginning of the
[05:40] conversation, we state that we want the
[05:42] price we want to price this project at
[05:43] $9,000. But near the end of the
[05:45] conversation, when the AI is drafting
[05:47] that proposal, it changes the price to
[05:49] $6,500. If nothing happened in between
[05:52] while it should change that price, it
[05:54] likely what happened is it just forgot
[05:56] the fact that you wanted to price it at
[05:57] 9K in the beginning. This is the third
[05:59] warning sign. And the fourth one is very
[06:01] explicit and obvious to see. So, if
[06:03] you're using Claude specifically, it's
[06:05] going to have an automatic compact
[06:08] happen in the conversation. What do I
[06:10] mean by compact? Well, what happens is
[06:12] in the background, Claude is
[06:14] automatically assessing how long the
[06:16] conversation is. Once the conversation
[06:18] gets to around 90% or 95%,
[06:21] the AI is going to automatically
[06:23] summarize this entire conversation. It's
[06:26] going to insert a new AI in that same
[06:28] thread. It's going to pass it that
[06:30] summary and it's going to continue that
[06:31] conversation with you. You'll know that
[06:33] this is happening if you read inside the
[06:36] section where the AI is thinking. It
[06:37] says, "I'm organizing my thoughts or
[06:39] it'll say I'm compacting the
[06:40] conversation." It'll make it very clear.
[06:42] Now, this can be useful for some people
[06:44] that are using Claude. But the issue I
[06:46] have with this is we have no say in
[06:48] what's being summarized above. It could
[06:51] be summarizing things generically and
[06:53] the conversation gets worse as we go on.
[06:55] But note, this is just for Claude today,
[06:57] but I guarantee that Chatbutt and Gemini
[06:59] will follow suit and add this feature as
[07:01] well, where they have an automatic
[07:03] summarization occurring once you get to
[07:05] a certain part of filling up the AI's
[07:06] memory. And that's our fourth warning
[07:07] sign. Now, one tactic I want to share
[07:09] with you before we actually get into the
[07:10] ways that we can mitigate this is
[07:12] knowing actually how many tokens you're
[07:13] using. Sadly, all the tools that you use
[07:15] today within the interface of the UI,
[07:17] such as Chatbt, Claude, and Gemini, they
[07:20] don't explicitly show you how much of
[07:22] the memory is being filled. This feature
[07:23] already does exist in coding tools,
[07:25] which means I'm sure this will be ported
[07:27] over to the UIs that we're all using
[07:28] today eventually. But in the meantime,
[07:30] what you can do, and this is something I
[07:32] commonly do with my clients and myself,
[07:34] is if I have a longunning conversation
[07:36] or a large file, I'll upload it to
[07:38] Google's AI Studio. Let me actually show
[07:40] you what that looks like. Okay, so what
[07:41] we have here is Google's AI Studio. So
[07:43] all you have to do is go to a
[07:44] studio.google.com.
[07:46] You want to then click on the playground
[07:48] here on the lefth hand side. And then
[07:49] you'll see something like this. All you
[07:51] need to do is drag and drop a file into
[07:53] the chat box down here. Or you can
[07:55] select the button here to upload the
[07:57] file directly. I'll drag and drop a file
[07:59] to show you the context window that's
[08:01] being shown. So I drag and drop it here.
[08:02] You can see that box pops up. Now this
[08:05] file, what's going to happen is it's
[08:06] loading the file into it. And you can
[08:08] see immediately it shows me that this is
[08:10] 5,735 tokens. Now this is useful to know
[08:13] because remember in the slide that I
[08:15] showed you previously, we have a good
[08:18] idea of how many tokens each AI can
[08:19] take. So, if I know that I'm giving the
[08:21] AI 5,000 tokens, any of these can handle
[08:24] that easily. So, as a rule of thumb, I
[08:27] recommend to use Google's AI Studio to
[08:30] best understand how many tokens you're
[08:32] using either in the entire conversation
[08:33] you've had already. So, you can copy and
[08:34] paste the entire conversation into AI
[08:36] Studio to understand how many tokens
[08:38] you've used so far and how much of the
[08:39] memory of the AI you've already filled.
[08:41] Or if you just have a large file like a
[08:43] PDF or something else and you want to
[08:44] see how big it is, you can drop that in
[08:46] there to see how many tokens it is. So
[08:47] that's just a a good little trick I
[08:49] recommend everybody take advantage of
[08:51] when trying to mitigate the AI getting
[08:52] dumber too quickly. Now onto our four
[08:54] primary tactics of how we can actually
[08:56] extend the intelligence of these AIs. So
[08:58] the first primary tactic is going to be
[09:00] the handoff approach. So this is
[09:02] basically taking the previous point that
[09:04] I made around claude and how it does an
[09:05] automatic summary. We're going to take
[09:07] that idea we're going to apply to our
[09:09] own situation so we can make very custom
[09:10] tailored handoffs. And this is what the
[09:12] flow looks like. So, say that you're
[09:14] having a conversation with an AI over
[09:16] here. And in that conversation, you
[09:18] start to either see two things. One is
[09:20] you've copy and pasted the entire
[09:21] conversation into AI Studio and you
[09:23] realize that we're getting around that
[09:25] 60% point and it's time to move on to a
[09:27] new fresh conversation or you start to
[09:29] see the AI's intelligence degrading and
[09:31] getting dumber. Either way, we know it's
[09:33] time to start a new conversation. So,
[09:35] the first thing you do is you open up a
[09:37] new tab inside of your browser and you
[09:38] start a fresh conversation with a new
[09:40] AI. You then go back to your other
[09:42] conversation that's starting to degrade.
[09:44] You want to ask the AI to summarize the
[09:45] entire conversation answering these four
[09:47] questions. What have we covered so far?
[09:49] The most important points. What have we
[09:51] what big decisions have we made
[09:53] throughout this conversation? Where have
[09:54] we left off based off of all the to-dos
[09:56] we have here? So, we probably have done
[09:58] some things. We still have a lot of
[09:59] things left. I want you to let us know
[10:01] where we are sitting in that to-do list.
[10:03] And then finally, I want you to give a
[10:05] very specific ask to the next AI on what
[10:07] it needs to do next. By giving it this
[10:09] ask either through a dictation or typing
[10:11] it out, the AI will give you a very
[10:13] specific tailored summary for the things
[10:15] that you care about in that context.
[10:18] You then copy and paste this summary
[10:21] into that new chat that you created in
[10:22] that new tab and you hit enter. That
[10:25] next AI will pick up where the other AI
[10:27] dropped off. So what we're doing here is
[10:29] we're basically refreshing the AI's
[10:31] memory and getting a fresh start with a
[10:33] new AI and a new memory. And this is our
[10:35] first tactic is the handoff process. The
[10:38] next tactic is really understanding the
[10:40] files that you're giving the AI. So some
[10:42] files are bigger than others. And also
[10:43] when you give a big file to an AI,
[10:45] sometimes it doesn't necessarily need
[10:46] that entire file. Maybe you can slice
[10:48] off a certain part of it just for that
[10:50] specific task you're giving to the AI.
[10:51] So we want to be strategic with the
[10:53] files that we choose. So first off, we
[10:55] need to understand the nature and the
[10:56] size of different files. So when you're
[10:58] giving a word document, a text file, or
[11:00] something else to the AI, these are
[11:02] cheap because they're smaller. And it's
[11:04] okay to assume that these these files
[11:05] are smaller and they're not going to
[11:07] fill the AI's memory so much. Next, we
[11:08] have PDFs. So, this will depend on the
[11:11] complexity of the PDF, meaning are there
[11:12] a bunch of diagrams, images, and things
[11:14] like that and or the size of the PDF. If
[11:16] they're overly complex or overly large,
[11:18] we can assume that this is going to fill
[11:20] the AI's memory much faster. But if not,
[11:23] then it's okay to drop those in. I would
[11:24] say if the PDF itself is over 120 pages,
[11:27] you probably want to drop an AI Studio
[11:29] just to see how many tokens it takes.
[11:30] But if it's anything below that, most
[11:32] AIs can handle that pretty easily. Next
[11:33] we have images. Now we can just assume
[11:35] straight off that images are going to
[11:37] fill up the memory faster just because
[11:38] of the nature of the file. And after
[11:40] that we have Excel sheets. Now this is
[11:42] varied by the Excel sheet. So if it's a
[11:44] really complex Excel sheet that has many
[11:45] different tabs, many columns and rows,
[11:48] AI tends to right now at least struggle
[11:49] with being able to do complex
[11:51] calculations and models on these
[11:53] specific Excel sheets. So there's one
[11:54] caveat here. If you have the Claude
[11:56] plugin for Excel set up, it may be able
[11:59] to do some more complex actions because
[12:01] of how that's built. But that's only if
[12:03] you have that plugin for Excel right
[12:05] now. And then finally, we have video
[12:06] files. So if you're dropping a video
[12:07] into an AI, we can automatically assume
[12:09] that's going to fill the AI's memory
[12:11] very quickly. So if you have a video
[12:13] that's longer than 2 to 5 minutes, it's
[12:15] going to fill up the entire thing, and
[12:16] you need to probably use Gemini since it
[12:18] has the biggest memory right now. So
[12:20] that's understanding the token cost or
[12:21] how much memory we fill per file type.
[12:24] Now, after we understand this, there's a
[12:25] few things that we can do with the files
[12:26] we're sharing with our AI. First, as I
[12:28] mentioned, we can always just check how
[12:30] many tokens this this file fills by
[12:32] using Google's AI Studio. After that, I
[12:36] recommend depending on the file and the
[12:37] task you have at hand, instead of giving
[12:39] the entire file to the AI, maybe you cut
[12:41] it up into chunks and you only give the
[12:42] AI what matters for that specific task.
[12:45] And this is beneficial for two reasons.
[12:46] One, we're not filling up the memory,
[12:47] but also we're not distracting it with
[12:49] irrelevant information. And then finally
[12:51] is if you have a massive Excel file and
[12:53] you want the AI to do something with
[12:55] this, there's likely one tab in this
[12:56] file that matters. As long as all the
[12:58] tabs aren't interconnected in some
[13:00] convoluted way, we can export that
[13:02] specific tab as a CSV file and upload
[13:04] that into the AI and it'll likely do
[13:06] what you needed to do with that specific
[13:08] tab. And those are the three tactics of
[13:10] how you can kind of mitigate the file
[13:11] type. Now, on to our third tactic, which
[13:13] is experimentation. This is all around
[13:14] building intuition, specifically
[13:16] understanding how complex of a task AI
[13:18] can deal with today. And the way that
[13:20] we're going to do this is through the
[13:21] learning cycle. So the first thing is
[13:23] we're going to drop a task into AI. And
[13:24] these tasks can be complex because we
[13:26] want to push the capabilities of what AI
[13:28] can do today. So we drop this in. We're
[13:30] going to observe the results. One of two
[13:31] things happen. Either the AI surprises
[13:33] us and it achieves it flawlessly. So
[13:35] that then updates our intuition of
[13:37] understanding what AI can do today based
[13:38] off the advancements these labs are
[13:40] pushing. And the second thing is the AI
[13:43] fails. If it fails, then what we need to
[13:45] do next is we need to adjust adjust the
[13:47] complexity of the task. So we need to
[13:49] take that task we initially dropped in
[13:50] there. We need to break it into smaller
[13:52] tasks and have multiple AIs take on
[13:55] different elements of that task. So
[13:56] maybe we open up three tabs with chatbt
[13:58] and we have one tab working on one part
[14:00] of the task, the second tab on the
[14:02] second part of the task and the third
[14:03] tab on the third part of the task. And
[14:04] running through this cycle, we're
[14:06] building intuition of what's possible
[14:07] with AI today. And we're going to then
[14:09] update our understanding of the types of
[14:11] tasks we can give off to AI right now.
[14:13] Now that's our third tactic,
[14:14] experimentation. Our fourth tactic is
[14:17] strategic summaries. Now there's two
[14:19] important caveats for this. So the first
[14:21] caveat is this is mainly for people
[14:22] using chatbt and Gemini. The second
[14:24] caveat is this is for the people that
[14:26] are unwilling to use the handoff
[14:28] strategy. So if you for some reason feel
[14:30] like you have to stay in the same
[14:31] conversation thread and you're unwilling
[14:33] to summarize it and go to a new
[14:34] conversation, this tactic's for you. So
[14:36] what we're going to do in this tactic is
[14:37] we're going to do the same thing that
[14:39] Claude does reactively. We're going to
[14:40] do it proactively. So all these dots
[14:42] represent an ongoing conversation with
[14:44] AI. And what we're going to do is every
[14:47] 5 to 10 exchanges with the AI, we're
[14:49] going to proactively ask the AI to
[14:51] summarize what we've done so far and
[14:54] then continue working in that
[14:55] conversation. So if we decide to do this
[14:57] every five exchanges, I'm probably
[14:59] assuming that you're having really long
[15:01] exchanges back and forth with the AI,
[15:03] meaning you give it a file, it gives you
[15:04] a long response, you give it a file, it
[15:06] gives you a long response. we're filling
[15:08] up the AI's memory much quicker, which
[15:09] means we need to do this refresh sooner.
[15:12] If we're doing it every 10 to 15
[15:13] exchanges, that probably means that
[15:15] you're having short back and forth with
[15:16] the AI. Gives you a short question, you
[15:18] give it a short answer. So, the AI's
[15:20] memory is filling up slower. And it's
[15:21] important to note when we do this
[15:22] refresh here, we want to ask the AI the
[15:25] same things we asked it in the handoff.
[15:26] We need to ask, what are the primary
[15:27] things we've achieved so far? What are
[15:29] the key decisions we've made throughout
[15:30] this conversation? Where are we leaving
[15:32] off based off of all the to-dos we have
[15:34] for this overall task? and what specific
[15:36] steps are next after this. And then I
[15:38] would also ask for it to make sure that
[15:40] that summary is very brief because we
[15:42] don't want to unnecessarily fill up the
[15:43] memory with a bunch of jargon that's not
[15:45] needed. Once we have this summary, we're
[15:46] then going to ask the AI to continue the
[15:48] conversation. We then do it again after
[15:50] 5 to 10 exchanges, maybe 15. Then we
[15:52] keep doing this. And the reason we keep
[15:54] doing this is we're going to extend the
[15:56] runway. Without this tactic, the AI's
[15:58] intelligence would drop off much faster.
[16:01] With this tactic, we can extend its
[16:03] intelligence. It'll eventually still
[16:04] drop off, but we can extend its
[16:06] intelligence over time. And again, this
[16:08] is only for the people that insist that
[16:09] they stay in the same thread. And those
[16:11] are four tactics. So, as a quick recap,
[16:13] the first one is the handoff summary.
[16:15] So, summarizing that conversation,
[16:17] opening up a new tab with a new AI with
[16:19] a new memory and giving in that new
[16:21] handoff summary. We're starting fresh.
[16:23] The second one is strategic file choice
[16:26] and parts of files. So, first we need to
[16:28] understand which files are cheap and
[16:30] which ones are expensive. And then we
[16:31] need to know if the entire file is
[16:33] needed or if we can cut off part of the
[16:34] file and give it to the AI so we're not
[16:36] filling its memory with irrelevant
[16:37] information. Then we want to work on
[16:39] experimentation so we can build our
[16:40] intuition and our understanding of how
[16:42] complex tasks AI can take on. And if the
[16:45] task is too complex for the AI to do, we
[16:47] want to break it up into subtasks and
[16:48] have different AIs take it on in
[16:50] different tabs. And then finally we have
[16:51] strategic summaries. So this is for
[16:53] people that are using chat and Gemini
[16:55] and insist on using the same
[16:56] conversation without starting a new one.
[16:58] And that's when we can do we can extend
[17:00] kind of that runway over time by having
[17:02] the AI write brief summaries throughout
[17:04] the overall thread to refresh its memory
[17:07] on what it needs to refer to and
[17:08] understand. And that's it. So, as a
[17:10] reminder, two quick things. First off,
[17:12] Blow is a 30-day AI insight series,
[17:20] is if you'd like to work with me, blow a
[17:23] good fit between the two of us. Now, you
[17:25] know how to stop AI from getting dumb.
[17:27] But here's a much bigger problem. Your
[17:29] smartest employee, everything that makes
[17:31] them great is stuck in their head. And
[17:34] if they leave, that knowledge leaves
[17:36] with them. I made a video that shows you
[17:38] how to pull all of that knowledge out of
[17:40] their head and spread it across your
[17:42] entire team using AI. It's right here.
[17:45] So, go ahead and check out that video.
[17:46] Click that video and I'll see you next
[17:48] time,
