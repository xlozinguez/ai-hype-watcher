# Raw Transcript: You're using Claude Code Wrong - These 10 Tips Will Change Everything

- **URL**: https://www.youtube.com/watch?v=V9atNrDjnZs
- **Duration**: 20:27
- **Captured**: 2026-02-13
- **Method**: yt-dlp VTT extraction

---

[0:00] If you're using claw code the way that most people do, you're leaving a huge amount on the table. And it's not because the tool itself is limited, but because of how you're approaching it. So most tutorials show isolated tricks, and what they don't show you is how those techniques can compound when used together. So in this video, I'm walking you through 10 claw code techniques that build on each other, starting with changes that immediately improve your results and ending with workflows even experienced users or most never use. So whether you've just opened Claude code for the first time or you run it daily,

[0:31] stick around because by the end of this you won't just work faster. You'll be able to use Claude in ways that probably haven't even crossed your mind yet. Now let's start up with the newly releasleased agent teams. Now most people are either running one clawed code session or starting to use sub agents. And that's fine for simple tasks, but if you're working on more complex projects, it's not good enough anymore. So agent teams let multiple clawed instances work in parallel as well as talk to each other. So before the agent teams feature was released a few days ago, people tended towards

[1:01] using sub agents which had this delegation architecture. So we had the main parent agent delegating to individual sub aents. So say we had a content writer as our main agent and we wanted help from a researcher and we wanted help from a content reviewer as well. Those would be specialist sub aents that would have delegated tasks from that main agent and pass their outputs back to the main agent. The problem as you start to expand the scope of this project is that we've got more sub aents feeding into this main agent and we end up with a communication bottleneck. Those sub aents aren't able

[1:32] to communicate to each other and therefore everything must be processed by that main agent. Now in contrast to the new architecture the claude code agent teams we have a main agent again which is able to talk to those teammates or sub agents but the key differences here are one they have a shared task list so each teammate can contribute and pull from that shared task list but also they can talk to each other so they know exactly what's going on by collaborating with their other teammates as well as the shared task list as well as still maintaining the ability to talk to the

[2:02] main agent which act as an orchestrator here. Now, this obviously comes at higher cost because more conversations between agents means higher use of tokens. So, there's only certain use cases in which I'd recommend this. Super easy to install. You just add this line to your settings.json file and then make sure you run clawed update so that you're on the latest version where it's accessible. But the tip is actually all around where not to use this because from my non-development use cases, there's not many areas where I'd actually start to use this. So the first area where I would not use this is

[2:32] creating an agent team that researches and writes my social media posts for LinkedIn and X where we have three agents. We have a researcher, we have a reviewer and we have a writer. The exact framework we talked about up here. Now the reason I would not use it here is the scope is really limited. We're just writing say for example 5 to 10 social media posts. So actually can be done with probably a single task and at best it has three different agents that don't need to collaborate with each other. The researcher doesn't need to talk to the reviewer. It does need to pass information back to our main agent, the

[3:02] writer. And the reviewer also passes information back to the writer. But they don't need to cross collaborate between each other. So it's totally overkill for this use case. Now, where agent teams start to shine is when you start to have more complex projects where cross collaboration is critical. So, in the same content creation flow, we could have dropping a YouTube transcript into a project folder, getting teammate one to write a long form SEO optimized blog article, teammate 2 to write a LinkedIn carousel script focusing on hooks, and teammate 3 to write an email newsletter version. And what we want from this

[3:32] project is there not to be any contradicting hooks or contradicting information across one, two, and three. And therefore, we're starting to actually need some collaboration between teammates one to three, like what angle are you working on so I don't duplicate that angle? But where it really starts to shine is when you have really complex apps. So say for example, we're building an X.js app. With Stripe, we have three different agent layers, all with their own complexities. We have the API layer, we have the front-end layer, and we have a testing agent that goes out and does all the testing and creates those tests. Now, the API agent and the front-end

[4:03] agent are constantly going to need to talk to the test agent so the test agent can spin up their own tests. This in the sub aent format would become a bottleneck because the main agent is actually handling too much of the delegation. Whereas, if they have a shared task list and they're able to collaborate with each other, this becomes a lot more effective. That being said, it's going to be quicker but still more expensive. And by the way, with agents, you can bypass the lead entirely. Navigate to a specific teammate like the testing layer using shift up and down on your keyboard and you're then able to give tasks to a

[4:33] specific agent. So, I'd summarize it by don't start with agent teams. Start simple. graduate to sub agents and then when you reach the point where the complexity and the collaboration is necessary then reach for agent teams. Now tip number two and these three get confused constantly hooks skills and slash commands but I'm going to give you a really simple way to remember them. So slash commands kept in the doclaude folder inside commands just have one single markdown file and think of this as you press a button and action is taken on you telling it to take that

[5:03] action. So we might have slashlin posts where we write three LinkedIn posts about a certain topic. We can look inside the MD file and it's like write three LinkedIn post variations and we pass our arguments in. So we'd run it by going / LinkedIn post and we'd now pass our arguments. So say we wanted to write about MCPS. We'd write three LinkedIn post variations about MCPS. When that starts running, you'll see that it starts to actually require certain skills. So it's starting to use the humanizer skill and the brand voice skill. So it brings us on to skills

[5:33] where unlike slash commands, we're not telling it to use it at that specific time and activating it by pressing a button. Claude understands from the description of the skill when to use that skill. So skills can be more comprehensive and Claude understands when to use them rather than us telling them when to use them. So for example, inside our Claude skills, we might have a brand voice skill. It might have examples for the brand voice for different platforms like LinkedIn X and Instagram. It might have a band words list and then it will always have a skill.md which gives this description

[6:04] which tells claude to always use the brand voice guidelines for every time it writes social media content. That's how it knows to use that skill. Now we back that up by putting a line in our claw.md file. Every time you write some content, make sure to use these skills. But actually it would know without the claw.md file from this description to use that skill. So skills are more comprehensive. You can give more context than you can with commands which just have one file and they also are invoked automatically by claude. Hooks completely different. Hooks don't require any LLM tokens at all and it's

[6:34] for stuff that can be done programmatically without the need for AI. So we might for example for our content flow have a band word checker. We'd add this to our settings.json JSON file. And what that would basically do is tell us if there are any output drafts added to that file, then make sure to check them for these band words and report back whether those words were found or not. So if you think about the full content pipeline, we would run /in post to write about MCPS. Claude would understand and use the brand voice skill automatically and the hooks would then check for the band words in the

[7:04] background. So they work together as a three. It brings us nicely onto tip number three. The one tip I'll give you for claw.mmd files, which is point don't dump. So most people dump their entire brand guide, the content pillars, the brand voice, the audience research and example post into their claude.mmd file. Do not do that. Keep claw.md lean and point to where the detail lives. Don't dump the detail itself. So the recommendation is 20 to 30 lines in your claude.md file and this is loaded into the context every time you have a conversation with Claude. So what you

[7:35] want to do is only include the relevant context and then point it to the other bits it will need to know at certain times. So if it's writing some content, it knows to look in the skills/humanizer to understand how it should write. Same as the brand voice there. So Claude can read those files only when it needs them and therefore you get a clean scannable claude.mmd that doesn't eat up your context window cuz you're not passing in too much information every time. Which brings us nicely onto plugins. So, we've got skills, we've got hooks, we've got slash commands. But what if you want to share a collection of those with someone

[8:05] else or install somebody else's setup? This is where plugins come in. And they're not additional to those. They're actually just how we distribute it or how we get it on our own system. So, it's just a package of skills, commands, and hooks, as well as potentially agents so that we can install them in one go. So, we've got Claude plug-in marketplace, and we add a certain plugin from a plug-in marketplace. And with those two commands, you've literally got all of their command, skills, and hooks. So, an example for a content creation might be that somebody has a Reddit research plugin. It includes a skill

[8:35] that teaches Claude how to analyze Reddit threads. It includes a Reddit research command that triggers deep research. And it also includes a hook that automatically summarizes our findings of those two into a mark down file. Instead of installing three individually, we run these two commands on the plug-in. We get the whole workflow straight away. So, think of it as a package collection of skills, hooks, commands, and agents. Install it once and get the whole workflow. Now, one thing I will say is the ecosystem for plugins is still very dev focused, but the concept is very powerful and hopefully there'll be less dev focused

[9:05] plugins coming to claw code. So, tip number five is going to help you search and bring back up context that you've lost from previous conversations. So, so you can load up claw code and ask something like what have we spoken about in the last week in all my projects? Give me a summary. And they live in this Claude projects global file. So, I'm going to run that and it should hopefully come up with a summary of exactly what we've spoken about. and then ask if I want to pick up on any of those conversation topics. You can search this manually by actually running the command line, but just to be honest, ask Lord Code to do it for you because

[9:35] it's much quicker. So, three of our last six projects had activity. The other three had no recent conversations. It's gone and given us a breakdown of all the different projects, the number of sessions and a general summary of each session as well and what came out of it. And then I can dig into details like tell me more about the agent teams that we created in the claw code demo folder when we explored agent teams. And it will obviously go and restore that history. So this is really useful for bringing back up context again or continuing a conversation that's been previously closed. So tip six is all

[10:05] about research workarounds. So claude code infamously can't access every site. So if you want data from things like Reddit, some news sites, paywalled content, it will be just blocked. So whenever you try to run this, you'll get claw code is unable to fetch from Reddit and then it will go and do some web searches around the topics, but it won't actually pull specific details from a tool like Reddit or X. Now this tip is from YK in his 45 claude code tips and I'll leave a link in the description below. There's some brilliant tips inside here and one of them is this

[10:35] research workaround. So actually you should get Claude to install the Gemini command line interface as a fallback. So if it can't search Reddit, then Gemini actually has broader web access. So what we're going to do is basically install the Gemini command line interface. Going to leave that running. And then we're going to add a Reddit fetch skill. So inside the skills, we'll have this Reddit fetch with the skill.md. And we're going to say when asked to fetch content from Reddit or other block sites X. It's going to start a teamwork session. It's going to use the Gemini command line interface to actually give it a prompt. Gemini, go and fetch and

[11:06] summarize and then give it URLs. It's going to capture the output and return the results. So, it's a workaround to go and get information from Reddit or other sites that you set up for it by actually accessing through Gemini, which has broader web search than claw code. Gemini's CLI is installed. We're going to now need to actually restart our instance to get this skill to be registered. We're going to ask it to fetch this Reddit thread and summarize it. And we've just got a random Reddit thread here from the artificial intelligence subreddit. It's successfully fetched the skill. So now it's been able to return the top posts

[11:36] from our artificial including the number of points, the number of comments, and a summary of what content is coming from that Reddit thread. Now I'll be honest, that last one struggled a bit. It didn't pull from a specific thread. It just summarized generalized information. But this next tip, which is 30 days of research in 30 seconds, is going to be a gamecher for this. So if you want trending topic research, whether that's you want to understand the latest prompting techniques, you want to understand what's trending and what the community is saying about a particular topic, then we're going to use this

[12:06] skill called last 30 days, which is able to scan Reddit and X for discussions in the last 30 days. Synthesize the patterns and deliver either copypaste prompts or comprehensive research that we're going to use. Credit to this GitHub repo here, which gives some more info about how it's actually used. We need to add our OpenAI API keys. We need to add our XAI API keys. So let's run this in the background and then we'll talk about usage. So we would effectively use it by using a slash command last 30 days and we'd say topic or topic for tool. So it could be prompting techniques for chat for legal

[12:37] questions iOS app mockups for Figma AI. What are the best rap songs? What are the LinkedIn hooks that are working right now? So trending topics on LinkedIn. And the way this differs is it's able to access specific Reddit and Twitter threads so that we're able to summarize that information succinctly so we don't hit those same pay walls. And the GitHub gives some great examples of where it's used and what the outputs are. If you want to see those outputs, we've got Claudebot use cases like community research, what were the best Claudebot use cases in the last 30 days, email calendar automation, we saw those already. Task management via chat,

[13:08] overnight coding agent, smart home and life admin, and browser automation. So we're going to get it to add our API keys. Then we're going to try it out. So then once we restart, we can run the command last 30 days and say exactly what we want to research. So, we're going to run three in parallel. SAS landing page mockups for an SEO tool. So, I want a nano banana prompt to generate SAS landing page mockups. I want the latest Claude code news. And I want AI automation YouTube content that's working right now. And you can see it says, I'll research AI automation YouTube content that's working right now across Reddit X and the web to find out

[13:40] what's been discussed in the last 30 days. It breaks down the topic, the target tool, and the query type. So for example, it's clearer on the SAS landing p page mockups for nano banana. The target tool is nano banana. The query type is prompting rather than general or trending topics here. Research typically takes 2 to 8 minutes. It's going to start that. We'll come back once it's finished and show you the outputs of all three of those. And this is super interesting. So for the nano banana prompts, it's come back that JSON structured prompts actually dominate nano banana, which I did not know. So

[14:10] the highest performing prompts always in JSON format with nested properties like visual style, preservation constraints and image prompts. Plain text prompts get less traction and basically this is the format that community has converged on. Website hero prompts already exist. Reality first system prompt is the hot technique that forces photorealistic editorial documentary quality and it's research six threads seen 240 up votes, 23 posts on X and 30 pages on the web. So it talks about which are the top voices and how many likes they've got. So, it backs up this with actual

[14:41] research and it's literally done that in 2 minutes 17 seconds. I'm now an expert on SAS landing page mockups for Nano Banana. What do you want to make? Let's do a 3x3 brand identity grid with dashboard screenshots all in one generation. And then we'll be able to actually put that inside Nano Banana and see what it comes up with. Whilst that's loading, let's take a look at the Claude Code news. Opus 4.6 launched Feb the 5th. Claude Code now accounts for 4% of all public GitHub commits. Not surprised there. Claude Code for marketing went viral. So, Savannah Feder's launch post hit 14K likes, announcing a version that

[15:11] browses, clicks, and posts like a human would. Claude Co-work hit Windows, etc., etc. So, it's gone through Reddit, X, the web, and Top Voices. Again, this is really cool. I'm liking this a lot. And then our final one was AI automation. YouTube content that's working right now. AI plus history is the breakout niche. New channels with only a few uploads are pulling 100K to 800K videos per view using hyperrealistic AI visuals and long- form storytelling. 3D skeleton animations, full end-to-end automation tools. So, let's jump back to the nano banana prompt. We've got the image prompt here. You can see it's in this JSON format with the type, the layout,

[15:42] the visual style. Says to swap the hex colors out for our actual brand palette and change SEO in the center tile to your product name. So, it's returned our 3x3 grids for the website itself, which mocks up some dashboards. And what I'm surprised about most is the consistency between these. So, I've run it twice, but you can see the prompt is actually so good that it's actually generated pretty consistently. You can see the laptop in the top left, project board with people on in the bottom right. We've got the project board again, slightly different text, but the laptop on the left. So, the consistency of this

[16:12] shows that it's actually gone out and put together a really consistent prompt. Whether we like the visuals or not, we can change those. So, definitely check out the last 30 days skill by Ronny Nutrition here. Now, coming back with tip number eight, which is built-in commands again by YK. These are super useful ones and you can use them super quickly and you'll use them fairly frequently. The first is slash clear. So it's going to clear up the conversation history and free up our context. So it's going to compress that context window and we start again. The second is / usage. So we can see our planned usage

[16:43] limit. So our current session we've used 15% of our actual Opus 4.6 usage and current week we've used 2%. So we've still got loads to go on our max plan. Here we can get usage over time with the command stats and we can see that our usage over time I've only recently started using this and I've had 201 sessions and my longest session has been 1 day 21 hours and it gives this nice little finish. You've used the same number of tokens as the book Moby Dick or you've used 24 more tokens than War in Peace. Now tip nine is all about

[17:13] getting the output into the format that you want. So you're often working between apps. Say you're working to create LinkedIn posts using claw code and you don't have your MCP connected to your LinkedIn. What you would actually tell Claude to do is just copy it directly to your clipboard. So we don't need to go in uh to the file itself C etc. We can just say add a LinkedIn post to my clipboard. You all know the pain when you're copying between chat or claude and LinkedIn and it doesn't have the correct formatting. The bullets are lost. The emojis don't appear. The bold

[17:44] doesn't appear etc. But when you use this function here, you can actually one ask it to write in LinkedIn native format with no markdown headers. Just use emoji bullets and it gives the examples instead of that. And two, ask it to just copy it to your clipboard and it will copy to your clipboard. You'll take it to LinkedIn. You'll paste it on here and obviously we've got three variations in here. But you can see the formatting of bullets and arrows etc. are maintained throughout there. So it's makes it super simple to work between different platforms. And a trick for this is also to copy it directly into a

[18:15] notion page which then enables the conversion to be done really easily. So if you're not working in LinkedIn and you're not doing it in a LinkedIn native format, always post it into a new notion page. It will maintain that markdown formatting and then notion supposedly when you copy from notion will convert to the output format of whatever platform you're using. Now this doesn't seem to work very well for LinkedIn. Hence I asked it to do a LinkedIn native format. The key point is you can actually just get it to copy directly to your clipboard with no effort at all. And tip number 10 is something we've all come across, which is Claude confidently

[18:46] writing a statistic or claim and not actually going through and verifying that. So, a quick tip here is to actually just tell it double check every claim and statistic and make a table of what you could and couldn't verify, including the source. It's now got a bunch of uh versions of posts about MCPS with facts in them. Each post uses different facts so they don't feel repetitive. And I'm now going to say double check every claim and statistic, make a table of what you could verify. So it's going to come up with the source, what has been verified, etc. So it's a double check before we're posting

[19:16] any information with facts that are potentially hallucinations are not true. And this demonstrates it really well because we've got the fact check table in a markdown document and all of the claims it's made. Eight claims in three different versions used in these versions either verified. So MCP launched November 2024. That is been verified. Downloads 100K to 8 million in five months. Is unverified. So it's got no primary source, no methodology cited, and it's a single blog. So it's saying that's not proof enough. Somebody's just said that including these cannot verify,

[19:47] cannot verify. So if there's no multiple sources there, it's going to tell us we cannot verify it. And it's going to say remove claims 5 67, soften claims 2, and three, or swap for official numbers. So even in just asking it to do that, it's gone out and got a single point of validation and called it a fact. And now we have a way to actually fact check that and make sure that all the facts that we're putting out there are actually verifiable facts. Now that rounds up the 10 tips to use Claude code more effectively. These are going to be

[20:17] absolutely fundamental for my different workflows and I hope they'll be for yours as well. If you want to check out a deeper dive into claude code, then check out the next
