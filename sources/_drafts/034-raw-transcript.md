# Raw Transcript: 034
[0:00] Well, you had an excellent YouTube that I'll be linking in the show notes about
[0:30] astonishment thing. You know what? Just run the tape. Tell me a little bit about
[1:00] Yeah. I had to I could imagine you when I was recording that video. I was like,
[1:30] It really catches my attention because I have a foot in both of these worlds. Um,
[2:00] one. So that is where you you will omit certain facts and put loosely related uh
[2:30] nothing to do with AI, but you put these things next to each other, you give that
[3:00] mining digital ick. So to me that's any AI story where you take an example from
[3:30] print journalism phenomenon but that's where every single thing that happens in
[4:00] I the only disagreement I'll have is that you would say that this isn't the
[4:30] around anything, you are you are wrong. I was about to call you a name, but I'm
[5:00] because you can't build your own word or what have you. I don't think you could,
[5:30] Claude code and these other command line interface agents can do really cool
[6:00] I would like you to be like completely like give people the actual explanation
[6:30] and it works with a file system. You can write files, edit files, send files to
[7:00] this sentiment of oh it's doing such cool things over in the world of command
[7:30] article I reported was oh it turns out like everything else we do on computer
[8:00] Well, it means a lot. like it's okay in code because they say, "Oh, that that
[8:30] Claude Code stuff and there was there's been a very big consent manufacturing
[9:00] because she was able to vibe code a some sort of Monday clone which is just like
[9:30] are able to find a lot of people who are invested in AI who will absolutely go on
[10:00] It's covered in two different ways. So, the Vibe reporting way it's covered.
[10:30] was covered as clearly intended to imply Amazon laid off 16,000 people because of
[11:00] focused because it was it was reporting that was for the financial market. So it
[11:30] with jobs being replaced by AI. But then you can vibe report it because like well
[12:00] and it had nothing to do with it. And I heard by the way so I I wrote about that
[12:30] fired here to do with AI." This is just what we do at Amazon. We're ruthless.
[13:00] But no, you are right. I think for the there was been a lot of vibe reporting
[13:30] directly tied to the tech industry. If they're cutting in a down cycle, majors
[14:00] we've had these cycles every 5 years we have this cycle there. This is nothing
[14:30] thing. They just, you know, I'm going to bring it up and read the title. I'm not
[15:00] there. Like I'm I just want to start by saying if that's the best you've got and
[15:30] but also be excited a rare triple score it's just stories like these piss me off
[16:00] I've been rew I've been watching the first season of True Detective. I've got
[16:30] I mean, I think it's it's fun to create these sort of demo apps if you're
[17:00] fun for him in the same way that someone else might be like hey I built a cabinet
[17:30] Well, you know that doesn't go well. I mean, look, this is the story of this is
[18:00] the key you use when you access the paid service to get use an LLM, you have an
[18:30] there's a lot of people who are building kind of like internal tools or personal
[19:00] but that's not like a trillion dollar industry. I can't get my arms around yet
[19:30] I heard I'm going to be honest. I was going to ask you I was literally going
[20:00] other bit of evidence is that in at the end of last year anthropics claude code
[20:30] performanceoriented code. You can't write safe code. Um you you can't write
[21:00] write safe code. Um you you can't write code that has to sort of juggle a sort
[21:30] since I was, you know, seven. And it's a there's an it's an art form, right? When
[22:00] programmers that produce like 90% of the really important valuable code on which
[22:30] We're trying to write serious programs. Like we have to sell this software. Like
[23:00] the discussion about the technology happening from more engineering-minded
[23:30] where you have no one embedded. There's no one actually on the ground where the
[24:00] responding to the press conferences that the generals are holding, you know, back
[24:30] serious software, like actual real deal software is being made with it, but then
[25:00] this spends a lot of money money too so this is actually good it's actually good
[25:30] not withstand even the laziest hacker. I can do this and thus it will extrapolate
[26:00] they do feel like there's a huge amount of risk of saying this is not a big deal
[26:30] right? is like you wanted it was less there would be less harm if you were too
[27:00] a focus and meaning to like an otherwise somewhat chaotic and disrupted world
[27:30] anthropic and the FD is generally pretty good where they're like, "Yeah, they're
[28:00] where every major publication did bubble reportings. Um, but you're Yeah, I guess
[28:30] Would a man that has a shiny jacket like the Gleinger of K wears at concerts, uh,
[29:00] think it's probably higher. How are they meant to pay 30 to60 billion a year in a
[29:30] there needs to be some sort of reckoning with this because if you look back there
[30:00] astonishment which I actually love the astonishment reporting of like oh well
[30:30] I mean this is a good case study, right? This one bothered me because like writer
[31:00] And I start reading these articles and I say well there's no discussion of what
[31:30] there's no new AI technology involved in this at all the the agents you build are
[32:00] available. Come up with a plan. And then it sends it back a plan. And then it the
[32:30] Manis was this AI agent that Facebook might be Meta might be acquiring. They
[33:00] cool demos that are also like incredibly insecure and unsafe. U and so it was fun
[33:30] basically can do actions on behalf of your LLM query. So you could have like a
[34:00] produce text. But then the plug-in could take the text and go and book you a
[34:30] It was just a way for other people to build these things. The only interesting
[35:00] know, with this agent who can like email guests on our behalf and book it on our
[35:30] agents and they were just kind of like prompting and proddding their agents to
[36:00] Yeah, it really it really my model train I added a tunnel like so that one really
[36:30] "Hey, I've been [ __ ] around with some software and I did something cool." I'd
[37:00] and it doesn't it's it's just a series of library calls that you can use to
[37:30] Does it work? But does it does it work? Well, it's it's just asking an LL you
[38:00] ask you to redo it. It's really an issue if you write a program that just says I
[38:30] like issues in the details doesn't work well when you execute that. I mean in a
[39:00] Are you really or are you just have you if it is it completely? It probably
[39:30] interesting. It's like, look, hobbyists are building these tools that kind of do
[40:00] out there. They're significantly cheaper than trying to use like Ope nAI or cloud.
[40:30] office or something like that. So to me, that's the most interesting story out of
[41:00] but you also have all these open source models like the the weights are just out
[41:30] newsletter about the fact that actually the margins of serving GPU compute are
[42:00] stories that are like, "Yeah, Claude can now work for hours uninterrupted." Have
[42:30] problem? Yeah, it's just a loop. Just keep reading. Call it, recall it, recall
[43:00] program that calls an hour for 24 hours. If you need me to burn something for
[43:30] Well, and and also that's those are like specialized tasks typically that have
[44:00] because it's testable and they can keep retrying or something like that. I mean,
[44:30] tearing their shirts off and screaming. It go but it goes back to the two things
[45:00] breakthrough made this possible now? And then what are the concrete implications?
[45:30] don't have that, you're mining emotions. You and you're mining emotions or just
[46:00] That's great. I'm not And to be clear, I think that this scrutiny should be from
[46:30] everyone should face this scrutiny. Like that's I'm not saying that I should get
[47:00] have like a technical thing that I want an idea of being percolating. So I think
[47:30] you're guess the word that came next. There's a real word that came next. This
[48:00] That's pre-trained. It's unsupervised. So you take Hamlet or you take Dickens
[48:30] been set through this massive multimonth you know billion dollar pre-training
[49:00] get those weights away from that answer and if it's a good answer, you give it a
[49:30] to spit out answers by bombs. Like this where all the guard rails come from. Um
[50:00] after GPT4. So GPT4 was like the extent of pre-training making it smarter. After
[50:30] began focusing on metrics. But if I have a particular metric, I can post-train a
[51:00] But they No, no, they would. I'm not saying that. I'm saying do they postrain
[51:30] the outputs. Training is framed as this R&amp;D mysticism which is just out there
[52:00] this point. Yeah, it's the only way you improve or update things, right? Like,
[52:30] Um which is different than the way most people actually think of it differently.
[53:00] bits of stuff you've talked to it before in the prompt that's going to the model.
[53:30] which again doesn't really make sense to me. But putting that aside, they're not.
[54:00] training. This would be profitable. If I didn't have all these expenses, I'd
[54:30] all the all the words in the world and it takes months. So it's it's just like
[55:00] not that big of a a data set compared to we're going to train this on every word
[55:30] you're back propagating from one side of the network to the beginning as opposed
[56:00] when you do a bunch of it's a bunch of derivatives because you're constantly
[56:30] particularly expensive prompts and you had to pay for that instead of like them
[57:00] Wait, I was going to ask you about this. Uh, last month there's this announcement
[57:30] they're doing insane math, which happens very rarely, but this company feels like
[58:00] No, this is their formula. Yeah. Okay. Yeah. It's an insane formula that does
[58:30] more you know times the amount of money. And it's like, well, wait, that theater
[59:00] It is the funny thing is with that as well is it's more vibe reporting because
[59:30] Pro with AI, it's actually because of the way large language models work, your
[1:00:00] of new like the I'm counting new year starting like new year 2023 or whatever.
[1:00:30] many years we have to go? So I I did a I did a a video where I went I found the
[1:01:00] not people don't have much like well you know like it could these are like really
[1:01:30] so I went through that thread in a video and this has kind of been my question is
[1:02:00] No, web 3 is not about to take off. None of this makes sense. And that was true.
[1:02:30] like electricity, you could say like it just completely changed what day-to-day
[1:03:00] necessarily going forward, but right now I don't think it's got past much farther
[1:03:30] this is like the the surprising thing of this field is we're not really past the
[1:04:00] reporting is right now in AI. Whereas to me, this is the hugest question. If this
[1:04:30] all right, that's like that's like a really interesting significant story. If
[1:05:00] Hater season's the best. We will be back this week with either a monologue or an
[1:05:30] I'm at Zitron. Subscribe to the premium. Download a t-shirt. Whatever you desire.
[1:06:00] You can email me at easy@betoffline.com or visit betteroffline.com to find more
[1:06:30] Apple Podcast or wherever you get your podcasts.
