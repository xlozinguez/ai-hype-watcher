---
source_id: "150"
title: "Claude Tried Chess. It's TERRIFYING."
creator: "GothamChess"
platform: "YouTube"
url: "https://www.youtube.com/watch?v=hzzPs17gavs"
date: "2026-02-21"
duration: "21:53"
type: "video"
tags: ["ai-hype", "ai-landscape"]
curriculum_modules: ["01-foundations"]
---

# 150: Claude Tried Chess. It's TERRIFYING.

> **Creator**: GothamChess | **Platform**: YouTube | **Date**: 2026-02-21 | **Duration**: 21:53

## Summary

GothamChess (Levy Rozman) hosts the second edition of his Chatbot Chess World Championship, where AI chatbots — ChatGPT, Copilot, Claude, Snapchat AI, Meta AI, and DeepSeek — play chess in a knockout tournament. This episode covers Claude vs. Snapchat AI, providing an entertaining and unintentionally revealing look at how LLMs handle structured games with strict rules.

The match exposes fundamental LLM limitations: both bots make illegal moves (Snapchat's knight captures its own pawn, Claude attempts an impossible en passant), teleport pieces across the board, and occasionally forget whose turn it is. Snapchat AI twice attempts to abandon the game entirely. Claude ultimately wins with checkmate but makes numerous blunders along the way, including moving a bishop like a rook and placing a knight on the checkmating square instead of a queen.

## Key Concepts

### LLMs Cannot Play Chess

Despite being trained on vast amounts of chess literature, LLMs fundamentally lack the ability to maintain a valid board state. They hallucinate legal moves, capture their own pieces, teleport pieces across the board, and make moves that violate basic piece movement rules. This is a concrete demonstration of the gap between pattern-matching language generation and actual reasoning.

### Confident Incorrectness

The bots provide sophisticated-sounding chess commentary while making illegal moves. They analyze positions with the confidence of experts while simultaneously breaking the rules. This mirrors a broader AI pattern: fluent, authoritative-sounding output that is factually wrong.

### Relative Capability Differences

Even among chatbots, capability varies dramatically. Snapchat AI repeatedly tries to skip turns or abandon the game, while Claude at least maintains engagement and occasionally makes strong moves (like Queen H4 exploiting an open king). The tournament bracket format makes these relative strengths visible.

## Practical Takeaways

- **LLMs are not reasoning engines**: Chess is a clear test case showing that language models cannot reliably maintain state or follow rule systems, despite generating plausible-sounding analysis
- **Fluent output does not equal correctness**: The bots provide confident commentary on positions they fundamentally misunderstand — a pattern that applies across all LLM use cases
- **Entertainment value reveals real limitations**: Casual, fun content like chatbot chess tournaments can be more illustrative of AI limitations than technical benchmarks

## Notable Quotes

> "They comment on them with the confidence of a person working on their second PhD who has yet to be employed." — GothamChess

> "How on earth can you get the wrong piece here? Queen G2 is — it's — that would have been the end of the video. Instead, we get knight to G2." — GothamChess

## Related Sources

_None currently in collection._

## Related Curriculum

- [Module 01: Foundations](../curriculum/01-foundations/README.md) — AI capabilities vs. hype, understanding what LLMs can and cannot do
